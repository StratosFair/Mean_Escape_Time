{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPbra/AwAABuwLltwNq5OeN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StratosFair/Mean_Escape_Time/blob/main/error_tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "SkqsJgtafqb3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sci_tex(x, sig=4):\n",
        "    \"\"\"\n",
        "    Convert float to LaTeX-like string with `sig` significant figures.\n",
        "    Always produces a mantissa with exactly `sig` significant digits.\n",
        "    Uses scientific notation when exponent != 0.\n",
        "\n",
        "    Examples (sig=4):\n",
        "      0.0020063 -> '2.006 \\\\times 10^{-3}'\n",
        "      0.6909    -> '6.909 \\\\times 10^{-1}'\n",
        "      1.2345    -> '1.235'\n",
        "      4.92      -> '4.920'\n",
        "    \"\"\"\n",
        "    if x == 0:\n",
        "        # e.g. sig=4 -> '0.000'\n",
        "        return \"0.\" + \"0\" * (sig - 1)\n",
        "\n",
        "    # Use scientific notation with fixed total significant digits = sig\n",
        "    # format: one digit before '.', (sig-1) after '.', then 'e±NN'\n",
        "    s = f\"{x:.{sig-1}e}\"\n",
        "    coeff, exp = s.split(\"e\")\n",
        "    exp = int(exp)\n",
        "\n",
        "    if exp == 0:\n",
        "        # No exponent: keep coeff, which already has sig significant digits\n",
        "        # e.g. '4.920'\n",
        "        return coeff\n",
        "\n",
        "    # Non-zero exponent: mantissa × 10^{exp}\n",
        "    return f\"{coeff} \\\\times 10^{{{exp}}}\"\n",
        "\n",
        "\n",
        "def fmt_mean_std(values, sig=4):\n",
        "    \"\"\"\n",
        "    Format a list of floats as 'mean±std' in LaTeX, with `sig` significant figures.\n",
        "    Returns '—' if values is empty.\n",
        "    \"\"\"\n",
        "    if not values:\n",
        "        return \"—\"\n",
        "    arr = np.array(values, dtype=float)\n",
        "    mean = np.mean(arr)\n",
        "    std = np.std(arr, ddof=1) if len(arr) > 1 else 0.0\n",
        "    if np.isnan(std):\n",
        "        std = 0.0\n",
        "    return f\"{sci_tex(mean, sig)}\\\\pm{sci_tex(std, sig)}\"\n",
        "\n",
        "\n",
        "def parse_tau_norms(text):\n",
        "    \"\"\"\n",
        "    Try to extract ||tau||_{L2}, ||tau||_{H1}, ||tau||_{H2} from the log text.\n",
        "\n",
        "    Preferred format in the .txt file (one line anywhere):\n",
        "        TAU_NORMS: L2=1.234e-01 H1=2.345e-01 H2=3.456e-01\n",
        "\n",
        "    If that is not present, adjust tau_patterns below to match your logs,\n",
        "    or add the TAU_NORMS line to your logging.\n",
        "\n",
        "    Returns a dict: {\"L2\": float or None, \"H1\": float or None, \"H2\": float or None}.\n",
        "    \"\"\"\n",
        "    tau_norms = {\"L2\": None, \"H1\": None, \"H2\": None}\n",
        "\n",
        "    # --- Option 1: TAU_NORMS line with key=val pairs ---\n",
        "    for line in text.splitlines():\n",
        "        if \"TAU_NORMS\" in line:\n",
        "            # Example: \"TAU_NORMS: L2=1.23e-01 H1=2.34e+00 H2=3.45e+00\"\n",
        "            after_colon = line.split(\":\", 1)[1].strip()\n",
        "            # Allow commas or spaces as separators\n",
        "            tokens = after_colon.replace(\",\", \" \").split()\n",
        "            for tok in tokens:\n",
        "                if \"=\" in tok:\n",
        "                    key, val = tok.split(\"=\", 1)\n",
        "                    key = key.strip()\n",
        "                    val = val.strip()\n",
        "                    if key in tau_norms:\n",
        "                        try:\n",
        "                            tau_norms[key] = float(val)\n",
        "                        except ValueError:\n",
        "                            pass\n",
        "            break  # stop after first TAU_NORMS line\n",
        "\n",
        "    # --- Option 2: fallback to simple phrase matching (edit if needed) ---\n",
        "    if any(v is None for v in tau_norms.values()):\n",
        "        tau_patterns = {\n",
        "            # EDIT these phrases to match how your logs mention the norms of tau.\n",
        "            # Example expected line:\n",
        "            #   \"L2 norm of tau over Omega: 1.234e-01\"\n",
        "            \"L2\": \"L2 norm of tau\",\n",
        "            \"H1\": \"H1 norm of tau\",\n",
        "            \"H2\": \"H2 norm of tau\",\n",
        "        }\n",
        "        for line in text.splitlines():\n",
        "            for key, phrase in tau_patterns.items():\n",
        "                if tau_norms[key] is not None:\n",
        "                    continue\n",
        "                if phrase in line:\n",
        "                    m = re.search(r\"([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", line)\n",
        "                    if m:\n",
        "                        try:\n",
        "                            tau_norms[key] = float(m.group(1))\n",
        "                        except ValueError:\n",
        "                            pass\n",
        "\n",
        "    return tau_norms\n",
        "\n",
        "\n",
        "def process_file(filename, caption, sig=4):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Full names as they should appear in the table\n",
        "    order = [\n",
        "        \"BoundaryPINN\",\n",
        "        \"SimplePINN\",\n",
        "        \"VariationalPINN\",\n",
        "        \"OverPINN $(d^{1.5})$\",\n",
        "        \"UnderPINN $(d^{0.5})$\",\n",
        "    ]\n",
        "\n",
        "    pretty_name = {\n",
        "        \"BoundaryPINN\": \"BoundaryPINN\",\n",
        "        \"SimplePINN\": \"SimplePINN\",\n",
        "        \"VariationalPINN\": \"VariationalPINN\",\n",
        "        \"OverPINN $(d^{1.5})$\": \"OverPINN $(d^{1.5})$\",\n",
        "        \"UnderPINN $(d^{0.5})$\": \"UnderPINN $(d^{0.5})$\",\n",
        "    }\n",
        "\n",
        "    # Map a simple base name (as appears in \\subsection) to the full key\n",
        "    base_to_arch = {\n",
        "        \"BoundaryPINN\": \"BoundaryPINN\",\n",
        "        \"SimplePINN\": \"SimplePINN\",\n",
        "        \"VariationalPINN\": \"VariationalPINN\",\n",
        "        \"OverPINN\": \"OverPINN $(d^{1.5})$\",\n",
        "        \"UnderPINN\": \"UnderPINN $(d^{0.5})$\",\n",
        "    }\n",
        "\n",
        "    # Data structure: data[architecture][metric] -> list of floats\n",
        "    data = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "    # Phrases to look for in each line\n",
        "    patterns = {\n",
        "        \"L2\":   \"Global relative L2 error\",\n",
        "        \"L1\":   \"Global relative L1 error\",\n",
        "        \"H1\":   \"Global relative H1 error\",\n",
        "        \"H2\":   \"Global relative H2 error\",\n",
        "        \"PDE\":  \"Final PDE loss\",\n",
        "        \"BC\":   \"Final BC loss\",\n",
        "        \"Data\": \"Final data loss\",\n",
        "    }\n",
        "\n",
        "    # Parse norms of tau (used in table headers)\n",
        "    tau_norms = parse_tau_norms(text)\n",
        "\n",
        "    current_arch = None\n",
        "\n",
        "    # ---- PARSING LOOP FOR METRICS ----\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Section headers identify the current architecture\n",
        "        if line.startswith(\"\\\\subsection\"):\n",
        "            current_arch = None\n",
        "            # Remove braces so things like ^{1.5} become ^1.5, etc.\n",
        "            clean = line.replace(\"{\", \"\").replace(\"}\", \"\")\n",
        "            for base, arch in base_to_arch.items():\n",
        "                if base in clean:\n",
        "                    current_arch = arch\n",
        "                    break\n",
        "            continue\n",
        "\n",
        "        if current_arch is None:\n",
        "            continue\n",
        "\n",
        "        # Match metrics by phrase and then capture the number just after the colon\n",
        "        for key, phrase in patterns.items():\n",
        "            if phrase in line:\n",
        "                match = re.search(r\":\\s*([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", line)\n",
        "                if match:\n",
        "                    val = float(match.group(1))\n",
        "                    data[current_arch][key].append(val)\n",
        "                break\n",
        "\n",
        "    # ---- ERROR METRICS TABLE (L2, H1, H2) ----\n",
        "    # Build headers with optional ||tau|| info\n",
        "    l2_header = r\"$L^2_{\\rm rel}$\"\n",
        "    h1_header = r\"$H^1_{\\rm rel}$\"\n",
        "    h2_header = r\"$H^2_{\\rm rel}$\"\n",
        "\n",
        "    if tau_norms.get(\"L2\") is not None:\n",
        "        l2_header = (\n",
        "            \"$L^2_{\\\\rm rel} \"\n",
        "            f\"(\\\\|\\\\tau\\\\|_{{L^2(\\\\Omega)}} = {sci_tex(tau_norms['L2'], sig)})$\"\n",
        "        )\n",
        "    if tau_norms.get(\"H1\") is not None:\n",
        "        h1_header = (\n",
        "            \"$H^1_{\\\\rm rel} \"\n",
        "            f\"(\\\\|\\\\tau\\\\|_{{H^1(\\\\Omega)}} = {sci_tex(tau_norms['H1'], sig)})$\"\n",
        "        )\n",
        "    if tau_norms.get(\"H2\") is not None:\n",
        "        h2_header = (\n",
        "            \"$H^2_{\\\\rm rel} \"\n",
        "            f\"(\\\\|\\\\tau\\\\|_{{H^2(\\\\Omega)}} = {sci_tex(tau_norms['H2'], sig)})$\"\n",
        "        )\n",
        "\n",
        "    print(\"\\\\begin{table}[htbp]\")\n",
        "    print(\"\\t\\\\centering\")\n",
        "    print(f\"\\t\\\\caption{{{caption} -- Error metrics}}\")\n",
        "    print(\"\\t\\\\small\")\n",
        "    print(\"\\t\\\\begin{tabular}{lccc}\")\n",
        "    print(\"\\t\\t\\\\toprule\")\n",
        "    print(f\"\\t\\tMethod & {l2_header} & {h1_header} & {h2_header} \\\\\\\\\")\n",
        "    print(\"\\t\\t\\\\midrule\")\n",
        "\n",
        "    for arch in order:\n",
        "        row = [pretty_name[arch]]\n",
        "        # Each numeric entry wrapped in math mode\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['L2'], sig)}$\")\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['H1'], sig)}$\")\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['H2'], sig)}$\")\n",
        "        print(\"\\t\\t\" + \" & \".join(row) + \" \\\\\\\\\")\n",
        "\n",
        "    print(\"\\t\\t\\\\bottomrule\")\n",
        "    print(\"\\t\\\\end{tabular}\")\n",
        "    print(\"\\\\end{table}\")\n",
        "    print()\n",
        "\n",
        "    # ---- TRAINING METRICS TABLE (PDE, Data, BC) ----\n",
        "    # NOTE: Data loss and BC loss columns are swapped compared to your original code.\n",
        "    print(\"\\\\begin{table}[htbp]\")\n",
        "    print(\"\\t\\\\centering\")\n",
        "    print(f\"\\t\\\\caption{{{caption} -- Training metrics}}\")\n",
        "    print(\"\\t\\\\small\")\n",
        "    print(\"\\t\\\\begin{tabular}{lccc}\")\n",
        "    print(\"\\t\\t\\\\toprule\")\n",
        "    print(\"\\t\\tMethod & PDE loss & Data loss & BC loss \\\\\\\\\")\n",
        "    print(\"\\t\\t\\\\midrule\")\n",
        "\n",
        "    for arch in order:\n",
        "        row = [pretty_name[arch]]\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['PDE'], sig)}$\")\n",
        "        # Swapped order: Data first, then BC\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['Data'], sig)}$\")\n",
        "        row.append(f\"${fmt_mean_std(data[arch]['BC'], sig)}$\")\n",
        "        print(\"\\t\\t\" + \" & \".join(row) + \" \\\\\\\\\")\n",
        "\n",
        "    print(\"\\t\\t\\\\bottomrule\")\n",
        "    print(\"\\t\\\\end{tabular}\")\n",
        "    print(\"\\\\end{table}\")"
      ],
      "metadata": {
        "id": "YrpPhPrB_T5R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_file(\"ou.txt\", \"Ornstein-Uhlenbeck 2D\", sig=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHAWzSgGgNa6",
        "outputId": "4e752f47-2d5b-4a83-fb57-c8ce75f41f1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[htbp]\n",
            "\t\\centering\n",
            "\t\\caption{Ornstein-Uhlenbeck 2D -- Error metrics}\n",
            "\t\\small\n",
            "\t\\begin{tabular}{lccc}\n",
            "\t\t\\toprule\n",
            "\t\tMethod & $L^2_{\\rm rel} (\\|\\tau\\|_{L^2(\\Omega)} = 1.155 \\times 10^{1})$ & $H^1_{\\rm rel} (\\|\\tau\\|_{H^1(\\Omega)} = 2.266 \\times 10^{1})$ & $H^2_{\\rm rel} (\\|\\tau\\|_{H^2(\\Omega)} = 1.841 \\times 10^{2})$ \\\\\n",
            "\t\t\\midrule\n",
            "\t\tBoundaryPINN & $2.006 \\times 10^{-3}\\pm3.014 \\times 10^{-4}$ & $1.998 \\times 10^{-3}\\pm2.981 \\times 10^{-4}$ & $1.990 \\times 10^{-3}\\pm2.946 \\times 10^{-4}$ \\\\\n",
            "\t\tSimplePINN & $4.887 \\times 10^{-2}\\pm3.872 \\times 10^{-2}$ & $4.994 \\times 10^{-2}\\pm3.926 \\times 10^{-2}$ & $5.041 \\times 10^{-2}\\pm3.964 \\times 10^{-2}$ \\\\\n",
            "\t\tVariationalPINN & $1.169 \\times 10^{-1}\\pm5.697 \\times 10^{-2}$ & $6.491 \\times 10^{-1}\\pm6.106 \\times 10^{-1}$ & $3.269\\pm4.211$ \\\\\n",
            "\t\tOverPINN $(d^{1.5})$ & $1.013\\pm5.774 \\times 10^{-4}$ & $1.006\\pm0.000$ & $1.001\\pm5.774 \\times 10^{-4}$ \\\\\n",
            "\t\tUnderPINN $(d^{0.5})$ & $1.009\\pm1.732 \\times 10^{-3}$ & $1.005\\pm5.774 \\times 10^{-4}$ & $1.000\\pm0.000$ \\\\\n",
            "\t\t\\bottomrule\n",
            "\t\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\\begin{table}[htbp]\n",
            "\t\\centering\n",
            "\t\\caption{Ornstein-Uhlenbeck 2D -- Training metrics}\n",
            "\t\\small\n",
            "\t\\begin{tabular}{lccc}\n",
            "\t\t\\toprule\n",
            "\t\tMethod & PDE loss & Data loss & BC loss \\\\\n",
            "\t\t\\midrule\n",
            "\t\tBoundaryPINN & $5.639 \\times 10^{-5}\\pm3.821 \\times 10^{-6}$ & $6.829 \\times 10^{-1}\\pm1.580 \\times 10^{-2}$ & $—$ \\\\\n",
            "\t\tSimplePINN & $5.229 \\times 10^{-1}\\pm6.802 \\times 10^{-1}$ & $6.221 \\times 10^{-1}\\pm8.254 \\times 10^{-2}$ & $2.170 \\times 10^{-1}\\pm3.759 \\times 10^{-1}$ \\\\\n",
            "\t\tVariationalPINN & $8.532 \\times 10^{-4}\\pm1.397 \\times 10^{-3}$ & $2.239\\pm8.159 \\times 10^{-1}$ & $4.920\\pm8.522$ \\\\\n",
            "\t\tOverPINN $(d^{1.5})$ & $5.450 \\times 10^{-2}\\pm4.157 \\times 10^{-2}$ & $1.254 \\times 10^{2}\\pm2.623$ & $—$ \\\\\n",
            "\t\tUnderPINN $(d^{0.5})$ & $4.332 \\times 10^{-1}\\pm9.777 \\times 10^{-2}$ & $1.254 \\times 10^{2}\\pm1.401$ & $—$ \\\\\n",
            "\t\t\\bottomrule\n",
            "\t\\end{tabular}\n",
            "\\end{table}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_file(\"dw.txt\", \"Double Well 2D\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yow6BlC2gRKF",
        "outputId": "cecd2309-626e-4b8f-b7e0-3f4ca7bd623c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[htbp]\n",
            "\t\\centering\n",
            "\t\\caption{Double Well 2D -- Error metrics}\n",
            "\t\\small\n",
            "\t\\begin{tabular}{lccc}\n",
            "\t\t\\toprule\n",
            "\t\tMethod & $L^2_{\\rm rel} (\\|\\tau\\|_{L^2(\\Omega)} = 9.538 \\times 10^{-1})$ & $H^1_{\\rm rel} (\\|\\tau\\|_{H^1(\\Omega)} = 1.834)$ & $H^2_{\\rm rel} (\\|\\tau\\|_{H^2(\\Omega)} = 8.577)$ \\\\\n",
            "\t\t\\midrule\n",
            "\t\tBoundaryPINN & $2.643 \\times 10^{-1}\\pm3.512 \\times 10^{-4}$ & $3.233 \\times 10^{-1}\\pm8.386 \\times 10^{-4}$ & $4.031 \\times 10^{-1}\\pm1.300 \\times 10^{-3}$ \\\\\n",
            "\t\tSimplePINN & $2.953 \\times 10^{-1}\\pm1.200 \\times 10^{-2}$ & $4.499 \\times 10^{-1}\\pm1.393 \\times 10^{-2}$ & $6.530 \\times 10^{-1}\\pm2.366 \\times 10^{-2}$ \\\\\n",
            "\t\tVariationalPINN & $5.639 \\times 10^{-1}\\pm1.100 \\times 10^{-2}$ & $1.173\\pm9.637 \\times 10^{-2}$ & $1.197 \\times 10^{1}\\pm1.703$ \\\\\n",
            "\t\tOverPINN $(d^{1.5})$ & $4.857 \\times 10^{-1}\\pm3.981 \\times 10^{-1}$ & $5.865 \\times 10^{-1}\\pm4.187 \\times 10^{-1}$ & $8.943 \\times 10^{-1}\\pm2.767 \\times 10^{-1}$ \\\\\n",
            "\t\tUnderPINN $(d^{0.5})$ & $9.047 \\times 10^{-1}\\pm8.524 \\times 10^{-3}$ & $9.202 \\times 10^{-1}\\pm9.625 \\times 10^{-3}$ & $9.625 \\times 10^{-1}\\pm8.305 \\times 10^{-3}$ \\\\\n",
            "\t\t\\bottomrule\n",
            "\t\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\\begin{table}[htbp]\n",
            "\t\\centering\n",
            "\t\\caption{Double Well 2D -- Training metrics}\n",
            "\t\\small\n",
            "\t\\begin{tabular}{lccc}\n",
            "\t\t\\toprule\n",
            "\t\tMethod & PDE loss & Data loss & BC loss \\\\\n",
            "\t\t\\midrule\n",
            "\t\tBoundaryPINN & $2.316 \\times 10^{-4}\\pm7.213 \\times 10^{-6}$ & $2.734 \\times 10^{-3}\\pm2.190 \\times 10^{-4}$ & $—$ \\\\\n",
            "\t\tSimplePINN & $3.580\\pm5.859 \\times 10^{-1}$ & $9.612 \\times 10^{-3}\\pm2.935 \\times 10^{-3}$ & $1.466 \\times 10^{-11}\\pm8.607 \\times 10^{-12}$ \\\\\n",
            "\t\tVariationalPINN & $1.059 \\times 10^{-6}\\pm6.009 \\times 10^{-7}$ & $1.050 \\times 10^{-1}\\pm9.377 \\times 10^{-3}$ & $8.653 \\times 10^{-18}\\pm9.463 \\times 10^{-18}$ \\\\\n",
            "\t\tOverPINN $(d^{1.5})$ & $6.912\\pm5.865$ & $1.565 \\times 10^{-1}\\pm2.674 \\times 10^{-1}$ & $—$ \\\\\n",
            "\t\tUnderPINN $(d^{0.5})$ & $1.088\\pm2.784 \\times 10^{-2}$ & $4.127 \\times 10^{-1}\\pm1.489 \\times 10^{-2}$ & $—$ \\\\\n",
            "\t\t\\bottomrule\n",
            "\t\\end{tabular}\n",
            "\\end{table}\n"
          ]
        }
      ]
    }
  ]
}