{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfP5I5tDm79j/WdA+eqL1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StratosFair/Mean_Escape_Time/blob/main/Duffin_oscillator/Models/boundary_pinn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "JioiNFwzetqk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import ReLU\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving for the MET of a Duffing oscillator process in a disk with \"Boundary Adapted PINNs\": computation of solutions using Finite Element Method\n",
        "\n",
        "Based on the paper [A neural network solution of first-passage problems](https://link.springer.com/article/10.1007/s10483-024-3189-8) (Jiamin Qian, Lincong Chen & J. Q. Sun, Oct. 2024), the 2-dimensional Duffing oscillator is defined by:\n",
        "$$ d \\begin{pmatrix} X_1(t)\\\\\n",
        "X_2(t) \\end{pmatrix} = \\begin{pmatrix} X_2\\\\\n",
        "-X_1 - X_1^3 - 2\\zeta X_2 \\end{pmatrix} dt + \\begin{pmatrix} \\sqrt{2\\varepsilon}dB_1(t)\\\\\n",
        "\\sqrt{2\\zeta} dB_2(t) \\end{pmatrix}$$\n",
        "\n",
        "The infinitesimal generator of this process is given for sufficiently smooth $f$ by\n",
        "$$\\mathscr Lf: x \\mapsto b(x) \\cdot \\nabla f(x) + a(x) : \\nabla^2 f(x)$$\n",
        "where\n",
        "$$b : x = (x_1, x_2)^T \\mapsto \\begin{pmatrix} x_2\\\\ -x_1 - x_1^3 - 2\\zeta x_2 \\end{pmatrix}  $$\n",
        "and\n",
        "$$a:x \\mapsto \\frac12 \\sigma(x)\\sigma(x)^T = \\begin{pmatrix} \\varepsilon & 0\\\\ 0 & \\zeta\\end{pmatrix} $$\n",
        "\n",
        "Let $\\Omega := B_r \\equiv \\{x\\in\\mathbb R^d : \\|x\\|< r \\}$, and for all $x\\in\\Omega$, let\n",
        "\n",
        "$$T(x) := \\inf\\{t\\ge 0 : X_t \\in\\partial\\Omega\\} $$\n",
        "\n",
        "and let its first moment be denoted\n",
        "\n",
        "$$\\tau(x) := \\mathbb E[T(x)] $$\n",
        "\n",
        "We can show under some regularity conditions on the coefficients $a$ and $b$ that $\\tau:\\Omega \\to \\mathbb R$ is the (unique) solution of the BVP :\n",
        "\n",
        "$$\\begin{cases}\\mathscr L\\tau = -1 \\quad \\text{in } \\Omega,\\\\\n",
        "\\tau= 0 \\quad\\text{ on }\\partial\\Omega\\end{cases} $$"
      ],
      "metadata": {
        "id": "Rh-yuT-m-8z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Setting up the Neural Network architecture and loss function\n",
        "\n",
        "Unlike the standard PINN, we will take an hypothesis space of Neural Networks which satisfy the boundary conditions explicitly. For this problem, we have homogenous zero Dirichlet boundary conditions, which we can enforce by multiplying our Neural Networks with an appropriate \"smooth distance approximation\" (see https://arxiv.org/abs/2104.08426). In accordance with the mentioned paper, we will take\n",
        "$$\\varphi : x\\mapsto \\frac{r^2 - \\|x\\|^2}{2r}$$\n",
        "as our smooth distance approximation.  \n",
        "\n",
        "\n",
        "With this modification, our objective to minimize becomes\n",
        "$$\\hat u := \\arg\\min_{u\\in\\mathcal{NN}}\\ \\frac1n \\sum_{i=1}^n (\\mathscr L u(x_i^c) + 1)^2 $$\n",
        "where $x_i^c$ are sampled i.i.d. with uniform distribution on $\\Omega$,\n",
        "$$\\sigma_k :x \\mapsto \\begin{cases}x^k &\\text{ if } x\\ge 0\\\\ 0 &\\text{ if } x\\le 0\\end{cases} $$\n",
        "is the ReLU$^k$ activation, and\n",
        "$\\mathcal{NN} $ is a space of feedforward Neural Networks with $\\sigma_k$ activation."
      ],
      "metadata": {
        "id": "ipb5U7KL7yL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters of the PDE\n",
        "radius = 2\n",
        "zeta = 3.2 #goal: zeta=0.08\n",
        "eps = 5e-4 #1e-8\n",
        "\n",
        "#define our NN architecture\n",
        "power = 2 #exponent k for relu^k\n",
        "width = 50\n",
        "depth = 3\n",
        "magnitude = 0.5 #magnitude of weights at initialization\n",
        "\n",
        "#define ReLU^k activation\n",
        "\n",
        "class RePU(nn.Module):\n",
        "    def __init__(self, power = power):\n",
        "        super(RePU, self).__init__()\n",
        "        self.power = power\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.pow(torch.relu(x), self.power)\n",
        "\n",
        "\n",
        "#define the smooth distance approximation\n",
        "def smooth_distance(x):\n",
        "    norm_x = torch.linalg.norm(x, dim=-1)\n",
        "    return (radius**2 - norm_x**2)/(2*radius)\n",
        "\n",
        "\n",
        "#define hypothesis space\n",
        "class BoundaryPINN(nn.Module):\n",
        "    def __init__(self, power = power, width = width, depth = depth):\n",
        "        super(BoundaryPINN,self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(2, width))\n",
        "        self.layers.append(RePU(power))\n",
        "        for _ in range(depth-1) :\n",
        "            self.layers.append(nn.Linear(width, width))\n",
        "            self.layers.append(RePU(power))\n",
        "        self.layers.append(nn.Linear(width, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x\n",
        "        for layer in self.layers:\n",
        "            output = layer(output)\n",
        "        distance =  smooth_distance(x)\n",
        "        return output**2 * distance.unsqueeze(-1)"
      ],
      "metadata": {
        "id": "8-itNA2vPyqb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all functions needed for training\n",
        "\n",
        "def derivative(dy: torch.Tensor, x: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function calculates the derivative of the model at x\n",
        "    \"\"\"\n",
        "    for i in range(order):\n",
        "        dy = torch.autograd.grad(\n",
        "            dy, x, grad_outputs = torch.ones_like(dy), create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "    return dy\n",
        "\n",
        "def u_function(model: BoundaryPINN, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function evaluates the model on the input x\n",
        "    \"\"\"\n",
        "    model_input = torch.stack((x, y), axis = 1)\n",
        "    return model(model_input)\n",
        "\n",
        "\n",
        "def residual(model, x_c, y_c, zeta, eps):\n",
        "    u = u_function(model, x_c, y_c)\n",
        "    u_x = derivative(u, x_c, order=1)\n",
        "    u_y = derivative(u, y_c, order=1)\n",
        "    u_xx = derivative(u, x_c, order=2)\n",
        "    u_yy = derivative(u, y_c, order=2)\n",
        "    res = y_c * u_x \\\n",
        "        - (x_c + x_c**3 + 2*zeta*y_c) * u_y \\\n",
        "        + eps * u_xx + zeta * u_yy \\\n",
        "        + 1\n",
        "    return res\n",
        "\n",
        "def loss_function(model: BoundaryPINN, x_c: torch.Tensor, y_c: torch.Tensor, zeta, eps) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function evaluates the physics governing the model on the input x\n",
        "    \"\"\"\n",
        "    res = residual(model, x_c, y_c, zeta, eps)\n",
        "    return torch.mean(res**2)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight, gain=magnitude)\n",
        "        m.bias.data.fill_(magnitude)"
      ],
      "metadata": {
        "id": "Wjer_ESbR0ab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Verification of the collocation points for training\n",
        "\n",
        "sampling $N= N_c$ collocation points in $\\Omega$."
      ],
      "metadata": {
        "id": "lVUscVjoR6hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_c = 2048 #number of points in the domain\n",
        "\n",
        "#definition of X_c_train : N_c points in the disk\n",
        "t = np.random.uniform(0,2*np.pi, N_c)\n",
        "rho = np.sqrt(np.random.uniform(0,radius**2, N_c)) #uniform distribution on the disk\n",
        "x_c = rho * np.cos(t)\n",
        "y_c = rho * np.sin(t)\n",
        "X_c_train = np.vstack( (x_c, y_c) )\n",
        "\n",
        "#shuffling X_c_train\n",
        "index = np.arange(0, N_c)\n",
        "np.random.shuffle(index)\n",
        "X_c_train = X_c_train[:,index]"
      ],
      "metadata": {
        "id": "XC_qfCnWSFyn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the collocation points\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "#circle\n",
        "a = np.linspace(0, 2*np.pi, 50)\n",
        "cx,cy = np.cos(a) * radius , np.sin(a)*radius\n",
        "\n",
        "plt.plot(cx,cy,'k-', alpha=.6)\n",
        "plt.scatter(x_c,y_c)"
      ],
      "metadata": {
        "id": "A8PSKrxGSGkc",
        "outputId": "38840e1f-fd00-4b51-d4f6-4b4b904b3d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7c36ac5b35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingData(Dataset):\n",
        "    def __init__(self, X_c):\n",
        "        self.X_c = X_c\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X_c.shape[1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X_c = self.X_c[:, index]\n",
        "        return X_c"
      ],
      "metadata": {
        "id": "5ryH2hjQSMp-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Training loop function"
      ],
      "metadata": {
        "id": "c6QXroqASO7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adam\n",
        "def train_one_epoch(model, optimizer, zeta, eps, losses):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "    n_display = max(1, (N_c // batch_size) // 3)\n",
        "\n",
        "    for i, X_c in enumerate(dataloader):\n",
        "\n",
        "        x_c = X_c[0,:]\n",
        "        y_c = X_c[1,:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_function(model, x_c, y_c, zeta, eps)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % n_display == 0 :\n",
        "            last_loss = running_loss / n_display # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            losses.append(last_loss)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "_0YrVEK1S7mC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#l-bfgs\n",
        "def train_one_epoch_lbfgs(model, optimizer, zeta, eps, losses):\n",
        "\n",
        "    iter = 0\n",
        "\n",
        "    for X_c in dataloader_bfgs:\n",
        "        x_c = X_c[0,:]  # Collocation points (x-coordinates)\n",
        "        y_c = X_c[1,:]  # Collocation points (y-coordinates)\n",
        "\n",
        "    # Define the closure function required by L-BFGS\n",
        "    def closure():\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "        # Compute total loss\n",
        "        loss = loss_function(model, x_c, y_c, zeta, eps)\n",
        "        loss.backward()  # Backpropagation to compute gradients\n",
        "\n",
        "        # Log the loss for the current iteration\n",
        "        print(f'L-BFGS Iteration {iter}: Loss = {loss.item()}')\n",
        "        iteration += 1\n",
        "        return loss\n",
        "\n",
        "    # Perform one optimization step\n",
        "    optimizer.step(closure)\n",
        "\n",
        "    final_loss = loss_function(model, x_c, y_c, zeta, eps).item()\n",
        "\n",
        "    # Gather data and report\n",
        "    print('Full-batch loss: {}'.format(final_loss))\n",
        "    losses.append(final_loss)  # Append the final loss to the losses list\n",
        "\n",
        "    return final_loss"
      ],
      "metadata": {
        "id": "l5V-CvBf_h9t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Launching the training"
      ],
      "metadata": {
        "id": "ZQUHMobzS_jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_curriculum = 1\n",
        "zetas = [zeta] #* nb_curriculum\n",
        "epsis = [eps] #np.linspace(zeta * nb_curriculum, eps, nb_curriculum).tolist()\n",
        "losses = [[] for _ in range(nb_curriculum)]\n",
        "\n",
        "#training parameters\n",
        "n_batches = 16 #<= N_c\n",
        "batch_size = max(4, N_c//n_batches)\n",
        "learning_rate_adam = 5e-4\n",
        "method = 'Adam' #'SGD' or 'Adam', Adam strongly recommended\n",
        "n_epochs = 10_000\n",
        "n_decreases = 100\n",
        "damping = 1e-3\n",
        "gamma = damping**(1/n_decreases) #damp the learning rate by a factor of 'damping' by the end of training\n",
        "\n",
        "#first training batch\n",
        "#convert numpy array to tensor and load it\n",
        "X_c_train_tensor = torch.from_numpy(X_c_train).requires_grad_(True).float()\n",
        "dataset = TrainingData(X_c_train_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "dataloader_bfgs = DataLoader(dataset, batch_size=len(dataset), shuffle=True)"
      ],
      "metadata": {
        "id": "0kbQdCiZTAQI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #model initialization\n",
        "# #Define the model\n",
        "# model = BoundaryPINN(power=power, width=width, depth=depth)\n",
        "\n",
        "# # Initialize weights (only for the first curriculum step)\n",
        "# model.apply(init_weights)\n",
        "\n",
        "# # Save an empty model (useful for debugging)\n",
        "# torch.save({'model_state_dict': model.state_dict()}, 'boundary_pinn_initial.pt')"
      ],
      "metadata": {
        "id": "L1x0KgR5GMIx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download a pretrained model\n",
        "!wget https://raw.githubusercontent.com/StratosFair/Mean_Escape_Time/main/OU_process/Models/boundary_pinn_theta=0.5_sigma=1.pt -O boundary_pinn_pretrained.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHOqYLFiOlHA",
        "outputId": "bb57eea6-46d3-47de-87e6-a0cfd1d374cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-12 09:18:57--  https://raw.githubusercontent.com/StratosFair/Mean_Escape_Time/main/OU_process/Models/boundary_pinn_theta=0.5_sigma=1.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73634 (72K) [application/octet-stream]\n",
            "Saving to: ‘boundary_pinn_pretrained.pt’\n",
            "\n",
            "\r          boundary_   0%[                    ]       0  --.-KB/s               \rboundary_pinn_pretr 100%[===================>]  71.91K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-12 09:18:57 (3.35 MB/s) - ‘boundary_pinn_pretrained.pt’ saved [73634/73634]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(nb_curriculum):\n",
        "\n",
        "    print(\"------CURRICULUM TRAINING: {0}/{1}------\".format(i+1, nb_curriculum))\n",
        "\n",
        "    #update parameter values\n",
        "    zeta = zetas[i]\n",
        "    eps = epsis[i]\n",
        "\n",
        "    #load model and set optimizer\n",
        "    if i > 0:\n",
        "        checkpoint = torch.load(f'boundary_pinn_curriculum_{i}.pt')\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Scale the learning rate back up\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = learning_rate_adam  # Reset to original learning rate\n",
        "\n",
        "    else:\n",
        "        model = BoundaryPINN(power=power, width=width, depth=depth)\n",
        "        pretrained_checkpoint = torch.load('boundary_pinn_pretrained.pt')\n",
        "        model.load_state_dict(pretrained_checkpoint['model_state_dict'])\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_adam)\n",
        "\n",
        "    # Define or continue scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "        optimizer, step_size=n_epochs // n_decreases, gamma=gamma\n",
        "    )\n",
        "\n",
        "    #train model for current curriculum\n",
        "    for epoch in range(n_epochs):\n",
        "        print('EPOCH {}:'.format(epoch + 1))\n",
        "\n",
        "        # Make sure gradient tracking is on, and do a pass over the data\n",
        "        model.train(True)\n",
        "        avg_loss = train_one_epoch(model, optimizer, zeta, eps, losses[i])\n",
        "        scheduler.step()\n",
        "        print('LOSS train {}'.format(avg_loss))\n",
        "\n",
        "    #save trained model\n",
        "    torch.save({'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, f'boundary_pinn_curriculum_{i+1}.pt')\n",
        "\n",
        "    # ---- SWITCH TO L-BFGS FOR FINE-TUNING ----\n",
        "    print(\"Switching to L-BFGS for fine-tuning...\")\n",
        "\n",
        "    # Initialize L-BFGS optimizer\n",
        "    lbfgs_optimizer = torch.optim.LBFGS(model.parameters(),\n",
        "                                        max_iter=1000, # Allow more iterations\n",
        "                                        tolerance_grad=1e-8,      # Stricter gradient tolerance\n",
        "                                        tolerance_change=1e-10,   # Stricter tolerance for parameter changes\n",
        "                                        line_search_fn=\"strong_wolfe\"  # More robust line search\n",
        "                                        )\n",
        "\n",
        "    # Train one epoch with L-BFGS\n",
        "    final_loss = train_one_epoch_lbfgs(model, lbfgs_optimizer, zeta, eps, losses[i])\n",
        "\n",
        "    # Log the final loss\n",
        "    print(f\"L-BFGS fine-tuning loss: {final_loss}\")\n",
        "\n",
        "    # Save the model after L-BFGS fine-tuning\n",
        "    torch.save({'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': lbfgs_optimizer.state_dict(),\n",
        "            }, f'boundary_pinn_curriculum_{i + 1}_lbfgs.pt')"
      ],
      "metadata": {
        "id": "elzpjZUHTcFO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37d4fa03-cf45-487e-ab2e-796c409446a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "  batch 5 loss: 0.5380327746272087\n",
            "  batch 10 loss: 0.9530385971069336\n",
            "  batch 15 loss: 0.9333896040916443\n",
            "LOSS train 0.9333896040916443\n",
            "EPOCH 19002:\n",
            "  batch 5 loss: 0.6520809084177017\n",
            "  batch 10 loss: 0.34486996084451677\n",
            "  batch 15 loss: 0.6192613214254379\n",
            "LOSS train 0.6192613214254379\n",
            "EPOCH 19003:\n",
            "  batch 5 loss: 0.5801440633833408\n",
            "  batch 10 loss: 0.5450848907232284\n",
            "  batch 15 loss: 0.5160254508256912\n",
            "LOSS train 0.5160254508256912\n",
            "EPOCH 19004:\n",
            "  batch 5 loss: 1.0187730729579925\n",
            "  batch 10 loss: 0.7623232126235961\n",
            "  batch 15 loss: 0.45004794001579285\n",
            "LOSS train 0.45004794001579285\n",
            "EPOCH 19005:\n",
            "  batch 5 loss: 0.5920801520347595\n",
            "  batch 10 loss: 0.9348989456892014\n",
            "  batch 15 loss: 0.5358125656843186\n",
            "LOSS train 0.5358125656843186\n",
            "EPOCH 19006:\n",
            "  batch 5 loss: 0.9808956265449524\n",
            "  batch 10 loss: 0.7646887242794037\n",
            "  batch 15 loss: 0.6183523297309875\n",
            "LOSS train 0.6183523297309875\n",
            "EPOCH 19007:\n",
            "  batch 5 loss: 0.6212279841303825\n",
            "  batch 10 loss: 0.8803707838058472\n",
            "  batch 15 loss: 0.5758200645446777\n",
            "LOSS train 0.5758200645446777\n",
            "EPOCH 19008:\n",
            "  batch 5 loss: 0.4213692516088486\n",
            "  batch 10 loss: 0.7828654468059539\n",
            "  batch 15 loss: 0.48949774354696274\n",
            "LOSS train 0.48949774354696274\n",
            "EPOCH 19009:\n",
            "  batch 5 loss: 0.5671642415225506\n",
            "  batch 10 loss: 0.5561120353639126\n",
            "  batch 15 loss: 0.5939839541912079\n",
            "LOSS train 0.5939839541912079\n",
            "EPOCH 19010:\n",
            "  batch 5 loss: 1.0597535848617554\n",
            "  batch 10 loss: 0.810442054271698\n",
            "  batch 15 loss: 0.948201584815979\n",
            "LOSS train 0.948201584815979\n",
            "EPOCH 19011:\n",
            "  batch 5 loss: 0.6904774129390716\n",
            "  batch 10 loss: 0.6811253070831299\n",
            "  batch 15 loss: 0.6299868019297719\n",
            "LOSS train 0.6299868019297719\n",
            "EPOCH 19012:\n",
            "  batch 5 loss: 0.8579659938812256\n",
            "  batch 10 loss: 0.7912488758563996\n",
            "  batch 15 loss: 0.7825191736221313\n",
            "LOSS train 0.7825191736221313\n",
            "EPOCH 19013:\n",
            "  batch 5 loss: 0.8838074445724488\n",
            "  batch 10 loss: 0.7446626663208008\n",
            "  batch 15 loss: 0.4994774989783764\n",
            "LOSS train 0.4994774989783764\n",
            "EPOCH 19014:\n",
            "  batch 5 loss: 0.840261721611023\n",
            "  batch 10 loss: 0.7133452653884887\n",
            "  batch 15 loss: 0.4675650469958782\n",
            "LOSS train 0.4675650469958782\n",
            "EPOCH 19015:\n",
            "  batch 5 loss: 0.5102793902158738\n",
            "  batch 10 loss: 0.4327643275260925\n",
            "  batch 15 loss: 0.4898037135601044\n",
            "LOSS train 0.4898037135601044\n",
            "EPOCH 19016:\n",
            "  batch 5 loss: 0.6382030814886093\n",
            "  batch 10 loss: 0.6786917179822922\n",
            "  batch 15 loss: 0.8323790580034256\n",
            "LOSS train 0.8323790580034256\n",
            "EPOCH 19017:\n",
            "  batch 5 loss: 0.3956278271973133\n",
            "  batch 10 loss: 0.5589722633361817\n",
            "  batch 15 loss: 0.6468678034842015\n",
            "LOSS train 0.6468678034842015\n",
            "EPOCH 19018:\n",
            "  batch 5 loss: 0.7787087589502335\n",
            "  batch 10 loss: 0.49529052898287773\n",
            "  batch 15 loss: 0.5927150845527649\n",
            "LOSS train 0.5927150845527649\n",
            "EPOCH 19019:\n",
            "  batch 5 loss: 0.49623671770095823\n",
            "  batch 10 loss: 0.7754206389188767\n",
            "  batch 15 loss: 0.7726373732089996\n",
            "LOSS train 0.7726373732089996\n",
            "EPOCH 19020:\n",
            "  batch 5 loss: 0.9914393782615661\n",
            "  batch 10 loss: 0.7427451275289059\n",
            "  batch 15 loss: 0.9389264702796936\n",
            "LOSS train 0.9389264702796936\n",
            "EPOCH 19021:\n",
            "  batch 5 loss: 0.8333407759666442\n",
            "  batch 10 loss: 0.7888503551483155\n",
            "  batch 15 loss: 0.6547473579645157\n",
            "LOSS train 0.6547473579645157\n",
            "EPOCH 19022:\n",
            "  batch 5 loss: 0.9052871063351631\n",
            "  batch 10 loss: 1.058971881866455\n",
            "  batch 15 loss: 0.892126989364624\n",
            "LOSS train 0.892126989364624\n",
            "EPOCH 19023:\n",
            "  batch 5 loss: 0.4509397817775607\n",
            "  batch 10 loss: 0.5391873627901077\n",
            "  batch 15 loss: 0.6486301824450493\n",
            "LOSS train 0.6486301824450493\n",
            "EPOCH 19024:\n",
            "  batch 5 loss: 0.9591623723506928\n",
            "  batch 10 loss: 0.2718308985233307\n",
            "  batch 15 loss: 0.8418236553668976\n",
            "LOSS train 0.8418236553668976\n",
            "EPOCH 19025:\n",
            "  batch 5 loss: 0.5842857599258423\n",
            "  batch 10 loss: 0.4659589156508446\n",
            "  batch 15 loss: 0.6074842810630798\n",
            "LOSS train 0.6074842810630798\n",
            "EPOCH 19026:\n",
            "  batch 5 loss: 0.597674286365509\n",
            "  batch 10 loss: 0.5934017360210418\n",
            "  batch 15 loss: 0.3618898369371891\n",
            "LOSS train 0.3618898369371891\n",
            "EPOCH 19027:\n",
            "  batch 5 loss: 0.9286819934844971\n",
            "  batch 10 loss: 0.6326649159193038\n",
            "  batch 15 loss: 0.5287410765886307\n",
            "LOSS train 0.5287410765886307\n",
            "EPOCH 19028:\n",
            "  batch 5 loss: 0.48298201858997347\n",
            "  batch 10 loss: 0.9006748527288437\n",
            "  batch 15 loss: 0.6071295261383056\n",
            "LOSS train 0.6071295261383056\n",
            "EPOCH 19029:\n",
            "  batch 5 loss: 0.5047689933329821\n",
            "  batch 10 loss: 0.6398609519004822\n",
            "  batch 15 loss: 0.43855859637260436\n",
            "LOSS train 0.43855859637260436\n",
            "EPOCH 19030:\n",
            "  batch 5 loss: 0.745343366265297\n",
            "  batch 10 loss: 0.4394422918558121\n",
            "  batch 15 loss: 0.7695725202560425\n",
            "LOSS train 0.7695725202560425\n",
            "EPOCH 19031:\n",
            "  batch 5 loss: 0.7296496987342834\n",
            "  batch 10 loss: 0.5334255948662758\n",
            "  batch 15 loss: 0.6994285464286805\n",
            "LOSS train 0.6994285464286805\n",
            "EPOCH 19032:\n",
            "  batch 5 loss: 0.6672050833702088\n",
            "  batch 10 loss: 0.7274367272853851\n",
            "  batch 15 loss: 0.4364161156117916\n",
            "LOSS train 0.4364161156117916\n",
            "EPOCH 19033:\n",
            "  batch 5 loss: 0.5997202530503273\n",
            "  batch 10 loss: 0.6316820859909058\n",
            "  batch 15 loss: 0.964808988571167\n",
            "LOSS train 0.964808988571167\n",
            "EPOCH 19034:\n",
            "  batch 5 loss: 0.7158775329589844\n",
            "  batch 10 loss: 0.7374294221401214\n",
            "  batch 15 loss: 0.7036987960338592\n",
            "LOSS train 0.7036987960338592\n",
            "EPOCH 19035:\n",
            "  batch 5 loss: 0.8560962080955505\n",
            "  batch 10 loss: 0.6801839835941792\n",
            "  batch 15 loss: 0.8005552113056182\n",
            "LOSS train 0.8005552113056182\n",
            "EPOCH 19036:\n",
            "  batch 5 loss: 0.8700692117214203\n",
            "  batch 10 loss: 0.6851581335067749\n",
            "  batch 15 loss: 0.7699472904205322\n",
            "LOSS train 0.7699472904205322\n",
            "EPOCH 19037:\n",
            "  batch 5 loss: 0.7108607351779938\n",
            "  batch 10 loss: 0.5303693741559983\n",
            "  batch 15 loss: 0.796636039018631\n",
            "LOSS train 0.796636039018631\n",
            "EPOCH 19038:\n",
            "  batch 5 loss: 0.6774843394756317\n",
            "  batch 10 loss: 0.6047992423176766\n",
            "  batch 15 loss: 0.7196406602859498\n",
            "LOSS train 0.7196406602859498\n",
            "EPOCH 19039:\n",
            "  batch 5 loss: 0.6781588360667229\n",
            "  batch 10 loss: 0.5071456760168076\n",
            "  batch 15 loss: 0.6710271954536438\n",
            "LOSS train 0.6710271954536438\n",
            "EPOCH 19040:\n",
            "  batch 5 loss: 0.3733087807893753\n",
            "  batch 10 loss: 0.4753684774041176\n",
            "  batch 15 loss: 0.6149704784154892\n",
            "LOSS train 0.6149704784154892\n",
            "EPOCH 19041:\n",
            "  batch 5 loss: 0.876127964258194\n",
            "  batch 10 loss: 0.7327157258987427\n",
            "  batch 15 loss: 0.5835625380277634\n",
            "LOSS train 0.5835625380277634\n",
            "EPOCH 19042:\n",
            "  batch 5 loss: 0.42715792208909986\n",
            "  batch 10 loss: 0.6489053681492806\n",
            "  batch 15 loss: 0.547890753671527\n",
            "LOSS train 0.547890753671527\n",
            "EPOCH 19043:\n",
            "  batch 5 loss: 0.45399061068892477\n",
            "  batch 10 loss: 1.0488810181617736\n",
            "  batch 15 loss: 0.5150874018669128\n",
            "LOSS train 0.5150874018669128\n",
            "EPOCH 19044:\n",
            "  batch 5 loss: 0.3426901914179325\n",
            "  batch 10 loss: 0.8918904304504395\n",
            "  batch 15 loss: 0.35768639743328096\n",
            "LOSS train 0.35768639743328096\n",
            "EPOCH 19045:\n",
            "  batch 5 loss: 0.6938928514719009\n",
            "  batch 10 loss: 0.5279672801494598\n",
            "  batch 15 loss: 0.5835622012615204\n",
            "LOSS train 0.5835622012615204\n",
            "EPOCH 19046:\n",
            "  batch 5 loss: 0.7350442707538605\n",
            "  batch 10 loss: 1.148155391216278\n",
            "  batch 15 loss: 0.7267261981964112\n",
            "LOSS train 0.7267261981964112\n",
            "EPOCH 19047:\n",
            "  batch 5 loss: 0.6109148859977722\n",
            "  batch 10 loss: 0.73259197473526\n",
            "  batch 15 loss: 0.6336815029382705\n",
            "LOSS train 0.6336815029382705\n",
            "EPOCH 19048:\n",
            "  batch 5 loss: 0.6427638530731201\n",
            "  batch 10 loss: 0.8000175952911377\n",
            "  batch 15 loss: 0.5912946462631226\n",
            "LOSS train 0.5912946462631226\n",
            "EPOCH 19049:\n",
            "  batch 5 loss: 0.48502800315618516\n",
            "  batch 10 loss: 0.6049027740955353\n",
            "  batch 15 loss: 0.7812290713191032\n",
            "LOSS train 0.7812290713191032\n",
            "EPOCH 19050:\n",
            "  batch 5 loss: 0.6972330987453461\n",
            "  batch 10 loss: 0.7005241215229034\n",
            "  batch 15 loss: 0.7182430326938629\n",
            "LOSS train 0.7182430326938629\n",
            "EPOCH 19051:\n",
            "  batch 5 loss: 0.8187676787376403\n",
            "  batch 10 loss: 0.4454144097864628\n",
            "  batch 15 loss: 0.48876055181026457\n",
            "LOSS train 0.48876055181026457\n",
            "EPOCH 19052:\n",
            "  batch 5 loss: 0.6134609006345272\n",
            "  batch 10 loss: 0.8996479570865631\n",
            "  batch 15 loss: 0.830047819018364\n",
            "LOSS train 0.830047819018364\n",
            "EPOCH 19053:\n",
            "  batch 5 loss: 0.7769649714231491\n",
            "  batch 10 loss: 0.8120440915226936\n",
            "  batch 15 loss: 1.1721122503280639\n",
            "LOSS train 1.1721122503280639\n",
            "EPOCH 19054:\n",
            "  batch 5 loss: 0.3913221716880798\n",
            "  batch 10 loss: 0.378024286031723\n",
            "  batch 15 loss: 0.5339184105396271\n",
            "LOSS train 0.5339184105396271\n",
            "EPOCH 19055:\n",
            "  batch 5 loss: 1.0639488577842713\n",
            "  batch 10 loss: 0.5605010420084\n",
            "  batch 15 loss: 0.6942685067653656\n",
            "LOSS train 0.6942685067653656\n",
            "EPOCH 19056:\n",
            "  batch 5 loss: 0.49830894321203234\n",
            "  batch 10 loss: 0.506218633800745\n",
            "  batch 15 loss: 0.7033497214317321\n",
            "LOSS train 0.7033497214317321\n",
            "EPOCH 19057:\n",
            "  batch 5 loss: 0.6024288356304168\n",
            "  batch 10 loss: 0.6288917466998101\n",
            "  batch 15 loss: 0.5244758315384388\n",
            "LOSS train 0.5244758315384388\n",
            "EPOCH 19058:\n",
            "  batch 5 loss: 0.5733805179595948\n",
            "  batch 10 loss: 0.4638924106955528\n",
            "  batch 15 loss: 0.6800695300102234\n",
            "LOSS train 0.6800695300102234\n",
            "EPOCH 19059:\n",
            "  batch 5 loss: 0.6556396663188935\n",
            "  batch 10 loss: 0.6575839161872864\n",
            "  batch 15 loss: 0.785642609000206\n",
            "LOSS train 0.785642609000206\n",
            "EPOCH 19060:\n",
            "  batch 5 loss: 0.7848477981984615\n",
            "  batch 10 loss: 0.5894141852855682\n",
            "  batch 15 loss: 0.6531906940042973\n",
            "LOSS train 0.6531906940042973\n",
            "EPOCH 19061:\n",
            "  batch 5 loss: 1.1044822335243225\n",
            "  batch 10 loss: 0.7003890603780747\n",
            "  batch 15 loss: 0.8536728978157043\n",
            "LOSS train 0.8536728978157043\n",
            "EPOCH 19062:\n",
            "  batch 5 loss: 0.7251894146203994\n",
            "  batch 10 loss: 0.8875593423843384\n",
            "  batch 15 loss: 0.7101795941591262\n",
            "LOSS train 0.7101795941591262\n",
            "EPOCH 19063:\n",
            "  batch 5 loss: 0.8095386385917663\n",
            "  batch 10 loss: 0.6437635958194733\n",
            "  batch 15 loss: 0.8120148658752442\n",
            "LOSS train 0.8120148658752442\n",
            "EPOCH 19064:\n",
            "  batch 5 loss: 0.5463520854711532\n",
            "  batch 10 loss: 0.8595842599868775\n",
            "  batch 15 loss: 0.8895892143249512\n",
            "LOSS train 0.8895892143249512\n",
            "EPOCH 19065:\n",
            "  batch 5 loss: 0.6401437044143676\n",
            "  batch 10 loss: 0.5859531402587891\n",
            "  batch 15 loss: 0.6074736833572387\n",
            "LOSS train 0.6074736833572387\n",
            "EPOCH 19066:\n",
            "  batch 5 loss: 0.572150519862771\n",
            "  batch 10 loss: 0.7149837851524353\n",
            "  batch 15 loss: 0.7350875496864319\n",
            "LOSS train 0.7350875496864319\n",
            "EPOCH 19067:\n",
            "  batch 5 loss: 1.1503762006759644\n",
            "  batch 10 loss: 0.7336778998374939\n",
            "  batch 15 loss: 0.45878126174211503\n",
            "LOSS train 0.45878126174211503\n",
            "EPOCH 19068:\n",
            "  batch 5 loss: 0.41918687596917154\n",
            "  batch 10 loss: 0.8048316478729248\n",
            "  batch 15 loss: 0.6517932713031769\n",
            "LOSS train 0.6517932713031769\n",
            "EPOCH 19069:\n",
            "  batch 5 loss: 0.8521268486976623\n",
            "  batch 10 loss: 0.48410616666078565\n",
            "  batch 15 loss: 0.6122158765792847\n",
            "LOSS train 0.6122158765792847\n",
            "EPOCH 19070:\n",
            "  batch 5 loss: 0.6607787206768989\n",
            "  batch 10 loss: 0.8617910981178284\n",
            "  batch 15 loss: 0.7830901801586151\n",
            "LOSS train 0.7830901801586151\n",
            "EPOCH 19071:\n",
            "  batch 5 loss: 0.717408511042595\n",
            "  batch 10 loss: 0.7553707830607891\n",
            "  batch 15 loss: 0.9446423649787903\n",
            "LOSS train 0.9446423649787903\n",
            "EPOCH 19072:\n",
            "  batch 5 loss: 0.6542574882507324\n",
            "  batch 10 loss: 0.5161785289645195\n",
            "  batch 15 loss: 0.5977479457855225\n",
            "LOSS train 0.5977479457855225\n",
            "EPOCH 19073:\n",
            "  batch 5 loss: 0.8322588741779328\n",
            "  batch 10 loss: 0.8644669562578201\n",
            "  batch 15 loss: 0.6333858877420425\n",
            "LOSS train 0.6333858877420425\n",
            "EPOCH 19074:\n",
            "  batch 5 loss: 0.644602370262146\n",
            "  batch 10 loss: 0.7883144915103912\n",
            "  batch 15 loss: 0.26267839670181276\n",
            "LOSS train 0.26267839670181276\n",
            "EPOCH 19075:\n",
            "  batch 5 loss: 0.7153602242469788\n",
            "  batch 10 loss: 0.6126497328281403\n",
            "  batch 15 loss: 0.33938903287053107\n",
            "LOSS train 0.33938903287053107\n",
            "EPOCH 19076:\n",
            "  batch 5 loss: 0.9251535847783089\n",
            "  batch 10 loss: 0.8058269143104553\n",
            "  batch 15 loss: 0.8077771723270416\n",
            "LOSS train 0.8077771723270416\n",
            "EPOCH 19077:\n",
            "  batch 5 loss: 0.8487688064575195\n",
            "  batch 10 loss: 0.6952191829681397\n",
            "  batch 15 loss: 0.5180152386426926\n",
            "LOSS train 0.5180152386426926\n",
            "EPOCH 19078:\n",
            "  batch 5 loss: 0.6549561440944671\n",
            "  batch 10 loss: 0.495797772705555\n",
            "  batch 15 loss: 0.620602136850357\n",
            "LOSS train 0.620602136850357\n",
            "EPOCH 19079:\n",
            "  batch 5 loss: 0.6257083088159561\n",
            "  batch 10 loss: 0.7279292553663254\n",
            "  batch 15 loss: 0.7846450001001358\n",
            "LOSS train 0.7846450001001358\n",
            "EPOCH 19080:\n",
            "  batch 5 loss: 0.6136312246322632\n",
            "  batch 10 loss: 0.6745361804962158\n",
            "  batch 15 loss: 0.8942576348781586\n",
            "LOSS train 0.8942576348781586\n",
            "EPOCH 19081:\n",
            "  batch 5 loss: 0.8009272128343582\n",
            "  batch 10 loss: 0.670607316121459\n",
            "  batch 15 loss: 0.8402369618415833\n",
            "LOSS train 0.8402369618415833\n",
            "EPOCH 19082:\n",
            "  batch 5 loss: 0.8135269105434417\n",
            "  batch 10 loss: 0.6086449265480042\n",
            "  batch 15 loss: 0.9600475907325745\n",
            "LOSS train 0.9600475907325745\n",
            "EPOCH 19083:\n",
            "  batch 5 loss: 0.571973803639412\n",
            "  batch 10 loss: 0.4834653876721859\n",
            "  batch 15 loss: 0.7144600093364716\n",
            "LOSS train 0.7144600093364716\n",
            "EPOCH 19084:\n",
            "  batch 5 loss: 0.7242863059043885\n",
            "  batch 10 loss: 0.7133026510477066\n",
            "  batch 15 loss: 0.6163506209850311\n",
            "LOSS train 0.6163506209850311\n",
            "EPOCH 19085:\n",
            "  batch 5 loss: 0.5807246029376983\n",
            "  batch 10 loss: 0.8322721511125565\n",
            "  batch 15 loss: 0.49366275370121004\n",
            "LOSS train 0.49366275370121004\n",
            "EPOCH 19086:\n",
            "  batch 5 loss: 1.2090609073638916\n",
            "  batch 10 loss: 0.7950723528861999\n",
            "  batch 15 loss: 0.604924675822258\n",
            "LOSS train 0.604924675822258\n",
            "EPOCH 19087:\n",
            "  batch 5 loss: 0.9465993881225586\n",
            "  batch 10 loss: 0.5403298825025559\n",
            "  batch 15 loss: 0.6139604926109314\n",
            "LOSS train 0.6139604926109314\n",
            "EPOCH 19088:\n",
            "  batch 5 loss: 0.5273457527160644\n",
            "  batch 10 loss: 0.726498931646347\n",
            "  batch 15 loss: 0.5849539712071419\n",
            "LOSS train 0.5849539712071419\n",
            "EPOCH 19089:\n",
            "  batch 5 loss: 0.7041852958500385\n",
            "  batch 10 loss: 0.574716454744339\n",
            "  batch 15 loss: 0.8753120556473732\n",
            "LOSS train 0.8753120556473732\n",
            "EPOCH 19090:\n",
            "  batch 5 loss: 1.0914499759674072\n",
            "  batch 10 loss: 0.2937631279230118\n",
            "  batch 15 loss: 0.8983032464981079\n",
            "LOSS train 0.8983032464981079\n",
            "EPOCH 19091:\n",
            "  batch 5 loss: 0.7550138413906098\n",
            "  batch 10 loss: 0.6790614247322082\n",
            "  batch 15 loss: 0.4832326501607895\n",
            "LOSS train 0.4832326501607895\n",
            "EPOCH 19092:\n",
            "  batch 5 loss: 5.745327216386795\n",
            "  batch 10 loss: 0.5463306471705437\n",
            "  batch 15 loss: 0.7782667100429534\n",
            "LOSS train 0.7782667100429534\n",
            "EPOCH 19093:\n",
            "  batch 5 loss: 0.7845264136791229\n",
            "  batch 10 loss: 0.5979647934436798\n",
            "  batch 15 loss: 0.4674455523490906\n",
            "LOSS train 0.4674455523490906\n",
            "EPOCH 19094:\n",
            "  batch 5 loss: 0.4524445742368698\n",
            "  batch 10 loss: 0.6316776886582375\n",
            "  batch 15 loss: 0.6656712129712105\n",
            "LOSS train 0.6656712129712105\n",
            "EPOCH 19095:\n",
            "  batch 5 loss: 0.6263966023921966\n",
            "  batch 10 loss: 0.40749170929193496\n",
            "  batch 15 loss: 0.7679568570107221\n",
            "LOSS train 0.7679568570107221\n",
            "EPOCH 19096:\n",
            "  batch 5 loss: 0.5200884133577347\n",
            "  batch 10 loss: 0.7708721041679383\n",
            "  batch 15 loss: 0.3324235647916794\n",
            "LOSS train 0.3324235647916794\n",
            "EPOCH 19097:\n",
            "  batch 5 loss: 0.8502376079559326\n",
            "  batch 10 loss: 0.8976702094078064\n",
            "  batch 15 loss: 0.824697482585907\n",
            "LOSS train 0.824697482585907\n",
            "EPOCH 19098:\n",
            "  batch 5 loss: 0.9238451197743416\n",
            "  batch 10 loss: 0.6756680130958557\n",
            "  batch 15 loss: 0.5671089932322502\n",
            "LOSS train 0.5671089932322502\n",
            "EPOCH 19099:\n",
            "  batch 5 loss: 0.4068384110927582\n",
            "  batch 10 loss: 0.5799746036529541\n",
            "  batch 15 loss: 0.5562786214053631\n",
            "LOSS train 0.5562786214053631\n",
            "EPOCH 19100:\n",
            "  batch 5 loss: 0.8605483710765839\n",
            "  batch 10 loss: 0.8487104058265686\n",
            "  batch 15 loss: 0.6908647686243057\n",
            "LOSS train 0.6908647686243057\n",
            "EPOCH 19101:\n",
            "  batch 5 loss: 0.5580596387386322\n",
            "  batch 10 loss: 0.33320470303297045\n",
            "  batch 15 loss: 0.5751597091555596\n",
            "LOSS train 0.5751597091555596\n",
            "EPOCH 19102:\n",
            "  batch 5 loss: 0.8402702152729035\n",
            "  batch 10 loss: 0.34395586475729945\n",
            "  batch 15 loss: 0.8368921637535095\n",
            "LOSS train 0.8368921637535095\n",
            "EPOCH 19103:\n",
            "  batch 5 loss: 0.6340055875480175\n",
            "  batch 10 loss: 0.7354324221611023\n",
            "  batch 15 loss: 0.9237953722476959\n",
            "LOSS train 0.9237953722476959\n",
            "EPOCH 19104:\n",
            "  batch 5 loss: 1.0373745441436768\n",
            "  batch 10 loss: 0.5606315493583679\n",
            "  batch 15 loss: 0.767605347931385\n",
            "LOSS train 0.767605347931385\n",
            "EPOCH 19105:\n",
            "  batch 5 loss: 0.640980327129364\n",
            "  batch 10 loss: 0.6394407451152802\n",
            "  batch 15 loss: 0.7630951046943665\n",
            "LOSS train 0.7630951046943665\n",
            "EPOCH 19106:\n",
            "  batch 5 loss: 0.6938148975372315\n",
            "  batch 10 loss: 0.7967022761702538\n",
            "  batch 15 loss: 0.716616527736187\n",
            "LOSS train 0.716616527736187\n",
            "EPOCH 19107:\n",
            "  batch 5 loss: 1.1285239219665528\n",
            "  batch 10 loss: 0.6432245701551438\n",
            "  batch 15 loss: 0.789950042963028\n",
            "LOSS train 0.789950042963028\n",
            "EPOCH 19108:\n",
            "  batch 5 loss: 0.6905738890171051\n",
            "  batch 10 loss: 0.8531997203826904\n",
            "  batch 15 loss: 0.62915298640728\n",
            "LOSS train 0.62915298640728\n",
            "EPOCH 19109:\n",
            "  batch 5 loss: 0.9613839030265808\n",
            "  batch 10 loss: 0.7038286000490188\n",
            "  batch 15 loss: 0.5062582671642304\n",
            "LOSS train 0.5062582671642304\n",
            "EPOCH 19110:\n",
            "  batch 5 loss: 0.781112015247345\n",
            "  batch 10 loss: 0.7211061120033264\n",
            "  batch 15 loss: 0.9053300738334655\n",
            "LOSS train 0.9053300738334655\n",
            "EPOCH 19111:\n",
            "  batch 5 loss: 0.6842206418514252\n",
            "  batch 10 loss: 0.8161349415779113\n",
            "  batch 15 loss: 0.7525343298912048\n",
            "LOSS train 0.7525343298912048\n",
            "EPOCH 19112:\n",
            "  batch 5 loss: 0.6351683169603348\n",
            "  batch 10 loss: 0.9081364750862122\n",
            "  batch 15 loss: 0.94988511800766\n",
            "LOSS train 0.94988511800766\n",
            "EPOCH 19113:\n",
            "  batch 5 loss: 0.6219322979450226\n",
            "  batch 10 loss: 0.5224938541650772\n",
            "  batch 15 loss: 0.8750604391098022\n",
            "LOSS train 0.8750604391098022\n",
            "EPOCH 19114:\n",
            "  batch 5 loss: 0.40908346474170687\n",
            "  batch 10 loss: 1.1361198902130127\n",
            "  batch 15 loss: 0.28813790939748285\n",
            "LOSS train 0.28813790939748285\n",
            "EPOCH 19115:\n",
            "  batch 5 loss: 0.32212470173835756\n",
            "  batch 10 loss: 0.6326692640781403\n",
            "  batch 15 loss: 0.8474771618843079\n",
            "LOSS train 0.8474771618843079\n",
            "EPOCH 19116:\n",
            "  batch 5 loss: 0.7051829934120178\n",
            "  batch 10 loss: 0.461803737282753\n",
            "  batch 15 loss: 0.9277214348316193\n",
            "LOSS train 0.9277214348316193\n",
            "EPOCH 19117:\n",
            "  batch 5 loss: 0.7314200818538665\n",
            "  batch 10 loss: 0.8077621668577194\n",
            "  batch 15 loss: 0.6930133640766144\n",
            "LOSS train 0.6930133640766144\n",
            "EPOCH 19118:\n",
            "  batch 5 loss: 0.7528490841388702\n",
            "  batch 10 loss: 0.7523133158683777\n",
            "  batch 15 loss: 0.9132295370101928\n",
            "LOSS train 0.9132295370101928\n",
            "EPOCH 19119:\n",
            "  batch 5 loss: 0.6400159150362015\n",
            "  batch 10 loss: 0.3708838015794754\n",
            "  batch 15 loss: 0.6773019343614578\n",
            "LOSS train 0.6773019343614578\n",
            "EPOCH 19120:\n",
            "  batch 5 loss: 0.36194212138652804\n",
            "  batch 10 loss: 0.5549811244010925\n",
            "  batch 15 loss: 0.7376311779022217\n",
            "LOSS train 0.7376311779022217\n",
            "EPOCH 19121:\n",
            "  batch 5 loss: 0.8942273259162903\n",
            "  batch 10 loss: 0.6361664652824401\n",
            "  batch 15 loss: 2.020328864455223\n",
            "LOSS train 2.020328864455223\n",
            "EPOCH 19122:\n",
            "  batch 5 loss: 0.49527754485607145\n",
            "  batch 10 loss: 0.8035859107971192\n",
            "  batch 15 loss: 0.6395804636180401\n",
            "LOSS train 0.6395804636180401\n",
            "EPOCH 19123:\n",
            "  batch 5 loss: 0.8377008438110352\n",
            "  batch 10 loss: 0.3836654555052519\n",
            "  batch 15 loss: 0.69099560379982\n",
            "LOSS train 0.69099560379982\n",
            "EPOCH 19124:\n",
            "  batch 5 loss: 0.6267463803291321\n",
            "  batch 10 loss: 0.9893259167671203\n",
            "  batch 15 loss: 0.41271487474441526\n",
            "LOSS train 0.41271487474441526\n",
            "EPOCH 19125:\n",
            "  batch 5 loss: 0.6594065427780151\n",
            "  batch 10 loss: 0.6710143566131592\n",
            "  batch 15 loss: 0.3496276676654816\n",
            "LOSS train 0.3496276676654816\n",
            "EPOCH 19126:\n",
            "  batch 5 loss: 0.6237094461917877\n",
            "  batch 10 loss: 0.5571637943387031\n",
            "  batch 15 loss: 0.8305635750293732\n",
            "LOSS train 0.8305635750293732\n",
            "EPOCH 19127:\n",
            "  batch 5 loss: 0.29632602967321875\n",
            "  batch 10 loss: 0.7022744998335838\n",
            "  batch 15 loss: 0.8222289502620697\n",
            "LOSS train 0.8222289502620697\n",
            "EPOCH 19128:\n",
            "  batch 5 loss: 0.9142223596572876\n",
            "  batch 10 loss: 0.6663161233067513\n",
            "  batch 15 loss: 0.7287788599729538\n",
            "LOSS train 0.7287788599729538\n",
            "EPOCH 19129:\n",
            "  batch 5 loss: 0.7239380002021789\n",
            "  batch 10 loss: 0.5644209146499634\n",
            "  batch 15 loss: 0.3424304097890854\n",
            "LOSS train 0.3424304097890854\n",
            "EPOCH 19130:\n",
            "  batch 5 loss: 0.5846915930509567\n",
            "  batch 10 loss: 0.7148620992898941\n",
            "  batch 15 loss: 0.7374529838562012\n",
            "LOSS train 0.7374529838562012\n",
            "EPOCH 19131:\n",
            "  batch 5 loss: 0.9438393354415894\n",
            "  batch 10 loss: 0.8049837410449981\n",
            "  batch 15 loss: 0.8907870650291443\n",
            "LOSS train 0.8907870650291443\n",
            "EPOCH 19132:\n",
            "  batch 5 loss: 0.7728770196437835\n",
            "  batch 10 loss: 0.6534670442342758\n",
            "  batch 15 loss: 0.8297415494918823\n",
            "LOSS train 0.8297415494918823\n",
            "EPOCH 19133:\n",
            "  batch 5 loss: 0.8069773256778717\n",
            "  batch 10 loss: 0.7023579597473144\n",
            "  batch 15 loss: 0.7555253028869628\n",
            "LOSS train 0.7555253028869628\n",
            "EPOCH 19134:\n",
            "  batch 5 loss: 0.9067862749099731\n",
            "  batch 10 loss: 0.6876403748989105\n",
            "  batch 15 loss: 0.9282958626747131\n",
            "LOSS train 0.9282958626747131\n",
            "EPOCH 19135:\n",
            "  batch 5 loss: 0.6567635700106621\n",
            "  batch 10 loss: 0.22299056574702264\n",
            "  batch 15 loss: 1.2036354184150695\n",
            "LOSS train 1.2036354184150695\n",
            "EPOCH 19136:\n",
            "  batch 5 loss: 0.6191453814506531\n",
            "  batch 10 loss: 0.6945866823196412\n",
            "  batch 15 loss: 0.8431103348731994\n",
            "LOSS train 0.8431103348731994\n",
            "EPOCH 19137:\n",
            "  batch 5 loss: 0.624020767211914\n",
            "  batch 10 loss: 0.5935950458049775\n",
            "  batch 15 loss: 0.38142032623291017\n",
            "LOSS train 0.38142032623291017\n",
            "EPOCH 19138:\n",
            "  batch 5 loss: 0.6735194563865662\n",
            "  batch 10 loss: 0.4571861304342747\n",
            "  batch 15 loss: 0.9810776114463806\n",
            "LOSS train 0.9810776114463806\n",
            "EPOCH 19139:\n",
            "  batch 5 loss: 0.8326488226652146\n",
            "  batch 10 loss: 0.6577354371547699\n",
            "  batch 15 loss: 0.8265956282615662\n",
            "LOSS train 0.8265956282615662\n",
            "EPOCH 19140:\n",
            "  batch 5 loss: 0.6907163292169571\n",
            "  batch 10 loss: 0.4634457603096962\n",
            "  batch 15 loss: 0.526425251364708\n",
            "LOSS train 0.526425251364708\n",
            "EPOCH 19141:\n",
            "  batch 5 loss: 0.8833902418613434\n",
            "  batch 10 loss: 0.8574818134307861\n",
            "  batch 15 loss: 0.8367169708013534\n",
            "LOSS train 0.8367169708013534\n",
            "EPOCH 19142:\n",
            "  batch 5 loss: 0.956221091747284\n",
            "  batch 10 loss: 0.6557472467422485\n",
            "  batch 15 loss: 0.8201278388500214\n",
            "LOSS train 0.8201278388500214\n",
            "EPOCH 19143:\n",
            "  batch 5 loss: 0.6961703300476074\n",
            "  batch 10 loss: 0.5816561847925186\n",
            "  batch 15 loss: 0.5899890109896659\n",
            "LOSS train 0.5899890109896659\n",
            "EPOCH 19144:\n",
            "  batch 5 loss: 0.6816445469856263\n",
            "  batch 10 loss: 0.9251713752746582\n",
            "  batch 15 loss: 0.5502961620688438\n",
            "LOSS train 0.5502961620688438\n",
            "EPOCH 19145:\n",
            "  batch 5 loss: 0.7808418989181518\n",
            "  batch 10 loss: 0.7443077594041825\n",
            "  batch 15 loss: 0.6484806597232818\n",
            "LOSS train 0.6484806597232818\n",
            "EPOCH 19146:\n",
            "  batch 5 loss: 0.5430781811475753\n",
            "  batch 10 loss: 0.5516921162605286\n",
            "  batch 15 loss: 0.520374234765768\n",
            "LOSS train 0.520374234765768\n",
            "EPOCH 19147:\n",
            "  batch 5 loss: 1.0545034676790237\n",
            "  batch 10 loss: 0.796965765953064\n",
            "  batch 15 loss: 0.5146226616576314\n",
            "LOSS train 0.5146226616576314\n",
            "EPOCH 19148:\n",
            "  batch 5 loss: 0.7077021777629853\n",
            "  batch 10 loss: 0.7510425209999084\n",
            "  batch 15 loss: 0.8382500350475312\n",
            "LOSS train 0.8382500350475312\n",
            "EPOCH 19149:\n",
            "  batch 5 loss: 0.6987128615379333\n",
            "  batch 10 loss: 0.44879370629787446\n",
            "  batch 15 loss: 0.5616177320480347\n",
            "LOSS train 0.5616177320480347\n",
            "EPOCH 19150:\n",
            "  batch 5 loss: 0.7985158771276474\n",
            "  batch 10 loss: 0.8058876991271973\n",
            "  batch 15 loss: 0.5075449287891388\n",
            "LOSS train 0.5075449287891388\n",
            "EPOCH 19151:\n",
            "  batch 5 loss: 0.7589061677455902\n",
            "  batch 10 loss: 0.8960801005363465\n",
            "  batch 15 loss: 0.9442102193832398\n",
            "LOSS train 0.9442102193832398\n",
            "EPOCH 19152:\n",
            "  batch 5 loss: 0.6755889236927033\n",
            "  batch 10 loss: 0.6330843806266785\n",
            "  batch 15 loss: 0.6541716098785401\n",
            "LOSS train 0.6541716098785401\n",
            "EPOCH 19153:\n",
            "  batch 5 loss: 0.7058263778686523\n",
            "  batch 10 loss: 0.5362688362598419\n",
            "  batch 15 loss: 0.5540531128644943\n",
            "LOSS train 0.5540531128644943\n",
            "EPOCH 19154:\n",
            "  batch 5 loss: 0.8676760703325271\n",
            "  batch 10 loss: 0.8232388496398926\n",
            "  batch 15 loss: 0.6951025605201722\n",
            "LOSS train 0.6951025605201722\n",
            "EPOCH 19155:\n",
            "  batch 5 loss: 0.7467279702425003\n",
            "  batch 10 loss: 0.6149203240871429\n",
            "  batch 15 loss: 0.7948880791664124\n",
            "LOSS train 0.7948880791664124\n",
            "EPOCH 19156:\n",
            "  batch 5 loss: 0.6227055639028549\n",
            "  batch 10 loss: 0.6660465657711029\n",
            "  batch 15 loss: 0.722683972120285\n",
            "LOSS train 0.722683972120285\n",
            "EPOCH 19157:\n",
            "  batch 5 loss: 0.7140761554241181\n",
            "  batch 10 loss: 1.0776729345321656\n",
            "  batch 15 loss: 0.5963617771863937\n",
            "LOSS train 0.5963617771863937\n",
            "EPOCH 19158:\n",
            "  batch 5 loss: 0.7082287847995759\n",
            "  batch 10 loss: 0.5834464102983474\n",
            "  batch 15 loss: 0.8389585614204407\n",
            "LOSS train 0.8389585614204407\n",
            "EPOCH 19159:\n",
            "  batch 5 loss: 0.954738712310791\n",
            "  batch 10 loss: 0.41256852746009826\n",
            "  batch 15 loss: 0.7316616237163543\n",
            "LOSS train 0.7316616237163543\n",
            "EPOCH 19160:\n",
            "  batch 5 loss: 0.9855209827423096\n",
            "  batch 10 loss: 0.559690061211586\n",
            "  batch 15 loss: 0.6428082108497619\n",
            "LOSS train 0.6428082108497619\n",
            "EPOCH 19161:\n",
            "  batch 5 loss: 0.8637365281581879\n",
            "  batch 10 loss: 0.8007993340492249\n",
            "  batch 15 loss: 0.9501433789730072\n",
            "LOSS train 0.9501433789730072\n",
            "EPOCH 19162:\n",
            "  batch 5 loss: 0.7336636543273926\n",
            "  batch 10 loss: 0.7513002187013627\n",
            "  batch 15 loss: 0.4795811325311661\n",
            "LOSS train 0.4795811325311661\n",
            "EPOCH 19163:\n",
            "  batch 5 loss: 0.7817106306552887\n",
            "  batch 10 loss: 0.632430699467659\n",
            "  batch 15 loss: 0.8277080178260803\n",
            "LOSS train 0.8277080178260803\n",
            "EPOCH 19164:\n",
            "  batch 5 loss: 1.134477400779724\n",
            "  batch 10 loss: 0.8070896863937378\n",
            "  batch 15 loss: 0.8828197240829467\n",
            "LOSS train 0.8828197240829467\n",
            "EPOCH 19165:\n",
            "  batch 5 loss: 0.7609759241342544\n",
            "  batch 10 loss: 0.7532439202070236\n",
            "  batch 15 loss: 0.5632881999015809\n",
            "LOSS train 0.5632881999015809\n",
            "EPOCH 19166:\n",
            "  batch 5 loss: 0.6444176495075226\n",
            "  batch 10 loss: 0.6082668155431747\n",
            "  batch 15 loss: 0.6894439488649369\n",
            "LOSS train 0.6894439488649369\n",
            "EPOCH 19167:\n",
            "  batch 5 loss: 0.6056412190198899\n",
            "  batch 10 loss: 1.188676154613495\n",
            "  batch 15 loss: 0.7048472046852112\n",
            "LOSS train 0.7048472046852112\n",
            "EPOCH 19168:\n",
            "  batch 5 loss: 0.6241137623786926\n",
            "  batch 10 loss: 0.8793317914009094\n",
            "  batch 15 loss: 0.761073237657547\n",
            "LOSS train 0.761073237657547\n",
            "EPOCH 19169:\n",
            "  batch 5 loss: 0.676316249370575\n",
            "  batch 10 loss: 0.5779233515262604\n",
            "  batch 15 loss: 0.5329175055027008\n",
            "LOSS train 0.5329175055027008\n",
            "EPOCH 19170:\n",
            "  batch 5 loss: 0.7314688980579376\n",
            "  batch 10 loss: 0.38522948920726774\n",
            "  batch 15 loss: 0.5731648743152619\n",
            "LOSS train 0.5731648743152619\n",
            "EPOCH 19171:\n",
            "  batch 5 loss: 0.884673896431923\n",
            "  batch 10 loss: 0.7849125385284423\n",
            "  batch 15 loss: 0.6151881769299508\n",
            "LOSS train 0.6151881769299508\n",
            "EPOCH 19172:\n",
            "  batch 5 loss: 0.8180813193321228\n",
            "  batch 10 loss: 0.9734652638435364\n",
            "  batch 15 loss: 0.9264020711183548\n",
            "LOSS train 0.9264020711183548\n",
            "EPOCH 19173:\n",
            "  batch 5 loss: 0.7007478028535843\n",
            "  batch 10 loss: 1.0911359667778016\n",
            "  batch 15 loss: 0.9556939959526062\n",
            "LOSS train 0.9556939959526062\n",
            "EPOCH 19174:\n",
            "  batch 5 loss: 0.6988358974456788\n",
            "  batch 10 loss: 0.732952105998993\n",
            "  batch 15 loss: 0.6961413085460663\n",
            "LOSS train 0.6961413085460663\n",
            "EPOCH 19175:\n",
            "  batch 5 loss: 0.5751323372125625\n",
            "  batch 10 loss: 0.2540903680026531\n",
            "  batch 15 loss: 1.0040978789329529\n",
            "LOSS train 1.0040978789329529\n",
            "EPOCH 19176:\n",
            "  batch 5 loss: 0.8735368847846985\n",
            "  batch 10 loss: 0.6250415944494307\n",
            "  batch 15 loss: 1.0481778174638747\n",
            "LOSS train 1.0481778174638747\n",
            "EPOCH 19177:\n",
            "  batch 5 loss: 0.6316340746358037\n",
            "  batch 10 loss: 0.9431070804595947\n",
            "  batch 15 loss: 0.858961433172226\n",
            "LOSS train 0.858961433172226\n",
            "EPOCH 19178:\n",
            "  batch 5 loss: 0.7177301496267319\n",
            "  batch 10 loss: 0.8273897111415863\n",
            "  batch 15 loss: 0.9420500993728638\n",
            "LOSS train 0.9420500993728638\n",
            "EPOCH 19179:\n",
            "  batch 5 loss: 0.5851268708705902\n",
            "  batch 10 loss: 0.788518738746643\n",
            "  batch 15 loss: 0.925307160615921\n",
            "LOSS train 0.925307160615921\n",
            "EPOCH 19180:\n",
            "  batch 5 loss: 0.6662837795913219\n",
            "  batch 10 loss: 0.4755205363035202\n",
            "  batch 15 loss: 1.096998679637909\n",
            "LOSS train 1.096998679637909\n",
            "EPOCH 19181:\n",
            "  batch 5 loss: 0.5177985608577729\n",
            "  batch 10 loss: 0.5508944675326347\n",
            "  batch 15 loss: 0.6001995816826821\n",
            "LOSS train 0.6001995816826821\n",
            "EPOCH 19182:\n",
            "  batch 5 loss: 0.46310451328754426\n",
            "  batch 10 loss: 0.7206572726368904\n",
            "  batch 15 loss: 0.5851392094045877\n",
            "LOSS train 0.5851392094045877\n",
            "EPOCH 19183:\n",
            "  batch 5 loss: 0.5945666067302227\n",
            "  batch 10 loss: 0.7656775265932083\n",
            "  batch 15 loss: 0.9170332312583923\n",
            "LOSS train 0.9170332312583923\n",
            "EPOCH 19184:\n",
            "  batch 5 loss: 0.8417991042137146\n",
            "  batch 10 loss: 0.7927442282438278\n",
            "  batch 15 loss: 0.5121916353702545\n",
            "LOSS train 0.5121916353702545\n",
            "EPOCH 19185:\n",
            "  batch 5 loss: 0.39289531409740447\n",
            "  batch 10 loss: 0.6238027662038803\n",
            "  batch 15 loss: 0.6937707424163818\n",
            "LOSS train 0.6937707424163818\n",
            "EPOCH 19186:\n",
            "  batch 5 loss: 0.7514555811882019\n",
            "  batch 10 loss: 0.848333477973938\n",
            "  batch 15 loss: 0.743826511502266\n",
            "LOSS train 0.743826511502266\n",
            "EPOCH 19187:\n",
            "  batch 5 loss: 0.37284421920776367\n",
            "  batch 10 loss: 0.6951170027256012\n",
            "  batch 15 loss: 0.8162161350250244\n",
            "LOSS train 0.8162161350250244\n",
            "EPOCH 19188:\n",
            "  batch 5 loss: 0.6160936176776886\n",
            "  batch 10 loss: 0.7563569664955139\n",
            "  batch 15 loss: 0.9097696423530579\n",
            "LOSS train 0.9097696423530579\n",
            "EPOCH 19189:\n",
            "  batch 5 loss: 0.5191233813762665\n",
            "  batch 10 loss: 0.7864551842212677\n",
            "  batch 15 loss: 0.6052972055971623\n",
            "LOSS train 0.6052972055971623\n",
            "EPOCH 19190:\n",
            "  batch 5 loss: 0.6555106937885284\n",
            "  batch 10 loss: 0.9418109297752381\n",
            "  batch 15 loss: 0.9170519649982453\n",
            "LOSS train 0.9170519649982453\n",
            "EPOCH 19191:\n",
            "  batch 5 loss: 0.6752793937921524\n",
            "  batch 10 loss: 0.7860902070999145\n",
            "  batch 15 loss: 0.5557060182094574\n",
            "LOSS train 0.5557060182094574\n",
            "EPOCH 19192:\n",
            "  batch 5 loss: 0.7132692337036133\n",
            "  batch 10 loss: 0.7260374814271927\n",
            "  batch 15 loss: 1.0822471737861634\n",
            "LOSS train 1.0822471737861634\n",
            "EPOCH 19193:\n",
            "  batch 5 loss: 0.8577903866767883\n",
            "  batch 10 loss: 0.451795569807291\n",
            "  batch 15 loss: 0.9055993780493736\n",
            "LOSS train 0.9055993780493736\n",
            "EPOCH 19194:\n",
            "  batch 5 loss: 0.8403888374567032\n",
            "  batch 10 loss: 0.6790813684463501\n",
            "  batch 15 loss: 0.8438489317893982\n",
            "LOSS train 0.8438489317893982\n",
            "EPOCH 19195:\n",
            "  batch 5 loss: 0.7707746028900146\n",
            "  batch 10 loss: 0.7759565711021423\n",
            "  batch 15 loss: 0.4272037699818611\n",
            "LOSS train 0.4272037699818611\n",
            "EPOCH 19196:\n",
            "  batch 5 loss: 0.8257522463798523\n",
            "  batch 10 loss: 0.5911287307739258\n",
            "  batch 15 loss: 0.7592291057109832\n",
            "LOSS train 0.7592291057109832\n",
            "EPOCH 19197:\n",
            "  batch 5 loss: 0.6500473007559776\n",
            "  batch 10 loss: 1.191975474357605\n",
            "  batch 15 loss: 0.6205325156450272\n",
            "LOSS train 0.6205325156450272\n",
            "EPOCH 19198:\n",
            "  batch 5 loss: 0.7748182371258736\n",
            "  batch 10 loss: 0.9374252319335937\n",
            "  batch 15 loss: 0.8553294539451599\n",
            "LOSS train 0.8553294539451599\n",
            "EPOCH 19199:\n",
            "  batch 5 loss: 0.823095953464508\n",
            "  batch 10 loss: 0.6921565100550652\n",
            "  batch 15 loss: 0.3182954493910074\n",
            "LOSS train 0.3182954493910074\n",
            "EPOCH 19200:\n",
            "  batch 5 loss: 0.5313690640032291\n",
            "  batch 10 loss: 0.6238676965236664\n",
            "  batch 15 loss: 0.5614310279488564\n",
            "LOSS train 0.5614310279488564\n",
            "EPOCH 19201:\n",
            "  batch 5 loss: 0.32539588809013364\n",
            "  batch 10 loss: 0.6220308601856231\n",
            "  batch 15 loss: 0.35272945910692216\n",
            "LOSS train 0.35272945910692216\n",
            "EPOCH 19202:\n",
            "  batch 5 loss: 0.8038443565368653\n",
            "  batch 10 loss: 0.7032129287719726\n",
            "  batch 15 loss: 0.4449925467371941\n",
            "LOSS train 0.4449925467371941\n",
            "EPOCH 19203:\n",
            "  batch 5 loss: 0.7442619234323502\n",
            "  batch 10 loss: 0.8836779117584228\n",
            "  batch 15 loss: 0.8012497663497925\n",
            "LOSS train 0.8012497663497925\n",
            "EPOCH 19204:\n",
            "  batch 5 loss: 0.8963243961334229\n",
            "  batch 10 loss: 0.5453696586191654\n",
            "  batch 15 loss: 0.8601888030767441\n",
            "LOSS train 0.8601888030767441\n",
            "EPOCH 19205:\n",
            "  batch 5 loss: 1.030285906791687\n",
            "  batch 10 loss: 0.6318599417805671\n",
            "  batch 15 loss: 1.0937870025634766\n",
            "LOSS train 1.0937870025634766\n",
            "EPOCH 19206:\n",
            "  batch 5 loss: 0.6066194295883178\n",
            "  batch 10 loss: 0.6174998760223389\n",
            "  batch 15 loss: 0.564579650759697\n",
            "LOSS train 0.564579650759697\n",
            "EPOCH 19207:\n",
            "  batch 5 loss: 0.7536640495061875\n",
            "  batch 10 loss: 0.6977614879608154\n",
            "  batch 15 loss: 0.8364587247371673\n",
            "LOSS train 0.8364587247371673\n",
            "EPOCH 19208:\n",
            "  batch 5 loss: 0.3104501821100712\n",
            "  batch 10 loss: 0.6342923223972321\n",
            "  batch 15 loss: 0.7538743555545807\n",
            "LOSS train 0.7538743555545807\n",
            "EPOCH 19209:\n",
            "  batch 5 loss: 0.6953253030776978\n",
            "  batch 10 loss: 0.2430299550294876\n",
            "  batch 15 loss: 0.7039076328277588\n",
            "LOSS train 0.7039076328277588\n",
            "EPOCH 19210:\n",
            "  batch 5 loss: 0.6390544757246971\n",
            "  batch 10 loss: 0.9148968100547791\n",
            "  batch 15 loss: 1.0466532349586486\n",
            "LOSS train 1.0466532349586486\n",
            "EPOCH 19211:\n",
            "  batch 5 loss: 0.5339073821902275\n",
            "  batch 10 loss: 0.6998599469661713\n",
            "  batch 15 loss: 0.6130709707736969\n",
            "LOSS train 0.6130709707736969\n",
            "EPOCH 19212:\n",
            "  batch 5 loss: 0.590599387139082\n",
            "  batch 10 loss: 0.7944196164608002\n",
            "  batch 15 loss: 0.7430422455072403\n",
            "LOSS train 0.7430422455072403\n",
            "EPOCH 19213:\n",
            "  batch 5 loss: 0.8069211602210998\n",
            "  batch 10 loss: 0.7381998658180237\n",
            "  batch 15 loss: 0.5023624420166015\n",
            "LOSS train 0.5023624420166015\n",
            "EPOCH 19214:\n",
            "  batch 5 loss: 0.9064652740955352\n",
            "  batch 10 loss: 0.9658458948135376\n",
            "  batch 15 loss: 0.5336228311061859\n",
            "LOSS train 0.5336228311061859\n",
            "EPOCH 19215:\n",
            "  batch 5 loss: 0.4585856504738331\n",
            "  batch 10 loss: 0.8957635074853897\n",
            "  batch 15 loss: 0.5881424576044083\n",
            "LOSS train 0.5881424576044083\n",
            "EPOCH 19216:\n",
            "  batch 5 loss: 0.534758061170578\n",
            "  batch 10 loss: 0.7686945199966431\n",
            "  batch 15 loss: 0.7216383442282677\n",
            "LOSS train 0.7216383442282677\n",
            "EPOCH 19217:\n",
            "  batch 5 loss: 0.9983628392219543\n",
            "  batch 10 loss: 0.5952257513999939\n",
            "  batch 15 loss: 0.7199658200144767\n",
            "LOSS train 0.7199658200144767\n",
            "EPOCH 19218:\n",
            "  batch 5 loss: 0.5307111322879792\n",
            "  batch 10 loss: 0.7220862373709679\n",
            "  batch 15 loss: 0.5529631793498992\n",
            "LOSS train 0.5529631793498992\n",
            "EPOCH 19219:\n",
            "  batch 5 loss: 0.7647329926490783\n",
            "  batch 10 loss: 0.725815749168396\n",
            "  batch 15 loss: 0.733671247959137\n",
            "LOSS train 0.733671247959137\n",
            "EPOCH 19220:\n",
            "  batch 5 loss: 0.5517659902572631\n",
            "  batch 10 loss: 0.5918820381164551\n",
            "  batch 15 loss: 0.7883618295192718\n",
            "LOSS train 0.7883618295192718\n",
            "EPOCH 19221:\n",
            "  batch 5 loss: 0.5996135205030442\n",
            "  batch 10 loss: 0.5411836251616478\n",
            "  batch 15 loss: 0.43540040850639344\n",
            "LOSS train 0.43540040850639344\n",
            "EPOCH 19222:\n",
            "  batch 5 loss: 0.6788103166967631\n",
            "  batch 10 loss: 1.1181940674781798\n",
            "  batch 15 loss: 0.5448553159832954\n",
            "LOSS train 0.5448553159832954\n",
            "EPOCH 19223:\n",
            "  batch 5 loss: 0.9446567893028259\n",
            "  batch 10 loss: 1.0789304494857788\n",
            "  batch 15 loss: 0.6482330977916717\n",
            "LOSS train 0.6482330977916717\n",
            "EPOCH 19224:\n",
            "  batch 5 loss: 0.5963226012885571\n",
            "  batch 10 loss: 0.8570884823799133\n",
            "  batch 15 loss: 0.44170109964907167\n",
            "LOSS train 0.44170109964907167\n",
            "EPOCH 19225:\n",
            "  batch 5 loss: 0.38366078957915306\n",
            "  batch 10 loss: 0.9283570766448974\n",
            "  batch 15 loss: 1.0242865085601807\n",
            "LOSS train 1.0242865085601807\n",
            "EPOCH 19226:\n",
            "  batch 5 loss: 0.815394377708435\n",
            "  batch 10 loss: 0.5000767335295677\n",
            "  batch 15 loss: 0.8202492952346802\n",
            "LOSS train 0.8202492952346802\n",
            "EPOCH 19227:\n",
            "  batch 5 loss: 0.4693403035402298\n",
            "  batch 10 loss: 0.8539019525051117\n",
            "  batch 15 loss: 0.8128951847553253\n",
            "LOSS train 0.8128951847553253\n",
            "EPOCH 19228:\n",
            "  batch 5 loss: 0.5897221177816391\n",
            "  batch 10 loss: 0.6745287835597992\n",
            "  batch 15 loss: 0.8429688036441803\n",
            "LOSS train 0.8429688036441803\n",
            "EPOCH 19229:\n",
            "  batch 5 loss: 0.6184913158416748\n",
            "  batch 10 loss: 0.45200750678777696\n",
            "  batch 15 loss: 0.6913998126983643\n",
            "LOSS train 0.6913998126983643\n",
            "EPOCH 19230:\n",
            "  batch 5 loss: 0.6165781736373901\n",
            "  batch 10 loss: 0.9198726058006287\n",
            "  batch 15 loss: 0.8456586956977844\n",
            "LOSS train 0.8456586956977844\n",
            "EPOCH 19231:\n",
            "  batch 5 loss: 0.59012640863657\n",
            "  batch 10 loss: 0.7980598747730255\n",
            "  batch 15 loss: 0.6977349549531937\n",
            "LOSS train 0.6977349549531937\n",
            "EPOCH 19232:\n",
            "  batch 5 loss: 0.7770371794700622\n",
            "  batch 10 loss: 0.5082526430487633\n",
            "  batch 15 loss: 0.6234507046639919\n",
            "LOSS train 0.6234507046639919\n",
            "EPOCH 19233:\n",
            "  batch 5 loss: 0.9730112195014954\n",
            "  batch 10 loss: 0.38542024940252306\n",
            "  batch 15 loss: 0.7643099308013916\n",
            "LOSS train 0.7643099308013916\n",
            "EPOCH 19234:\n",
            "  batch 5 loss: 0.6603645913302898\n",
            "  batch 10 loss: 0.967862355709076\n",
            "  batch 15 loss: 0.6419841460883617\n",
            "LOSS train 0.6419841460883617\n",
            "EPOCH 19235:\n",
            "  batch 5 loss: 0.7374281525611878\n",
            "  batch 10 loss: 0.8452470302581787\n",
            "  batch 15 loss: 0.7057572364807129\n",
            "LOSS train 0.7057572364807129\n",
            "EPOCH 19236:\n",
            "  batch 5 loss: 0.7011399090290069\n",
            "  batch 10 loss: 0.4166025683283806\n",
            "  batch 15 loss: 0.8230021372437477\n",
            "LOSS train 0.8230021372437477\n",
            "EPOCH 19237:\n",
            "  batch 5 loss: 1.0154337286949158\n",
            "  batch 10 loss: 0.9448314785957337\n",
            "  batch 15 loss: 0.7622458547353744\n",
            "LOSS train 0.7622458547353744\n",
            "EPOCH 19238:\n",
            "  batch 5 loss: 1.0417329490184783\n",
            "  batch 10 loss: 0.8778993010520935\n",
            "  batch 15 loss: 0.5664037585258483\n",
            "LOSS train 0.5664037585258483\n",
            "EPOCH 19239:\n",
            "  batch 5 loss: 0.9648426294326782\n",
            "  batch 10 loss: 0.7341826021671295\n",
            "  batch 15 loss: 0.782222443819046\n",
            "LOSS train 0.782222443819046\n",
            "EPOCH 19240:\n",
            "  batch 5 loss: 0.5141266763210297\n",
            "  batch 10 loss: 0.7566507637500763\n",
            "  batch 15 loss: 0.8711443960666656\n",
            "LOSS train 0.8711443960666656\n",
            "EPOCH 19241:\n",
            "  batch 5 loss: 1.1628816843032836\n",
            "  batch 10 loss: 0.7212976932525634\n",
            "  batch 15 loss: 0.9674115210771561\n",
            "LOSS train 0.9674115210771561\n",
            "EPOCH 19242:\n",
            "  batch 5 loss: 0.6654359310865402\n",
            "  batch 10 loss: 0.4768137838691473\n",
            "  batch 15 loss: 0.7728235721588135\n",
            "LOSS train 0.7728235721588135\n",
            "EPOCH 19243:\n",
            "  batch 5 loss: 0.6254764854907989\n",
            "  batch 10 loss: 2.214885926246643\n",
            "  batch 15 loss: 0.8434021890163421\n",
            "LOSS train 0.8434021890163421\n",
            "EPOCH 19244:\n",
            "  batch 5 loss: 0.8249741315841674\n",
            "  batch 10 loss: 0.8788947939872742\n",
            "  batch 15 loss: 0.8510367155075074\n",
            "LOSS train 0.8510367155075074\n",
            "EPOCH 19245:\n",
            "  batch 5 loss: 0.657060070335865\n",
            "  batch 10 loss: 1.0263951390981674\n",
            "  batch 15 loss: 0.7281281352043152\n",
            "LOSS train 0.7281281352043152\n",
            "EPOCH 19246:\n",
            "  batch 5 loss: 0.6073755323886871\n",
            "  batch 10 loss: 0.6986304491758346\n",
            "  batch 15 loss: 0.4518112659454346\n",
            "LOSS train 0.4518112659454346\n",
            "EPOCH 19247:\n",
            "  batch 5 loss: 0.624437826871872\n",
            "  batch 10 loss: 0.6602819800376892\n",
            "  batch 15 loss: 0.8452231287956238\n",
            "LOSS train 0.8452231287956238\n",
            "EPOCH 19248:\n",
            "  batch 5 loss: 0.6617996960878372\n",
            "  batch 10 loss: 0.6700428903102875\n",
            "  batch 15 loss: 0.33340988755226136\n",
            "LOSS train 0.33340988755226136\n",
            "EPOCH 19249:\n",
            "  batch 5 loss: 0.7536770761013031\n",
            "  batch 10 loss: 0.8506761074066163\n",
            "  batch 15 loss: 0.9620459675788879\n",
            "LOSS train 0.9620459675788879\n",
            "EPOCH 19250:\n",
            "  batch 5 loss: 0.6575657874345779\n",
            "  batch 10 loss: 0.544496163725853\n",
            "  batch 15 loss: 0.4751400947570801\n",
            "LOSS train 0.4751400947570801\n",
            "EPOCH 19251:\n",
            "  batch 5 loss: 0.26695531606674194\n",
            "  batch 10 loss: 0.6000475481152534\n",
            "  batch 15 loss: 0.7639164574444294\n",
            "LOSS train 0.7639164574444294\n",
            "EPOCH 19252:\n",
            "  batch 5 loss: 0.662428742647171\n",
            "  batch 10 loss: 0.6561771333217621\n",
            "  batch 15 loss: 0.621498641371727\n",
            "LOSS train 0.621498641371727\n",
            "EPOCH 19253:\n",
            "  batch 5 loss: 0.4025969676673412\n",
            "  batch 10 loss: 0.42757040560245513\n",
            "  batch 15 loss: 0.5596723914146423\n",
            "LOSS train 0.5596723914146423\n",
            "EPOCH 19254:\n",
            "  batch 5 loss: 0.8924945585429669\n",
            "  batch 10 loss: 0.43327281475067136\n",
            "  batch 15 loss: 0.8647786557674408\n",
            "LOSS train 0.8647786557674408\n",
            "EPOCH 19255:\n",
            "  batch 5 loss: 0.6272553876042366\n",
            "  batch 10 loss: 0.8997151255607605\n",
            "  batch 15 loss: 0.8381446585059166\n",
            "LOSS train 0.8381446585059166\n",
            "EPOCH 19256:\n",
            "  batch 5 loss: 0.6404526829719543\n",
            "  batch 10 loss: 0.7777514815330505\n",
            "  batch 15 loss: 0.5486899852752686\n",
            "LOSS train 0.5486899852752686\n",
            "EPOCH 19257:\n",
            "  batch 5 loss: 0.652390006557107\n",
            "  batch 10 loss: 1.0807002186775208\n",
            "  batch 15 loss: 0.5958818286657334\n",
            "LOSS train 0.5958818286657334\n",
            "EPOCH 19258:\n",
            "  batch 5 loss: 0.4590564213693142\n",
            "  batch 10 loss: 0.7150263786315918\n",
            "  batch 15 loss: 0.7459896266460418\n",
            "LOSS train 0.7459896266460418\n",
            "EPOCH 19259:\n",
            "  batch 5 loss: 0.7855186343193055\n",
            "  batch 10 loss: 0.6285383820533752\n",
            "  batch 15 loss: 0.7702821612358093\n",
            "LOSS train 0.7702821612358093\n",
            "EPOCH 19260:\n",
            "  batch 5 loss: 0.8544472098350525\n",
            "  batch 10 loss: 0.7384171783924103\n",
            "  batch 15 loss: 0.42710588723421095\n",
            "LOSS train 0.42710588723421095\n",
            "EPOCH 19261:\n",
            "  batch 5 loss: 0.7193328231573105\n",
            "  batch 10 loss: 0.6285386562347413\n",
            "  batch 15 loss: 0.8757674038410187\n",
            "LOSS train 0.8757674038410187\n",
            "EPOCH 19262:\n",
            "  batch 5 loss: 0.40661993641406297\n",
            "  batch 10 loss: 0.6945777967572212\n",
            "  batch 15 loss: 0.9391406297683715\n",
            "LOSS train 0.9391406297683715\n",
            "EPOCH 19263:\n",
            "  batch 5 loss: 0.38283411487936975\n",
            "  batch 10 loss: 0.6780161559581757\n",
            "  batch 15 loss: 1.286815631389618\n",
            "LOSS train 1.286815631389618\n",
            "EPOCH 19264:\n",
            "  batch 5 loss: 0.5911896139383316\n",
            "  batch 10 loss: 0.4442049294710159\n",
            "  batch 15 loss: 0.7209409713745117\n",
            "LOSS train 0.7209409713745117\n",
            "EPOCH 19265:\n",
            "  batch 5 loss: 0.3835952118039131\n",
            "  batch 10 loss: 0.7674209833145141\n",
            "  batch 15 loss: 0.8052663773298263\n",
            "LOSS train 0.8052663773298263\n",
            "EPOCH 19266:\n",
            "  batch 5 loss: 1.0600549101829528\n",
            "  batch 10 loss: 0.41580127477645873\n",
            "  batch 15 loss: 0.9219793487340212\n",
            "LOSS train 0.9219793487340212\n",
            "EPOCH 19267:\n",
            "  batch 5 loss: 0.9038013756275177\n",
            "  batch 10 loss: 0.784448778629303\n",
            "  batch 15 loss: 0.8081697821617126\n",
            "LOSS train 0.8081697821617126\n",
            "EPOCH 19268:\n",
            "  batch 5 loss: 0.6896127790212632\n",
            "  batch 10 loss: 0.7370301425457001\n",
            "  batch 15 loss: 0.7146593868732453\n",
            "LOSS train 0.7146593868732453\n",
            "EPOCH 19269:\n",
            "  batch 5 loss: 0.5895673021674156\n",
            "  batch 10 loss: 0.9092694282531738\n",
            "  batch 15 loss: 0.2984370119869709\n",
            "LOSS train 0.2984370119869709\n",
            "EPOCH 19270:\n",
            "  batch 5 loss: 0.27950840145349504\n",
            "  batch 10 loss: 0.8706519424915313\n",
            "  batch 15 loss: 0.6792854070663452\n",
            "LOSS train 0.6792854070663452\n",
            "EPOCH 19271:\n",
            "  batch 5 loss: 0.4182512849569321\n",
            "  batch 10 loss: 0.8874561786651611\n",
            "  batch 15 loss: 0.7629636108875275\n",
            "LOSS train 0.7629636108875275\n",
            "EPOCH 19272:\n",
            "  batch 5 loss: 0.7505085289478302\n",
            "  batch 10 loss: 0.42868383824825285\n",
            "  batch 15 loss: 0.6517574906349182\n",
            "LOSS train 0.6517574906349182\n",
            "EPOCH 19273:\n",
            "  batch 5 loss: 0.5483802765607834\n",
            "  batch 10 loss: 0.20948281064629554\n",
            "  batch 15 loss: 0.47582421600818636\n",
            "LOSS train 0.47582421600818636\n",
            "EPOCH 19274:\n",
            "  batch 5 loss: 0.8835081994533539\n",
            "  batch 10 loss: 0.731702184677124\n",
            "  batch 15 loss: 0.8286708354949951\n",
            "LOSS train 0.8286708354949951\n",
            "EPOCH 19275:\n",
            "  batch 5 loss: 0.7014349400997162\n",
            "  batch 10 loss: 0.751207458972931\n",
            "  batch 15 loss: 0.6394227743148804\n",
            "LOSS train 0.6394227743148804\n",
            "EPOCH 19276:\n",
            "  batch 5 loss: 0.36199643462896347\n",
            "  batch 10 loss: 0.4775808438658714\n",
            "  batch 15 loss: 0.7097414016723633\n",
            "LOSS train 0.7097414016723633\n",
            "EPOCH 19277:\n",
            "  batch 5 loss: 0.9592597842216491\n",
            "  batch 10 loss: 0.7765466690063476\n",
            "  batch 15 loss: 0.48976038098335267\n",
            "LOSS train 0.48976038098335267\n",
            "EPOCH 19278:\n",
            "  batch 5 loss: 1.0061436891555786\n",
            "  batch 10 loss: 0.6643697559833527\n",
            "  batch 15 loss: 0.8188178062438964\n",
            "LOSS train 0.8188178062438964\n",
            "EPOCH 19279:\n",
            "  batch 5 loss: 1.351619052886963\n",
            "  batch 10 loss: 0.6537102371454239\n",
            "  batch 15 loss: 0.9146688431501389\n",
            "LOSS train 0.9146688431501389\n",
            "EPOCH 19280:\n",
            "  batch 5 loss: 0.879729625582695\n",
            "  batch 10 loss: 0.46929500848054884\n",
            "  batch 15 loss: 0.5983065344393254\n",
            "LOSS train 0.5983065344393254\n",
            "EPOCH 19281:\n",
            "  batch 5 loss: 0.7307138696312905\n",
            "  batch 10 loss: 0.8613272726535797\n",
            "  batch 15 loss: 0.4617950886487961\n",
            "LOSS train 0.4617950886487961\n",
            "EPOCH 19282:\n",
            "  batch 5 loss: 0.9383492946624756\n",
            "  batch 10 loss: 0.6798545897006989\n",
            "  batch 15 loss: 0.24770530089735984\n",
            "LOSS train 0.24770530089735984\n",
            "EPOCH 19283:\n",
            "  batch 5 loss: 0.6950448036193848\n",
            "  batch 10 loss: 0.879048353433609\n",
            "  batch 15 loss: 0.822463795542717\n",
            "LOSS train 0.822463795542717\n",
            "EPOCH 19284:\n",
            "  batch 5 loss: 0.3418244421482086\n",
            "  batch 10 loss: 0.9178004026412964\n",
            "  batch 15 loss: 0.7197130680084228\n",
            "LOSS train 0.7197130680084228\n",
            "EPOCH 19285:\n",
            "  batch 5 loss: 0.9327604413032532\n",
            "  batch 10 loss: 0.6952908784151077\n",
            "  batch 15 loss: 0.8781423091888427\n",
            "LOSS train 0.8781423091888427\n",
            "EPOCH 19286:\n",
            "  batch 5 loss: 0.7830086648464203\n",
            "  batch 10 loss: 0.5874327421188354\n",
            "  batch 15 loss: 0.6442353844642639\n",
            "LOSS train 0.6442353844642639\n",
            "EPOCH 19287:\n",
            "  batch 5 loss: 0.9375176429748535\n",
            "  batch 10 loss: 0.73155078291893\n",
            "  batch 15 loss: 0.7787220120429993\n",
            "LOSS train 0.7787220120429993\n",
            "EPOCH 19288:\n",
            "  batch 5 loss: 0.7185812354087829\n",
            "  batch 10 loss: 0.5498747080564499\n",
            "  batch 15 loss: 0.7908110678195953\n",
            "LOSS train 0.7908110678195953\n",
            "EPOCH 19289:\n",
            "  batch 5 loss: 0.8549703121185303\n",
            "  batch 10 loss: 0.6798057809472084\n",
            "  batch 15 loss: 0.5574843138456345\n",
            "LOSS train 0.5574843138456345\n",
            "EPOCH 19290:\n",
            "  batch 5 loss: 0.5404349535703659\n",
            "  batch 10 loss: 0.39249152559787037\n",
            "  batch 15 loss: 0.6068130314350129\n",
            "LOSS train 0.6068130314350129\n",
            "EPOCH 19291:\n",
            "  batch 5 loss: 0.584607195854187\n",
            "  batch 10 loss: 0.8398639917373657\n",
            "  batch 15 loss: 0.775939530134201\n",
            "LOSS train 0.775939530134201\n",
            "EPOCH 19292:\n",
            "  batch 5 loss: 1.0049188017845154\n",
            "  batch 10 loss: 0.5039294719696045\n",
            "  batch 15 loss: 0.6969753742218018\n",
            "LOSS train 0.6969753742218018\n",
            "EPOCH 19293:\n",
            "  batch 5 loss: 0.778955626487732\n",
            "  batch 10 loss: 0.9913453102111817\n",
            "  batch 15 loss: 0.6486988008022309\n",
            "LOSS train 0.6486988008022309\n",
            "EPOCH 19294:\n",
            "  batch 5 loss: 0.6899786710739135\n",
            "  batch 10 loss: 0.9630692601203918\n",
            "  batch 15 loss: 0.572899729013443\n",
            "LOSS train 0.572899729013443\n",
            "EPOCH 19295:\n",
            "  batch 5 loss: 0.8460098564624786\n",
            "  batch 10 loss: 0.6554998815059662\n",
            "  batch 15 loss: 0.677953690290451\n",
            "LOSS train 0.677953690290451\n",
            "EPOCH 19296:\n",
            "  batch 5 loss: 0.5433360755443573\n",
            "  batch 10 loss: 0.8528559565544128\n",
            "  batch 15 loss: 0.4537879228591919\n",
            "LOSS train 0.4537879228591919\n",
            "EPOCH 19297:\n",
            "  batch 5 loss: 0.7375134114176035\n",
            "  batch 10 loss: 0.8358355045318604\n",
            "  batch 15 loss: 0.5135625436902046\n",
            "LOSS train 0.5135625436902046\n",
            "EPOCH 19298:\n",
            "  batch 5 loss: 0.9149093270301819\n",
            "  batch 10 loss: 0.4114001203328371\n",
            "  batch 15 loss: 0.6299738734960556\n",
            "LOSS train 0.6299738734960556\n",
            "EPOCH 19299:\n",
            "  batch 5 loss: 1.017468810081482\n",
            "  batch 10 loss: 0.6776959866285324\n",
            "  batch 15 loss: 0.6567799687385559\n",
            "LOSS train 0.6567799687385559\n",
            "EPOCH 19300:\n",
            "  batch 5 loss: 0.7674197733402253\n",
            "  batch 10 loss: 0.5081062689423561\n",
            "  batch 15 loss: 0.9271681189537049\n",
            "LOSS train 0.9271681189537049\n",
            "EPOCH 19301:\n",
            "  batch 5 loss: 0.6209180951118469\n",
            "  batch 10 loss: 0.6982437074184418\n",
            "  batch 15 loss: 0.37228227630257604\n",
            "LOSS train 0.37228227630257604\n",
            "EPOCH 19302:\n",
            "  batch 5 loss: 0.557780310511589\n",
            "  batch 10 loss: 1.1065115809440613\n",
            "  batch 15 loss: 0.5945068806409836\n",
            "LOSS train 0.5945068806409836\n",
            "EPOCH 19303:\n",
            "  batch 5 loss: 0.5610242985188961\n",
            "  batch 10 loss: 0.8756143093109131\n",
            "  batch 15 loss: 0.5948221981525421\n",
            "LOSS train 0.5948221981525421\n",
            "EPOCH 19304:\n",
            "  batch 5 loss: 0.6602334558963776\n",
            "  batch 10 loss: 0.7521014243364335\n",
            "  batch 15 loss: 0.7184328675270081\n",
            "LOSS train 0.7184328675270081\n",
            "EPOCH 19305:\n",
            "  batch 5 loss: 0.8063326597213745\n",
            "  batch 10 loss: 0.8925731539726257\n",
            "  batch 15 loss: 0.9755141854286193\n",
            "LOSS train 0.9755141854286193\n",
            "EPOCH 19306:\n",
            "  batch 5 loss: 0.7605778753757477\n",
            "  batch 10 loss: 0.6590333878993988\n",
            "  batch 15 loss: 0.6037462517619133\n",
            "LOSS train 0.6037462517619133\n",
            "EPOCH 19307:\n",
            "  batch 5 loss: 0.4194099739193916\n",
            "  batch 10 loss: 0.5009743750095368\n",
            "  batch 15 loss: 0.6892715454101562\n",
            "LOSS train 0.6892715454101562\n",
            "EPOCH 19308:\n",
            "  batch 5 loss: 0.644620668888092\n",
            "  batch 10 loss: 0.7038387179374694\n",
            "  batch 15 loss: 0.3698729559779167\n",
            "LOSS train 0.3698729559779167\n",
            "EPOCH 19309:\n",
            "  batch 5 loss: 0.7059137344360351\n",
            "  batch 10 loss: 0.7182537697255611\n",
            "  batch 15 loss: 0.5546556003391743\n",
            "LOSS train 0.5546556003391743\n",
            "EPOCH 19310:\n",
            "  batch 5 loss: 0.7910646796226501\n",
            "  batch 10 loss: 0.7479105561971664\n",
            "  batch 15 loss: 1.0253741838037969\n",
            "LOSS train 1.0253741838037969\n",
            "EPOCH 19311:\n",
            "  batch 5 loss: 0.8050390601158142\n",
            "  batch 10 loss: 0.9384058952331543\n",
            "  batch 15 loss: 0.45890559554100036\n",
            "LOSS train 0.45890559554100036\n",
            "EPOCH 19312:\n",
            "  batch 5 loss: 0.5098891943693161\n",
            "  batch 10 loss: 0.6954154804348945\n",
            "  batch 15 loss: 0.8182248830795288\n",
            "LOSS train 0.8182248830795288\n",
            "EPOCH 19313:\n",
            "  batch 5 loss: 0.5648450553417206\n",
            "  batch 10 loss: 0.6901980519294739\n",
            "  batch 15 loss: 0.8144258439540863\n",
            "LOSS train 0.8144258439540863\n",
            "EPOCH 19314:\n",
            "  batch 5 loss: 0.5165219210088253\n",
            "  batch 10 loss: 0.6066448435187339\n",
            "  batch 15 loss: 0.7965305641293525\n",
            "LOSS train 0.7965305641293525\n",
            "EPOCH 19315:\n",
            "  batch 5 loss: 0.6532836759462952\n",
            "  batch 10 loss: 0.583418220281601\n",
            "  batch 15 loss: 0.5590878576040268\n",
            "LOSS train 0.5590878576040268\n",
            "EPOCH 19316:\n",
            "  batch 5 loss: 0.6059142911806703\n",
            "  batch 10 loss: 0.7422254502773284\n",
            "  batch 15 loss: 0.6931766200810671\n",
            "LOSS train 0.6931766200810671\n",
            "EPOCH 19317:\n",
            "  batch 5 loss: 0.4688235580921173\n",
            "  batch 10 loss: 0.769383093714714\n",
            "  batch 15 loss: 0.5036320209503173\n",
            "LOSS train 0.5036320209503173\n",
            "EPOCH 19318:\n",
            "  batch 5 loss: 0.9005818396806717\n",
            "  batch 10 loss: 1.0728073358535766\n",
            "  batch 15 loss: 0.4879667341709137\n",
            "LOSS train 0.4879667341709137\n",
            "EPOCH 19319:\n",
            "  batch 5 loss: 0.6739731848239898\n",
            "  batch 10 loss: 0.42003261744976045\n",
            "  batch 15 loss: 0.5844563126564026\n",
            "LOSS train 0.5844563126564026\n",
            "EPOCH 19320:\n",
            "  batch 5 loss: 0.6404312282800675\n",
            "  batch 10 loss: 0.6035473585128784\n",
            "  batch 15 loss: 0.5024980276823043\n",
            "LOSS train 0.5024980276823043\n",
            "EPOCH 19321:\n",
            "  batch 5 loss: 0.6199220061302185\n",
            "  batch 10 loss: 0.6458272218704224\n",
            "  batch 15 loss: 0.8518101930618286\n",
            "LOSS train 0.8518101930618286\n",
            "EPOCH 19322:\n",
            "  batch 5 loss: 0.6998161680996418\n",
            "  batch 10 loss: 1.042579674720764\n",
            "  batch 15 loss: 0.7743949055671692\n",
            "LOSS train 0.7743949055671692\n",
            "EPOCH 19323:\n",
            "  batch 5 loss: 0.7663645684719086\n",
            "  batch 10 loss: 0.7937792062759399\n",
            "  batch 15 loss: 0.5420699387788772\n",
            "LOSS train 0.5420699387788772\n",
            "EPOCH 19324:\n",
            "  batch 5 loss: 0.7608048051595688\n",
            "  batch 10 loss: 1.0664684414863586\n",
            "  batch 15 loss: 0.9968492388725281\n",
            "LOSS train 0.9968492388725281\n",
            "EPOCH 19325:\n",
            "  batch 5 loss: 0.8096272826194764\n",
            "  batch 10 loss: 0.7114256367087364\n",
            "  batch 15 loss: 0.6926219284534454\n",
            "LOSS train 0.6926219284534454\n",
            "EPOCH 19326:\n",
            "  batch 5 loss: 0.8662791475653648\n",
            "  batch 10 loss: 0.7402342617511749\n",
            "  batch 15 loss: 0.9485209345817566\n",
            "LOSS train 0.9485209345817566\n",
            "EPOCH 19327:\n",
            "  batch 5 loss: 0.9118798732757568\n",
            "  batch 10 loss: 0.6981372117996216\n",
            "  batch 15 loss: 0.8300557732582092\n",
            "LOSS train 0.8300557732582092\n",
            "EPOCH 19328:\n",
            "  batch 5 loss: 0.4875628653913736\n",
            "  batch 10 loss: 0.7694430708885193\n",
            "  batch 15 loss: 0.4391962230205536\n",
            "LOSS train 0.4391962230205536\n",
            "EPOCH 19329:\n",
            "  batch 5 loss: 0.7800000093877315\n",
            "  batch 10 loss: 0.7116142928600311\n",
            "  batch 15 loss: 0.421024426817894\n",
            "LOSS train 0.421024426817894\n",
            "EPOCH 19330:\n",
            "  batch 5 loss: 1.2177188396453857\n",
            "  batch 10 loss: 0.93609619140625\n",
            "  batch 15 loss: 0.9246243119239808\n",
            "LOSS train 0.9246243119239808\n",
            "EPOCH 19331:\n",
            "  batch 5 loss: 0.5474354416131973\n",
            "  batch 10 loss: 1.0173796474933625\n",
            "  batch 15 loss: 0.5859156250953674\n",
            "LOSS train 0.5859156250953674\n",
            "EPOCH 19332:\n",
            "  batch 5 loss: 0.8493129014968872\n",
            "  batch 10 loss: 0.5241201192140579\n",
            "  batch 15 loss: 0.9607595503330231\n",
            "LOSS train 0.9607595503330231\n",
            "EPOCH 19333:\n",
            "  batch 5 loss: 0.5479792140424251\n",
            "  batch 10 loss: 0.6702805101871491\n",
            "  batch 15 loss: 0.4758152686059475\n",
            "LOSS train 0.4758152686059475\n",
            "EPOCH 19334:\n",
            "  batch 5 loss: 0.5720629423856736\n",
            "  batch 10 loss: 0.8449128031730652\n",
            "  batch 15 loss: 0.8211839497089386\n",
            "LOSS train 0.8211839497089386\n",
            "EPOCH 19335:\n",
            "  batch 5 loss: 0.8187811017036438\n",
            "  batch 10 loss: 0.7719570338726044\n",
            "  batch 15 loss: 0.7391184210777283\n",
            "LOSS train 0.7391184210777283\n",
            "EPOCH 19336:\n",
            "  batch 5 loss: 0.5072074323892594\n",
            "  batch 10 loss: 1.0602959752082826\n",
            "  batch 15 loss: 0.5012329824268817\n",
            "LOSS train 0.5012329824268817\n",
            "EPOCH 19337:\n",
            "  batch 5 loss: 0.5587847530841827\n",
            "  batch 10 loss: 0.6308126796036959\n",
            "  batch 15 loss: 0.6867700517177582\n",
            "LOSS train 0.6867700517177582\n",
            "EPOCH 19338:\n",
            "  batch 5 loss: 0.9570637702941894\n",
            "  batch 10 loss: 0.5347011268138886\n",
            "  batch 15 loss: 0.6916933476924896\n",
            "LOSS train 0.6916933476924896\n",
            "EPOCH 19339:\n",
            "  batch 5 loss: 0.8998940944671631\n",
            "  batch 10 loss: 0.6655275344848632\n",
            "  batch 15 loss: 0.696593028306961\n",
            "LOSS train 0.696593028306961\n",
            "EPOCH 19340:\n",
            "  batch 5 loss: 0.774150638282299\n",
            "  batch 10 loss: 0.6210701666772366\n",
            "  batch 15 loss: 0.5738106004893779\n",
            "LOSS train 0.5738106004893779\n",
            "EPOCH 19341:\n",
            "  batch 5 loss: 0.9620497941970825\n",
            "  batch 10 loss: 0.8854972898960114\n",
            "  batch 15 loss: 0.6318338692188263\n",
            "LOSS train 0.6318338692188263\n",
            "EPOCH 19342:\n",
            "  batch 5 loss: 0.565660972893238\n",
            "  batch 10 loss: 0.6994752883911133\n",
            "  batch 15 loss: 0.5060141086578369\n",
            "LOSS train 0.5060141086578369\n",
            "EPOCH 19343:\n",
            "  batch 5 loss: 0.7200486153364182\n",
            "  batch 10 loss: 0.6484615720808506\n",
            "  batch 15 loss: 0.7115808606147767\n",
            "LOSS train 0.7115808606147767\n",
            "EPOCH 19344:\n",
            "  batch 5 loss: 0.6113890588283539\n",
            "  batch 10 loss: 0.7371511995792389\n",
            "  batch 15 loss: 0.7091111660003662\n",
            "LOSS train 0.7091111660003662\n",
            "EPOCH 19345:\n",
            "  batch 5 loss: 0.842577052116394\n",
            "  batch 10 loss: 0.5175918400287628\n",
            "  batch 15 loss: 0.8507339775562286\n",
            "LOSS train 0.8507339775562286\n",
            "EPOCH 19346:\n",
            "  batch 5 loss: 0.5802050650119781\n",
            "  batch 10 loss: 0.7672524362802505\n",
            "  batch 15 loss: 0.8306552588939666\n",
            "LOSS train 0.8306552588939666\n",
            "EPOCH 19347:\n",
            "  batch 5 loss: 0.8014376938343049\n",
            "  batch 10 loss: 0.6551319271326065\n",
            "  batch 15 loss: 0.5655443213880063\n",
            "LOSS train 0.5655443213880063\n",
            "EPOCH 19348:\n",
            "  batch 5 loss: 0.5960091888904572\n",
            "  batch 10 loss: 0.850755798816681\n",
            "  batch 15 loss: 0.5412189483642578\n",
            "LOSS train 0.5412189483642578\n",
            "EPOCH 19349:\n",
            "  batch 5 loss: 0.8448834419250488\n",
            "  batch 10 loss: 0.9705868244171143\n",
            "  batch 15 loss: 0.8958495140075684\n",
            "LOSS train 0.8958495140075684\n",
            "EPOCH 19350:\n",
            "  batch 5 loss: 1.0560537457466126\n",
            "  batch 10 loss: 0.916725891828537\n",
            "  batch 15 loss: 0.6765520133078098\n",
            "LOSS train 0.6765520133078098\n",
            "EPOCH 19351:\n",
            "  batch 5 loss: 0.716800332069397\n",
            "  batch 10 loss: 0.9825487732887268\n",
            "  batch 15 loss: 0.9222961843013764\n",
            "LOSS train 0.9222961843013764\n",
            "EPOCH 19352:\n",
            "  batch 5 loss: 0.6786698877811432\n",
            "  batch 10 loss: 0.46937585473060606\n",
            "  batch 15 loss: 0.8713424786925316\n",
            "LOSS train 0.8713424786925316\n",
            "EPOCH 19353:\n",
            "  batch 5 loss: 1.3723178923130035\n",
            "  batch 10 loss: 0.4411719799041748\n",
            "  batch 15 loss: 0.6953069627285003\n",
            "LOSS train 0.6953069627285003\n",
            "EPOCH 19354:\n",
            "  batch 5 loss: 0.9592644035816192\n",
            "  batch 10 loss: 0.8362407803535461\n",
            "  batch 15 loss: 0.651099094748497\n",
            "LOSS train 0.651099094748497\n",
            "EPOCH 19355:\n",
            "  batch 5 loss: 0.9279339730739593\n",
            "  batch 10 loss: 0.7935234382748604\n",
            "  batch 15 loss: 0.7049707628786563\n",
            "LOSS train 0.7049707628786563\n",
            "EPOCH 19356:\n",
            "  batch 5 loss: 0.5705205291509629\n",
            "  batch 10 loss: 0.9219864487648011\n",
            "  batch 15 loss: 0.9175456047058106\n",
            "LOSS train 0.9175456047058106\n",
            "EPOCH 19357:\n",
            "  batch 5 loss: 0.6015759944915772\n",
            "  batch 10 loss: 0.5074677102267742\n",
            "  batch 15 loss: 0.7202301859855652\n",
            "LOSS train 0.7202301859855652\n",
            "EPOCH 19358:\n",
            "  batch 5 loss: 0.8050289928913117\n",
            "  batch 10 loss: 0.7868186235427856\n",
            "  batch 15 loss: 0.5594360530376434\n",
            "LOSS train 0.5594360530376434\n",
            "EPOCH 19359:\n",
            "  batch 5 loss: 0.7010277390480042\n",
            "  batch 10 loss: 0.7468960762023926\n",
            "  batch 15 loss: 0.8308136105537415\n",
            "LOSS train 0.8308136105537415\n",
            "EPOCH 19360:\n",
            "  batch 5 loss: 0.49776733219623565\n",
            "  batch 10 loss: 0.7336503505706787\n",
            "  batch 15 loss: 0.5833492875099182\n",
            "LOSS train 0.5833492875099182\n",
            "EPOCH 19361:\n",
            "  batch 5 loss: 0.5378345966339111\n",
            "  batch 10 loss: 0.7791640877723693\n",
            "  batch 15 loss: 0.3804211184382439\n",
            "LOSS train 0.3804211184382439\n",
            "EPOCH 19362:\n",
            "  batch 5 loss: 0.5489744663238525\n",
            "  batch 10 loss: 0.5499680548906326\n",
            "  batch 15 loss: 0.6694467484951019\n",
            "LOSS train 0.6694467484951019\n",
            "EPOCH 19363:\n",
            "  batch 5 loss: 1.0207456707954408\n",
            "  batch 10 loss: 0.7070553183555603\n",
            "  batch 15 loss: 0.5056109391152859\n",
            "LOSS train 0.5056109391152859\n",
            "EPOCH 19364:\n",
            "  batch 5 loss: 0.8621270373463631\n",
            "  batch 10 loss: 0.5312139801681042\n",
            "  batch 15 loss: 0.8952543139457703\n",
            "LOSS train 0.8952543139457703\n",
            "EPOCH 19365:\n",
            "  batch 5 loss: 0.7148396909236908\n",
            "  batch 10 loss: 0.9340941473841667\n",
            "  batch 15 loss: 0.6850153088569642\n",
            "LOSS train 0.6850153088569642\n",
            "EPOCH 19366:\n",
            "  batch 5 loss: 0.6427110701799392\n",
            "  batch 10 loss: 0.6831775426864624\n",
            "  batch 15 loss: 0.5967099159955979\n",
            "LOSS train 0.5967099159955979\n",
            "EPOCH 19367:\n",
            "  batch 5 loss: 0.8274722754955292\n",
            "  batch 10 loss: 0.9061861127614975\n",
            "  batch 15 loss: 0.7602064281702041\n",
            "LOSS train 0.7602064281702041\n",
            "EPOCH 19368:\n",
            "  batch 5 loss: 0.5621695563197135\n",
            "  batch 10 loss: 0.7163057327270508\n",
            "  batch 15 loss: 0.36048243194818497\n",
            "LOSS train 0.36048243194818497\n",
            "EPOCH 19369:\n",
            "  batch 5 loss: 0.8576626092195511\n",
            "  batch 10 loss: 0.5898288890719414\n",
            "  batch 15 loss: 0.599670672416687\n",
            "LOSS train 0.599670672416687\n",
            "EPOCH 19370:\n",
            "  batch 5 loss: 0.6980476319789887\n",
            "  batch 10 loss: 0.7249717570841312\n",
            "  batch 15 loss: 0.7468483567237854\n",
            "LOSS train 0.7468483567237854\n",
            "EPOCH 19371:\n",
            "  batch 5 loss: 0.8248868942260742\n",
            "  batch 10 loss: 0.6097755491733551\n",
            "  batch 15 loss: 0.6782919138669967\n",
            "LOSS train 0.6782919138669967\n",
            "EPOCH 19372:\n",
            "  batch 5 loss: 0.6345223128795624\n",
            "  batch 10 loss: 0.5164795339107513\n",
            "  batch 15 loss: 0.43182026110589505\n",
            "LOSS train 0.43182026110589505\n",
            "EPOCH 19373:\n",
            "  batch 5 loss: 0.833866536617279\n",
            "  batch 10 loss: 0.6326689183712005\n",
            "  batch 15 loss: 0.4959618128836155\n",
            "LOSS train 0.4959618128836155\n",
            "EPOCH 19374:\n",
            "  batch 5 loss: 1.148618996143341\n",
            "  batch 10 loss: 0.3317486748099327\n",
            "  batch 15 loss: 0.5185594692826271\n",
            "LOSS train 0.5185594692826271\n",
            "EPOCH 19375:\n",
            "  batch 5 loss: 0.6878299087285995\n",
            "  batch 10 loss: 0.9638597875833511\n",
            "  batch 15 loss: 0.857273256778717\n",
            "LOSS train 0.857273256778717\n",
            "EPOCH 19376:\n",
            "  batch 5 loss: 0.5614077985286713\n",
            "  batch 10 loss: 0.7932788312435151\n",
            "  batch 15 loss: 0.6455286920070649\n",
            "LOSS train 0.6455286920070649\n",
            "EPOCH 19377:\n",
            "  batch 5 loss: 0.4150392025709152\n",
            "  batch 10 loss: 0.4626439124345779\n",
            "  batch 15 loss: 0.735684902407229\n",
            "LOSS train 0.735684902407229\n",
            "EPOCH 19378:\n",
            "  batch 5 loss: 0.5325597405433655\n",
            "  batch 10 loss: 0.5209886156022548\n",
            "  batch 15 loss: 0.8710693478584289\n",
            "LOSS train 0.8710693478584289\n",
            "EPOCH 19379:\n",
            "  batch 5 loss: 0.6031057596206665\n",
            "  batch 10 loss: 0.7953701257705689\n",
            "  batch 15 loss: 0.6597282290458679\n",
            "LOSS train 0.6597282290458679\n",
            "EPOCH 19380:\n",
            "  batch 5 loss: 0.6202115818858147\n",
            "  batch 10 loss: 0.6872929751873016\n",
            "  batch 15 loss: 0.664251321554184\n",
            "LOSS train 0.664251321554184\n",
            "EPOCH 19381:\n",
            "  batch 5 loss: 0.6530790090560913\n",
            "  batch 10 loss: 0.6470013737678528\n",
            "  batch 15 loss: 1.1041634202003479\n",
            "LOSS train 1.1041634202003479\n",
            "EPOCH 19382:\n",
            "  batch 5 loss: 0.870721697807312\n",
            "  batch 10 loss: 0.5004665195941925\n",
            "  batch 15 loss: 0.7113640785217286\n",
            "LOSS train 0.7113640785217286\n",
            "EPOCH 19383:\n",
            "  batch 5 loss: 0.7227902919054031\n",
            "  batch 10 loss: 0.6854189395904541\n",
            "  batch 15 loss: 0.7056659057736396\n",
            "LOSS train 0.7056659057736396\n",
            "EPOCH 19384:\n",
            "  batch 5 loss: 0.7959739074110985\n",
            "  batch 10 loss: 0.9294757008552551\n",
            "  batch 15 loss: 0.7255234658718109\n",
            "LOSS train 0.7255234658718109\n",
            "EPOCH 19385:\n",
            "  batch 5 loss: 0.5880706876516342\n",
            "  batch 10 loss: 0.7340506255626679\n",
            "  batch 15 loss: 0.7057720780372619\n",
            "LOSS train 0.7057720780372619\n",
            "EPOCH 19386:\n",
            "  batch 5 loss: 0.7778921723365784\n",
            "  batch 10 loss: 0.8696641325950623\n",
            "  batch 15 loss: 0.8190454483032227\n",
            "LOSS train 0.8190454483032227\n",
            "EPOCH 19387:\n",
            "  batch 5 loss: 0.6221724420785903\n",
            "  batch 10 loss: 0.5645854711532593\n",
            "  batch 15 loss: 0.2754498615860939\n",
            "LOSS train 0.2754498615860939\n",
            "EPOCH 19388:\n",
            "  batch 5 loss: 0.6238819718360901\n",
            "  batch 10 loss: 0.4391638830304146\n",
            "  batch 15 loss: 0.6460888519883156\n",
            "LOSS train 0.6460888519883156\n",
            "EPOCH 19389:\n",
            "  batch 5 loss: 0.3852864921092987\n",
            "  batch 10 loss: 0.5158829599618912\n",
            "  batch 15 loss: 0.7573738876730204\n",
            "LOSS train 0.7573738876730204\n",
            "EPOCH 19390:\n",
            "  batch 5 loss: 1.1221948504447936\n",
            "  batch 10 loss: 0.6077726483345032\n",
            "  batch 15 loss: 1.052444064617157\n",
            "LOSS train 1.052444064617157\n",
            "EPOCH 19391:\n",
            "  batch 5 loss: 0.558175177499652\n",
            "  batch 10 loss: 0.8928250908851624\n",
            "  batch 15 loss: 0.4327800303697586\n",
            "LOSS train 0.4327800303697586\n",
            "EPOCH 19392:\n",
            "  batch 5 loss: 0.6672929167747498\n",
            "  batch 10 loss: 0.7673653125762939\n",
            "  batch 15 loss: 0.7821408033370971\n",
            "LOSS train 0.7821408033370971\n",
            "EPOCH 19393:\n",
            "  batch 5 loss: 1.174683678150177\n",
            "  batch 10 loss: 0.5721375472843647\n",
            "  batch 15 loss: 0.9803090691566467\n",
            "LOSS train 0.9803090691566467\n",
            "EPOCH 19394:\n",
            "  batch 5 loss: 0.9902115106582642\n",
            "  batch 10 loss: 0.7855392098426819\n",
            "  batch 15 loss: 0.7407744884490967\n",
            "LOSS train 0.7407744884490967\n",
            "EPOCH 19395:\n",
            "  batch 5 loss: 0.7051976636052132\n",
            "  batch 10 loss: 0.8100893676280976\n",
            "  batch 15 loss: 1.083458709716797\n",
            "LOSS train 1.083458709716797\n",
            "EPOCH 19396:\n",
            "  batch 5 loss: 0.8166370421648026\n",
            "  batch 10 loss: 0.6593001119792461\n",
            "  batch 15 loss: 0.7115057051181793\n",
            "LOSS train 0.7115057051181793\n",
            "EPOCH 19397:\n",
            "  batch 5 loss: 0.30495643652975557\n",
            "  batch 10 loss: 0.8043654084205627\n",
            "  batch 15 loss: 0.7193660140037537\n",
            "LOSS train 0.7193660140037537\n",
            "EPOCH 19398:\n",
            "  batch 5 loss: 0.8316729247570038\n",
            "  batch 10 loss: 0.532624426484108\n",
            "  batch 15 loss: 0.9300095200538635\n",
            "LOSS train 0.9300095200538635\n",
            "EPOCH 19399:\n",
            "  batch 5 loss: 0.7506688714027405\n",
            "  batch 10 loss: 0.6481964588165283\n",
            "  batch 15 loss: 0.5959068834781647\n",
            "LOSS train 0.5959068834781647\n",
            "EPOCH 19400:\n",
            "  batch 5 loss: 0.5648527055978775\n",
            "  batch 10 loss: 1.1173721492290496\n",
            "  batch 15 loss: 0.39451828207820655\n",
            "LOSS train 0.39451828207820655\n",
            "EPOCH 19401:\n",
            "  batch 5 loss: 0.7485788501799107\n",
            "  batch 10 loss: 0.7330741912126542\n",
            "  batch 15 loss: 0.6115137711167336\n",
            "LOSS train 0.6115137711167336\n",
            "EPOCH 19402:\n",
            "  batch 5 loss: 0.7618569642305374\n",
            "  batch 10 loss: 0.31389543004333975\n",
            "  batch 15 loss: 0.7569237105548382\n",
            "LOSS train 0.7569237105548382\n",
            "EPOCH 19403:\n",
            "  batch 5 loss: 0.5771467506885528\n",
            "  batch 10 loss: 0.5638111352920532\n",
            "  batch 15 loss: 0.536236013751477\n",
            "LOSS train 0.536236013751477\n",
            "EPOCH 19404:\n",
            "  batch 5 loss: 0.7601267695426941\n",
            "  batch 10 loss: 0.47140356302261355\n",
            "  batch 15 loss: 0.80862943418324\n",
            "LOSS train 0.80862943418324\n",
            "EPOCH 19405:\n",
            "  batch 5 loss: 0.5215049669146538\n",
            "  batch 10 loss: 0.5734672084450722\n",
            "  batch 15 loss: 0.6993708848953247\n",
            "LOSS train 0.6993708848953247\n",
            "EPOCH 19406:\n",
            "  batch 5 loss: 0.3428975611925125\n",
            "  batch 10 loss: 0.7026428759098053\n",
            "  batch 15 loss: 0.5493612840771676\n",
            "LOSS train 0.5493612840771676\n",
            "EPOCH 19407:\n",
            "  batch 5 loss: 0.777911925315857\n",
            "  batch 10 loss: 0.9057013154029846\n",
            "  batch 15 loss: 0.5141196250915527\n",
            "LOSS train 0.5141196250915527\n",
            "EPOCH 19408:\n",
            "  batch 5 loss: 0.6432017713785172\n",
            "  batch 10 loss: 0.6649156451225281\n",
            "  batch 15 loss: 0.7474647700786591\n",
            "LOSS train 0.7474647700786591\n",
            "EPOCH 19409:\n",
            "  batch 5 loss: 1.0149117887020112\n",
            "  batch 10 loss: 1.0176085710525513\n",
            "  batch 15 loss: 0.6776362240314484\n",
            "LOSS train 0.6776362240314484\n",
            "EPOCH 19410:\n",
            "  batch 5 loss: 0.6234304130077362\n",
            "  batch 10 loss: 0.5520452827215194\n",
            "  batch 15 loss: 0.7234976351261139\n",
            "LOSS train 0.7234976351261139\n",
            "EPOCH 19411:\n",
            "  batch 5 loss: 0.4790544420480728\n",
            "  batch 10 loss: 0.6715741157531738\n",
            "  batch 15 loss: 0.6250712394714355\n",
            "LOSS train 0.6250712394714355\n",
            "EPOCH 19412:\n",
            "  batch 5 loss: 0.7630510926246643\n",
            "  batch 10 loss: 1.0153581500053406\n",
            "  batch 15 loss: 0.6332794010639191\n",
            "LOSS train 0.6332794010639191\n",
            "EPOCH 19413:\n",
            "  batch 5 loss: 1.0119243144989014\n",
            "  batch 10 loss: 0.941999489068985\n",
            "  batch 15 loss: 0.3639053113758564\n",
            "LOSS train 0.3639053113758564\n",
            "EPOCH 19414:\n",
            "  batch 5 loss: 0.7941763520240783\n",
            "  batch 10 loss: 0.5972918808460236\n",
            "  batch 15 loss: 0.4875615358352661\n",
            "LOSS train 0.4875615358352661\n",
            "EPOCH 19415:\n",
            "  batch 5 loss: 0.8393018066883087\n",
            "  batch 10 loss: 0.7658890798687935\n",
            "  batch 15 loss: 0.467625629901886\n",
            "LOSS train 0.467625629901886\n",
            "EPOCH 19416:\n",
            "  batch 5 loss: 0.6133197337388993\n",
            "  batch 10 loss: 0.5766055643558502\n",
            "  batch 15 loss: 0.9348612010478974\n",
            "LOSS train 0.9348612010478974\n",
            "EPOCH 19417:\n",
            "  batch 5 loss: 0.762394267320633\n",
            "  batch 10 loss: 0.8653151273727417\n",
            "  batch 15 loss: 0.8035641878843307\n",
            "LOSS train 0.8035641878843307\n",
            "EPOCH 19418:\n",
            "  batch 5 loss: 0.9327018976211547\n",
            "  batch 10 loss: 0.5768143236637115\n",
            "  batch 15 loss: 0.8341817200183869\n",
            "LOSS train 0.8341817200183869\n",
            "EPOCH 19419:\n",
            "  batch 5 loss: 0.47263772785663605\n",
            "  batch 10 loss: 0.3491107314825058\n",
            "  batch 15 loss: 0.838301283121109\n",
            "LOSS train 0.838301283121109\n",
            "EPOCH 19420:\n",
            "  batch 5 loss: 0.8655220299959183\n",
            "  batch 10 loss: 0.8395867824554444\n",
            "  batch 15 loss: 0.777063998952508\n",
            "LOSS train 0.777063998952508\n",
            "EPOCH 19421:\n",
            "  batch 5 loss: 0.8485249876976013\n",
            "  batch 10 loss: 0.7481030464172364\n",
            "  batch 15 loss: 0.8932456612586975\n",
            "LOSS train 0.8932456612586975\n",
            "EPOCH 19422:\n",
            "  batch 5 loss: 0.8767786264419556\n",
            "  batch 10 loss: 0.7967899143695831\n",
            "  batch 15 loss: 0.7700415119528771\n",
            "LOSS train 0.7700415119528771\n",
            "EPOCH 19423:\n",
            "  batch 5 loss: 0.6585306227207184\n",
            "  batch 10 loss: 0.6012806832790375\n",
            "  batch 15 loss: 0.9269634306430816\n",
            "LOSS train 0.9269634306430816\n",
            "EPOCH 19424:\n",
            "  batch 5 loss: 0.8487272262573242\n",
            "  batch 10 loss: 0.8024206310510635\n",
            "  batch 15 loss: 0.9686046719551087\n",
            "LOSS train 0.9686046719551087\n",
            "EPOCH 19425:\n",
            "  batch 5 loss: 0.6393027007579803\n",
            "  batch 10 loss: 1.13267080783844\n",
            "  batch 15 loss: 0.9647095918655395\n",
            "LOSS train 0.9647095918655395\n",
            "EPOCH 19426:\n",
            "  batch 5 loss: 0.5328329652547836\n",
            "  batch 10 loss: 0.6906861655414105\n",
            "  batch 15 loss: 1.0169834852218629\n",
            "LOSS train 1.0169834852218629\n",
            "EPOCH 19427:\n",
            "  batch 5 loss: 0.4850157558917999\n",
            "  batch 10 loss: 0.7201022252440452\n",
            "  batch 15 loss: 0.6362662702798844\n",
            "LOSS train 0.6362662702798844\n",
            "EPOCH 19428:\n",
            "  batch 5 loss: 0.7168469905853272\n",
            "  batch 10 loss: 0.5664158701896668\n",
            "  batch 15 loss: 0.6583700537681579\n",
            "LOSS train 0.6583700537681579\n",
            "EPOCH 19429:\n",
            "  batch 5 loss: 0.8289210647344589\n",
            "  batch 10 loss: 0.7206233710050582\n",
            "  batch 15 loss: 0.7977567553520203\n",
            "LOSS train 0.7977567553520203\n",
            "EPOCH 19430:\n",
            "  batch 5 loss: 0.8366810619831085\n",
            "  batch 10 loss: 0.6266138762235641\n",
            "  batch 15 loss: 0.38746281564235685\n",
            "LOSS train 0.38746281564235685\n",
            "EPOCH 19431:\n",
            "  batch 5 loss: 0.770641416311264\n",
            "  batch 10 loss: 0.810197114944458\n",
            "  batch 15 loss: 0.6122920989990235\n",
            "LOSS train 0.6122920989990235\n",
            "EPOCH 19432:\n",
            "  batch 5 loss: 0.8368807405233383\n",
            "  batch 10 loss: 0.7011070787906647\n",
            "  batch 15 loss: 0.6929371297359467\n",
            "LOSS train 0.6929371297359467\n",
            "EPOCH 19433:\n",
            "  batch 5 loss: 0.8707720518112183\n",
            "  batch 10 loss: 0.729603236913681\n",
            "  batch 15 loss: 0.5505069047212601\n",
            "LOSS train 0.5505069047212601\n",
            "EPOCH 19434:\n",
            "  batch 5 loss: 0.9063213437795639\n",
            "  batch 10 loss: 0.5621412381529808\n",
            "  batch 15 loss: 1.0808131575584412\n",
            "LOSS train 1.0808131575584412\n",
            "EPOCH 19435:\n",
            "  batch 5 loss: 0.40189726613461974\n",
            "  batch 10 loss: 0.6076165556907653\n",
            "  batch 15 loss: 0.9694831371307373\n",
            "LOSS train 0.9694831371307373\n",
            "EPOCH 19436:\n",
            "  batch 5 loss: 0.6787056028842926\n",
            "  batch 10 loss: 0.6276409864425659\n",
            "  batch 15 loss: 1.0939184069633483\n",
            "LOSS train 1.0939184069633483\n",
            "EPOCH 19437:\n",
            "  batch 5 loss: 1.0295101642608642\n",
            "  batch 10 loss: 0.7513955861330033\n",
            "  batch 15 loss: 0.5397314772009849\n",
            "LOSS train 0.5397314772009849\n",
            "EPOCH 19438:\n",
            "  batch 5 loss: 0.9177853494882584\n",
            "  batch 10 loss: 0.7863011837005616\n",
            "  batch 15 loss: 0.8311858534812927\n",
            "LOSS train 0.8311858534812927\n",
            "EPOCH 19439:\n",
            "  batch 5 loss: 0.24534159302711486\n",
            "  batch 10 loss: 0.8351610779762269\n",
            "  batch 15 loss: 0.6102430522441864\n",
            "LOSS train 0.6102430522441864\n",
            "EPOCH 19440:\n",
            "  batch 5 loss: 0.748959219455719\n",
            "  batch 10 loss: 0.9363820672035217\n",
            "  batch 15 loss: 0.687275868654251\n",
            "LOSS train 0.687275868654251\n",
            "EPOCH 19441:\n",
            "  batch 5 loss: 0.5272838294506073\n",
            "  batch 10 loss: 0.4163507044315338\n",
            "  batch 15 loss: 0.5153276368975639\n",
            "LOSS train 0.5153276368975639\n",
            "EPOCH 19442:\n",
            "  batch 5 loss: 0.7152430176734924\n",
            "  batch 10 loss: 0.4952017992734909\n",
            "  batch 15 loss: 0.7076196908950806\n",
            "LOSS train 0.7076196908950806\n",
            "EPOCH 19443:\n",
            "  batch 5 loss: 0.5728057220578193\n",
            "  batch 10 loss: 0.8882128834724426\n",
            "  batch 15 loss: 0.5624888315796852\n",
            "LOSS train 0.5624888315796852\n",
            "EPOCH 19444:\n",
            "  batch 5 loss: 0.8770694255828857\n",
            "  batch 10 loss: 0.5001637101173401\n",
            "  batch 15 loss: 0.8738170385360717\n",
            "LOSS train 0.8738170385360717\n",
            "EPOCH 19445:\n",
            "  batch 5 loss: 0.6255252301692963\n",
            "  batch 10 loss: 0.716502171754837\n",
            "  batch 15 loss: 0.5691405840218067\n",
            "LOSS train 0.5691405840218067\n",
            "EPOCH 19446:\n",
            "  batch 5 loss: 0.7582060337066651\n",
            "  batch 10 loss: 0.7914238691329956\n",
            "  batch 15 loss: 1.046195101737976\n",
            "LOSS train 1.046195101737976\n",
            "EPOCH 19447:\n",
            "  batch 5 loss: 0.5505063191056252\n",
            "  batch 10 loss: 0.5242183819413185\n",
            "  batch 15 loss: 0.5211333632469177\n",
            "LOSS train 0.5211333632469177\n",
            "EPOCH 19448:\n",
            "  batch 5 loss: 0.8851408004760742\n",
            "  batch 10 loss: 0.6288641214370727\n",
            "  batch 15 loss: 0.6352693751454354\n",
            "LOSS train 0.6352693751454354\n",
            "EPOCH 19449:\n",
            "  batch 5 loss: 0.5612173557281495\n",
            "  batch 10 loss: 0.573691126704216\n",
            "  batch 15 loss: 0.6119183018803597\n",
            "LOSS train 0.6119183018803597\n",
            "EPOCH 19450:\n",
            "  batch 5 loss: 0.6374077677726746\n",
            "  batch 10 loss: 0.7818511605262757\n",
            "  batch 15 loss: 0.6158549845218658\n",
            "LOSS train 0.6158549845218658\n",
            "EPOCH 19451:\n",
            "  batch 5 loss: 0.9982105016708374\n",
            "  batch 10 loss: 0.8139092087745666\n",
            "  batch 15 loss: 1.0063123941421508\n",
            "LOSS train 1.0063123941421508\n",
            "EPOCH 19452:\n",
            "  batch 5 loss: 0.6186010360717773\n",
            "  batch 10 loss: 0.8832931995391846\n",
            "  batch 15 loss: 0.6837864093482494\n",
            "LOSS train 0.6837864093482494\n",
            "EPOCH 19453:\n",
            "  batch 5 loss: 0.6438400745391846\n",
            "  batch 10 loss: 0.7626817941665649\n",
            "  batch 15 loss: 0.852391904592514\n",
            "LOSS train 0.852391904592514\n",
            "EPOCH 19454:\n",
            "  batch 5 loss: 0.7624999403953552\n",
            "  batch 10 loss: 0.686170470714569\n",
            "  batch 15 loss: 0.5404589474201202\n",
            "LOSS train 0.5404589474201202\n",
            "EPOCH 19455:\n",
            "  batch 5 loss: 0.9237380146980285\n",
            "  batch 10 loss: 0.6756822943687439\n",
            "  batch 15 loss: 0.6159981422126293\n",
            "LOSS train 0.6159981422126293\n",
            "EPOCH 19456:\n",
            "  batch 5 loss: 0.6721575319766998\n",
            "  batch 10 loss: 0.672746104374528\n",
            "  batch 15 loss: 0.9106559455394745\n",
            "LOSS train 0.9106559455394745\n",
            "EPOCH 19457:\n",
            "  batch 5 loss: 0.9881308555603028\n",
            "  batch 10 loss: 0.7858363389968872\n",
            "  batch 15 loss: 0.8654249429702758\n",
            "LOSS train 0.8654249429702758\n",
            "EPOCH 19458:\n",
            "  batch 5 loss: 0.9179398000240326\n",
            "  batch 10 loss: 0.7163532018661499\n",
            "  batch 15 loss: 0.9219861328601837\n",
            "LOSS train 0.9219861328601837\n",
            "EPOCH 19459:\n",
            "  batch 5 loss: 1.2584885776042938\n",
            "  batch 10 loss: 0.3759804110974073\n",
            "  batch 15 loss: 0.6195131242275238\n",
            "LOSS train 0.6195131242275238\n",
            "EPOCH 19460:\n",
            "  batch 5 loss: 0.9920726180076599\n",
            "  batch 10 loss: 0.6400457039475441\n",
            "  batch 15 loss: 0.7333684742450715\n",
            "LOSS train 0.7333684742450715\n",
            "EPOCH 19461:\n",
            "  batch 5 loss: 0.6762805953621864\n",
            "  batch 10 loss: 0.8050657391548157\n",
            "  batch 15 loss: 0.7356611870229244\n",
            "LOSS train 0.7356611870229244\n",
            "EPOCH 19462:\n",
            "  batch 5 loss: 0.8303772211074829\n",
            "  batch 10 loss: 0.7830291807651519\n",
            "  batch 15 loss: 0.5284524828195571\n",
            "LOSS train 0.5284524828195571\n",
            "EPOCH 19463:\n",
            "  batch 5 loss: 0.7670089364051819\n",
            "  batch 10 loss: 0.5745931006968021\n",
            "  batch 15 loss: 0.9713892340660095\n",
            "LOSS train 0.9713892340660095\n",
            "EPOCH 19464:\n",
            "  batch 5 loss: 0.3774812027812004\n",
            "  batch 10 loss: 0.9676663756370545\n",
            "  batch 15 loss: 0.8205660879611969\n",
            "LOSS train 0.8205660879611969\n",
            "EPOCH 19465:\n",
            "  batch 5 loss: 0.6257356643676758\n",
            "  batch 10 loss: 0.8953314304351807\n",
            "  batch 15 loss: 0.8328157663345337\n",
            "LOSS train 0.8328157663345337\n",
            "EPOCH 19466:\n",
            "  batch 5 loss: 0.6931077003479004\n",
            "  batch 10 loss: 0.8186166405677795\n",
            "  batch 15 loss: 0.40439738929271696\n",
            "LOSS train 0.40439738929271696\n",
            "EPOCH 19467:\n",
            "  batch 5 loss: 0.7842386543750763\n",
            "  batch 10 loss: 0.6227385640144348\n",
            "  batch 15 loss: 0.8456143140792847\n",
            "LOSS train 0.8456143140792847\n",
            "EPOCH 19468:\n",
            "  batch 5 loss: 0.350506529211998\n",
            "  batch 10 loss: 0.8221163839101792\n",
            "  batch 15 loss: 0.5263045400381088\n",
            "LOSS train 0.5263045400381088\n",
            "EPOCH 19469:\n",
            "  batch 5 loss: 0.7745741307735443\n",
            "  batch 10 loss: 0.7726833581924438\n",
            "  batch 15 loss: 0.7998069047927856\n",
            "LOSS train 0.7998069047927856\n",
            "EPOCH 19470:\n",
            "  batch 5 loss: 0.3033438228070736\n",
            "  batch 10 loss: 0.7670166254043579\n",
            "  batch 15 loss: 0.6373105198144913\n",
            "LOSS train 0.6373105198144913\n",
            "EPOCH 19471:\n",
            "  batch 5 loss: 0.7754576146602631\n",
            "  batch 10 loss: 0.6586811542510986\n",
            "  batch 15 loss: 0.49072245955467225\n",
            "LOSS train 0.49072245955467225\n",
            "EPOCH 19472:\n",
            "  batch 5 loss: 0.45025329738855363\n",
            "  batch 10 loss: 0.6806011319160461\n",
            "  batch 15 loss: 0.969563341140747\n",
            "LOSS train 0.969563341140747\n",
            "EPOCH 19473:\n",
            "  batch 5 loss: 0.8261292338371277\n",
            "  batch 10 loss: 0.8538290977478027\n",
            "  batch 15 loss: 0.8799378335475921\n",
            "LOSS train 0.8799378335475921\n",
            "EPOCH 19474:\n",
            "  batch 5 loss: 0.6563639879226685\n",
            "  batch 10 loss: 0.7546026408672333\n",
            "  batch 15 loss: 0.9387298285961151\n",
            "LOSS train 0.9387298285961151\n",
            "EPOCH 19475:\n",
            "  batch 5 loss: 0.8762316167354584\n",
            "  batch 10 loss: 0.7319203317165375\n",
            "  batch 15 loss: 0.7810649812221527\n",
            "LOSS train 0.7810649812221527\n",
            "EPOCH 19476:\n",
            "  batch 5 loss: 0.9828703165054321\n",
            "  batch 10 loss: 0.7721200227737427\n",
            "  batch 15 loss: 0.5210158228874207\n",
            "LOSS train 0.5210158228874207\n",
            "EPOCH 19477:\n",
            "  batch 5 loss: 0.6886201143264771\n",
            "  batch 10 loss: 0.6718838334083557\n",
            "  batch 15 loss: 0.8656037002801895\n",
            "LOSS train 0.8656037002801895\n",
            "EPOCH 19478:\n",
            "  batch 5 loss: 0.5199674844741822\n",
            "  batch 10 loss: 0.6590767055749893\n",
            "  batch 15 loss: 0.6259036123752594\n",
            "LOSS train 0.6259036123752594\n",
            "EPOCH 19479:\n",
            "  batch 5 loss: 0.8127296328544616\n",
            "  batch 10 loss: 0.7091163188219071\n",
            "  batch 15 loss: 0.8224296271800995\n",
            "LOSS train 0.8224296271800995\n",
            "EPOCH 19480:\n",
            "  batch 5 loss: 0.6992255941033363\n",
            "  batch 10 loss: 0.8500452280044556\n",
            "  batch 15 loss: 0.6588090717792511\n",
            "LOSS train 0.6588090717792511\n",
            "EPOCH 19481:\n",
            "  batch 5 loss: 0.7300104886293411\n",
            "  batch 10 loss: 0.7163388833403588\n",
            "  batch 15 loss: 0.807174801826477\n",
            "LOSS train 0.807174801826477\n",
            "EPOCH 19482:\n",
            "  batch 5 loss: 0.529284444451332\n",
            "  batch 10 loss: 0.5177561521530152\n",
            "  batch 15 loss: 0.7553744077682495\n",
            "LOSS train 0.7553744077682495\n",
            "EPOCH 19483:\n",
            "  batch 5 loss: 0.8202035069465637\n",
            "  batch 10 loss: 0.7144641280174255\n",
            "  batch 15 loss: 0.813141143321991\n",
            "LOSS train 0.813141143321991\n",
            "EPOCH 19484:\n",
            "  batch 5 loss: 0.6191705703735352\n",
            "  batch 10 loss: 0.6437184274196625\n",
            "  batch 15 loss: 0.6903996288776397\n",
            "LOSS train 0.6903996288776397\n",
            "EPOCH 19485:\n",
            "  batch 5 loss: 0.8096801370382309\n",
            "  batch 10 loss: 0.5283631678670645\n",
            "  batch 15 loss: 0.594267138838768\n",
            "LOSS train 0.594267138838768\n",
            "EPOCH 19486:\n",
            "  batch 5 loss: 0.48191204816102984\n",
            "  batch 10 loss: 0.5444084838032722\n",
            "  batch 15 loss: 0.768224062025547\n",
            "LOSS train 0.768224062025547\n",
            "EPOCH 19487:\n",
            "  batch 5 loss: 0.4612997002899647\n",
            "  batch 10 loss: 0.2894684076309204\n",
            "  batch 15 loss: 0.5132894575595855\n",
            "LOSS train 0.5132894575595855\n",
            "EPOCH 19488:\n",
            "  batch 5 loss: 0.5317394435405731\n",
            "  batch 10 loss: 0.671518212556839\n",
            "  batch 15 loss: 0.6217434210702777\n",
            "LOSS train 0.6217434210702777\n",
            "EPOCH 19489:\n",
            "  batch 5 loss: 0.5429758816957474\n",
            "  batch 10 loss: 0.8405114233493804\n",
            "  batch 15 loss: 1.0846480667591094\n",
            "LOSS train 1.0846480667591094\n",
            "EPOCH 19490:\n",
            "  batch 5 loss: 0.6752847671508789\n",
            "  batch 10 loss: 0.5250119969248772\n",
            "  batch 15 loss: 0.6429829210042953\n",
            "LOSS train 0.6429829210042953\n",
            "EPOCH 19491:\n",
            "  batch 5 loss: 0.473759351670742\n",
            "  batch 10 loss: 0.6015135668218136\n",
            "  batch 15 loss: 0.6148764073848725\n",
            "LOSS train 0.6148764073848725\n",
            "EPOCH 19492:\n",
            "  batch 5 loss: 0.6940715342760087\n",
            "  batch 10 loss: 0.7264685869216919\n",
            "  batch 15 loss: 0.8070404171943665\n",
            "LOSS train 0.8070404171943665\n",
            "EPOCH 19493:\n",
            "  batch 5 loss: 0.7450643330812454\n",
            "  batch 10 loss: 0.40659809559583665\n",
            "  batch 15 loss: 0.791971641778946\n",
            "LOSS train 0.791971641778946\n",
            "EPOCH 19494:\n",
            "  batch 5 loss: 0.6700354784727096\n",
            "  batch 10 loss: 0.7903041839599609\n",
            "  batch 15 loss: 0.8871156811714173\n",
            "LOSS train 0.8871156811714173\n",
            "EPOCH 19495:\n",
            "  batch 5 loss: 0.7490597426891327\n",
            "  batch 10 loss: 0.5464763447642327\n",
            "  batch 15 loss: 0.7251130849123001\n",
            "LOSS train 0.7251130849123001\n",
            "EPOCH 19496:\n",
            "  batch 5 loss: 0.39215837568044665\n",
            "  batch 10 loss: 0.8774047255516052\n",
            "  batch 15 loss: 0.8445838689804077\n",
            "LOSS train 0.8445838689804077\n",
            "EPOCH 19497:\n",
            "  batch 5 loss: 0.6229267671704293\n",
            "  batch 10 loss: 0.5574184715747833\n",
            "  batch 15 loss: 0.524777190387249\n",
            "LOSS train 0.524777190387249\n",
            "EPOCH 19498:\n",
            "  batch 5 loss: 0.6100737757980823\n",
            "  batch 10 loss: 0.5282772906124592\n",
            "  batch 15 loss: 0.49847194105386733\n",
            "LOSS train 0.49847194105386733\n",
            "EPOCH 19499:\n",
            "  batch 5 loss: 0.49437286108732226\n",
            "  batch 10 loss: 0.35765166133642196\n",
            "  batch 15 loss: 0.7355072677135468\n",
            "LOSS train 0.7355072677135468\n",
            "EPOCH 19500:\n",
            "  batch 5 loss: 0.655009514093399\n",
            "  batch 10 loss: 0.8867897868156434\n",
            "  batch 15 loss: 0.7382604122161865\n",
            "LOSS train 0.7382604122161865\n",
            "EPOCH 19501:\n",
            "  batch 5 loss: 0.2804835647344589\n",
            "  batch 10 loss: 0.33639278411865237\n",
            "  batch 15 loss: 0.6605665475130081\n",
            "LOSS train 0.6605665475130081\n",
            "EPOCH 19502:\n",
            "  batch 5 loss: 0.7184510430321097\n",
            "  batch 10 loss: 0.5749825708568096\n",
            "  batch 15 loss: 0.27718493193387983\n",
            "LOSS train 0.27718493193387983\n",
            "EPOCH 19503:\n",
            "  batch 5 loss: 0.5360732406377793\n",
            "  batch 10 loss: 0.7737298786640168\n",
            "  batch 15 loss: 0.41817427761852743\n",
            "LOSS train 0.41817427761852743\n",
            "EPOCH 19504:\n",
            "  batch 5 loss: 0.9701874136924744\n",
            "  batch 10 loss: 0.4084627375006676\n",
            "  batch 15 loss: 0.6471343524754047\n",
            "LOSS train 0.6471343524754047\n",
            "EPOCH 19505:\n",
            "  batch 5 loss: 0.8726687788963318\n",
            "  batch 10 loss: 0.700135686993599\n",
            "  batch 15 loss: 0.8689530670642853\n",
            "LOSS train 0.8689530670642853\n",
            "EPOCH 19506:\n",
            "  batch 5 loss: 0.9610960721969605\n",
            "  batch 10 loss: 0.6456073313951493\n",
            "  batch 15 loss: 0.6500610262155533\n",
            "LOSS train 0.6500610262155533\n",
            "EPOCH 19507:\n",
            "  batch 5 loss: 0.8893119156360626\n",
            "  batch 10 loss: 0.7069173388183116\n",
            "  batch 15 loss: 1.0298868417739868\n",
            "LOSS train 1.0298868417739868\n",
            "EPOCH 19508:\n",
            "  batch 5 loss: 0.3666342802345753\n",
            "  batch 10 loss: 1.097893053293228\n",
            "  batch 15 loss: 0.8229202151298523\n",
            "LOSS train 0.8229202151298523\n",
            "EPOCH 19509:\n",
            "  batch 5 loss: 0.8729016780853271\n",
            "  batch 10 loss: 0.36704795658588407\n",
            "  batch 15 loss: 0.9874993801116944\n",
            "LOSS train 0.9874993801116944\n",
            "EPOCH 19510:\n",
            "  batch 5 loss: 0.7099845230579376\n",
            "  batch 10 loss: 0.9985804677009582\n",
            "  batch 15 loss: 0.36099144592881205\n",
            "LOSS train 0.36099144592881205\n",
            "EPOCH 19511:\n",
            "  batch 5 loss: 0.7138478755950928\n",
            "  batch 10 loss: 0.459380054473877\n",
            "  batch 15 loss: 0.825633880496025\n",
            "LOSS train 0.825633880496025\n",
            "EPOCH 19512:\n",
            "  batch 5 loss: 1.0699302554130554\n",
            "  batch 10 loss: 0.6840534090995789\n",
            "  batch 15 loss: 0.8954202890396118\n",
            "LOSS train 0.8954202890396118\n",
            "EPOCH 19513:\n",
            "  batch 5 loss: 0.5987784057855606\n",
            "  batch 10 loss: 0.9955040454864502\n",
            "  batch 15 loss: 1.1684179186820984\n",
            "LOSS train 1.1684179186820984\n",
            "EPOCH 19514:\n",
            "  batch 5 loss: 0.6824503540992737\n",
            "  batch 10 loss: 0.666226452589035\n",
            "  batch 15 loss: 0.8418040156364441\n",
            "LOSS train 0.8418040156364441\n",
            "EPOCH 19515:\n",
            "  batch 5 loss: 0.4735401000827551\n",
            "  batch 10 loss: 0.7852038502693176\n",
            "  batch 15 loss: 0.4891980767250061\n",
            "LOSS train 0.4891980767250061\n",
            "EPOCH 19516:\n",
            "  batch 5 loss: 0.6658661663532257\n",
            "  batch 10 loss: 0.8635878920555115\n",
            "  batch 15 loss: 0.7145051240921021\n",
            "LOSS train 0.7145051240921021\n",
            "EPOCH 19517:\n",
            "  batch 5 loss: 0.816659277677536\n",
            "  batch 10 loss: 0.7975658416748047\n",
            "  batch 15 loss: 0.7800804823637009\n",
            "LOSS train 0.7800804823637009\n",
            "EPOCH 19518:\n",
            "  batch 5 loss: 0.5590502828359604\n",
            "  batch 10 loss: 0.7828279107809066\n",
            "  batch 15 loss: 0.5930189669132233\n",
            "LOSS train 0.5930189669132233\n",
            "EPOCH 19519:\n",
            "  batch 5 loss: 0.6590313971042633\n",
            "  batch 10 loss: 0.752156549692154\n",
            "  batch 15 loss: 0.3382054504007101\n",
            "LOSS train 0.3382054504007101\n",
            "EPOCH 19520:\n",
            "  batch 5 loss: 0.7685360252857208\n",
            "  batch 10 loss: 0.692210453748703\n",
            "  batch 15 loss: 0.6774942249059677\n",
            "LOSS train 0.6774942249059677\n",
            "EPOCH 19521:\n",
            "  batch 5 loss: 1.0108617186546325\n",
            "  batch 10 loss: 0.9614941000938415\n",
            "  batch 15 loss: 0.4512497067451477\n",
            "LOSS train 0.4512497067451477\n",
            "EPOCH 19522:\n",
            "  batch 5 loss: 0.5997411668300628\n",
            "  batch 10 loss: 0.5624728456139565\n",
            "  batch 15 loss: 0.7971389055252075\n",
            "LOSS train 0.7971389055252075\n",
            "EPOCH 19523:\n",
            "  batch 5 loss: 0.8916207253932953\n",
            "  batch 10 loss: 0.6322714537382126\n",
            "  batch 15 loss: 0.8961430966854096\n",
            "LOSS train 0.8961430966854096\n",
            "EPOCH 19524:\n",
            "  batch 5 loss: 0.49961466789245607\n",
            "  batch 10 loss: 0.6779437720775604\n",
            "  batch 15 loss: 0.661545242369175\n",
            "LOSS train 0.661545242369175\n",
            "EPOCH 19525:\n",
            "  batch 5 loss: 0.833337339758873\n",
            "  batch 10 loss: 0.534809323400259\n",
            "  batch 15 loss: 1.0112288475036622\n",
            "LOSS train 1.0112288475036622\n",
            "EPOCH 19526:\n",
            "  batch 5 loss: 0.8290844917297363\n",
            "  batch 10 loss: 0.9348354816436768\n",
            "  batch 15 loss: 0.7147737920284272\n",
            "LOSS train 0.7147737920284272\n",
            "EPOCH 19527:\n",
            "  batch 5 loss: 0.7652980625629425\n",
            "  batch 10 loss: 0.9039756298065186\n",
            "  batch 15 loss: 0.42605786621570585\n",
            "LOSS train 0.42605786621570585\n",
            "EPOCH 19528:\n",
            "  batch 5 loss: 0.5844403624534606\n",
            "  batch 10 loss: 0.8099149525165558\n",
            "  batch 15 loss: 0.7797684151679277\n",
            "LOSS train 0.7797684151679277\n",
            "EPOCH 19529:\n",
            "  batch 5 loss: 0.5968759536743165\n",
            "  batch 10 loss: 0.7012067854404449\n",
            "  batch 15 loss: 0.6780849240720273\n",
            "LOSS train 0.6780849240720273\n",
            "EPOCH 19530:\n",
            "  batch 5 loss: 0.7261041894555091\n",
            "  batch 10 loss: 0.6068067908287048\n",
            "  batch 15 loss: 0.9052035510540009\n",
            "LOSS train 0.9052035510540009\n",
            "EPOCH 19531:\n",
            "  batch 5 loss: 0.8293850839138031\n",
            "  batch 10 loss: 0.6832391291856765\n",
            "  batch 15 loss: 0.7565155461430549\n",
            "LOSS train 0.7565155461430549\n",
            "EPOCH 19532:\n",
            "  batch 5 loss: 0.465668135881424\n",
            "  batch 10 loss: 0.5694119572639466\n",
            "  batch 15 loss: 0.4651780441403389\n",
            "LOSS train 0.4651780441403389\n",
            "EPOCH 19533:\n",
            "  batch 5 loss: 0.6300261616706848\n",
            "  batch 10 loss: 0.6264785706996918\n",
            "  batch 15 loss: 1.009963321685791\n",
            "LOSS train 1.009963321685791\n",
            "EPOCH 19534:\n",
            "  batch 5 loss: 0.785479086637497\n",
            "  batch 10 loss: 1.0351216197013855\n",
            "  batch 15 loss: 0.49232242405414584\n",
            "LOSS train 0.49232242405414584\n",
            "EPOCH 19535:\n",
            "  batch 5 loss: 0.7052478909492492\n",
            "  batch 10 loss: 0.9687010526657105\n",
            "  batch 15 loss: 0.9935878276824951\n",
            "LOSS train 0.9935878276824951\n",
            "EPOCH 19536:\n",
            "  batch 5 loss: 0.5438610434532165\n",
            "  batch 10 loss: 0.701062622666359\n",
            "  batch 15 loss: 0.9487715363502502\n",
            "LOSS train 0.9487715363502502\n",
            "EPOCH 19537:\n",
            "  batch 5 loss: 1.2590009331703187\n",
            "  batch 10 loss: 0.7457266747951508\n",
            "  batch 15 loss: 1.1290789008140565\n",
            "LOSS train 1.1290789008140565\n",
            "EPOCH 19538:\n",
            "  batch 5 loss: 0.7432318091392517\n",
            "  batch 10 loss: 0.5634760856628418\n",
            "  batch 15 loss: 1.0405426442623138\n",
            "LOSS train 1.0405426442623138\n",
            "EPOCH 19539:\n",
            "  batch 5 loss: 0.5981888175010681\n",
            "  batch 10 loss: 0.8047770619392395\n",
            "  batch 15 loss: 0.699630719423294\n",
            "LOSS train 0.699630719423294\n",
            "EPOCH 19540:\n",
            "  batch 5 loss: 0.23559131994843482\n",
            "  batch 10 loss: 0.6976991593837738\n",
            "  batch 15 loss: 0.5940383732318878\n",
            "LOSS train 0.5940383732318878\n",
            "EPOCH 19541:\n",
            "  batch 5 loss: 0.31149806678295133\n",
            "  batch 10 loss: 0.6254323959350586\n",
            "  batch 15 loss: 0.5074753940105439\n",
            "LOSS train 0.5074753940105439\n",
            "EPOCH 19542:\n",
            "  batch 5 loss: 0.576087811589241\n",
            "  batch 10 loss: 0.7514484405517579\n",
            "  batch 15 loss: 0.501451164484024\n",
            "LOSS train 0.501451164484024\n",
            "EPOCH 19543:\n",
            "  batch 5 loss: 0.7038787961006164\n",
            "  batch 10 loss: 0.6186249285936356\n",
            "  batch 15 loss: 0.6810743808746338\n",
            "LOSS train 0.6810743808746338\n",
            "EPOCH 19544:\n",
            "  batch 5 loss: 1.0114100694656372\n",
            "  batch 10 loss: 0.7998322010040283\n",
            "  batch 15 loss: 0.2391753986477852\n",
            "LOSS train 0.2391753986477852\n",
            "EPOCH 19545:\n",
            "  batch 5 loss: 0.7854483723640442\n",
            "  batch 10 loss: 0.6022996485233307\n",
            "  batch 15 loss: 0.70097716152668\n",
            "LOSS train 0.70097716152668\n",
            "EPOCH 19546:\n",
            "  batch 5 loss: 0.7627025842666626\n",
            "  batch 10 loss: 0.6811073869466782\n",
            "  batch 15 loss: 0.49358142018318174\n",
            "LOSS train 0.49358142018318174\n",
            "EPOCH 19547:\n",
            "  batch 5 loss: 0.6109845578670502\n",
            "  batch 10 loss: 0.7378976702690124\n",
            "  batch 15 loss: 0.46536241471767426\n",
            "LOSS train 0.46536241471767426\n",
            "EPOCH 19548:\n",
            "  batch 5 loss: 0.8925594568252564\n",
            "  batch 10 loss: 0.3946930646896362\n",
            "  batch 15 loss: 0.5104279592633247\n",
            "LOSS train 0.5104279592633247\n",
            "EPOCH 19549:\n",
            "  batch 5 loss: 0.8119953393936157\n",
            "  batch 10 loss: 0.45525973066687586\n",
            "  batch 15 loss: 0.8944515347480774\n",
            "LOSS train 0.8944515347480774\n",
            "EPOCH 19550:\n",
            "  batch 5 loss: 0.8904317796230317\n",
            "  batch 10 loss: 0.7541374385356903\n",
            "  batch 15 loss: 0.8238431274890899\n",
            "LOSS train 0.8238431274890899\n",
            "EPOCH 19551:\n",
            "  batch 5 loss: 0.8407390236854553\n",
            "  batch 10 loss: 0.7002876743674278\n",
            "  batch 15 loss: 1.1053989052772522\n",
            "LOSS train 1.1053989052772522\n",
            "EPOCH 19552:\n",
            "  batch 5 loss: 1.0616804957389832\n",
            "  batch 10 loss: 0.9149624109268188\n",
            "  batch 15 loss: 0.5922104597091675\n",
            "LOSS train 0.5922104597091675\n",
            "EPOCH 19553:\n",
            "  batch 5 loss: 0.5969975680112839\n",
            "  batch 10 loss: 0.6443156898021698\n",
            "  batch 15 loss: 0.8603818744421006\n",
            "LOSS train 0.8603818744421006\n",
            "EPOCH 19554:\n",
            "  batch 5 loss: 0.9537296533584595\n",
            "  batch 10 loss: 0.6690182149410248\n",
            "  batch 15 loss: 0.5118145018815994\n",
            "LOSS train 0.5118145018815994\n",
            "EPOCH 19555:\n",
            "  batch 5 loss: 0.6579593300819397\n",
            "  batch 10 loss: 0.8155556201934815\n",
            "  batch 15 loss: 0.47176446616649625\n",
            "LOSS train 0.47176446616649625\n",
            "EPOCH 19556:\n",
            "  batch 5 loss: 0.5850176334381103\n",
            "  batch 10 loss: 0.9058276891708374\n",
            "  batch 15 loss: 0.6379467368125915\n",
            "LOSS train 0.6379467368125915\n",
            "EPOCH 19557:\n",
            "  batch 5 loss: 0.9357092976570129\n",
            "  batch 10 loss: 0.5339791297912597\n",
            "  batch 15 loss: 0.7604526042938232\n",
            "LOSS train 0.7604526042938232\n",
            "EPOCH 19558:\n",
            "  batch 5 loss: 0.6538345992565155\n",
            "  batch 10 loss: 0.6043952882289887\n",
            "  batch 15 loss: 0.5667285814881324\n",
            "LOSS train 0.5667285814881324\n",
            "EPOCH 19559:\n",
            "  batch 5 loss: 0.8248780131340027\n",
            "  batch 10 loss: 0.48697321563959123\n",
            "  batch 15 loss: 0.6327850699424744\n",
            "LOSS train 0.6327850699424744\n",
            "EPOCH 19560:\n",
            "  batch 5 loss: 0.48906956911087035\n",
            "  batch 10 loss: 0.8374057054519654\n",
            "  batch 15 loss: 0.4477353483438492\n",
            "LOSS train 0.4477353483438492\n",
            "EPOCH 19561:\n",
            "  batch 5 loss: 0.46247617341578007\n",
            "  batch 10 loss: 0.828831958770752\n",
            "  batch 15 loss: 0.5806668102741241\n",
            "LOSS train 0.5806668102741241\n",
            "EPOCH 19562:\n",
            "  batch 5 loss: 0.5012917533516884\n",
            "  batch 10 loss: 0.8198005378246307\n",
            "  batch 15 loss: 0.6973309427499771\n",
            "LOSS train 0.6973309427499771\n",
            "EPOCH 19563:\n",
            "  batch 5 loss: 1.0442843198776246\n",
            "  batch 10 loss: 0.5844660237431526\n",
            "  batch 15 loss: 1.1371642351150513\n",
            "LOSS train 1.1371642351150513\n",
            "EPOCH 19564:\n",
            "  batch 5 loss: 0.4679111957550049\n",
            "  batch 10 loss: 0.6097425043582916\n",
            "  batch 15 loss: 0.6414579346776008\n",
            "LOSS train 0.6414579346776008\n",
            "EPOCH 19565:\n",
            "  batch 5 loss: 0.5025917395949364\n",
            "  batch 10 loss: 0.6703217029571533\n",
            "  batch 15 loss: 0.5422423243522644\n",
            "LOSS train 0.5422423243522644\n",
            "EPOCH 19566:\n",
            "  batch 5 loss: 1.125109314918518\n",
            "  batch 10 loss: 0.6232291013002396\n",
            "  batch 15 loss: 0.7894559860229492\n",
            "LOSS train 0.7894559860229492\n",
            "EPOCH 19567:\n",
            "  batch 5 loss: 0.7457491338253022\n",
            "  batch 10 loss: 0.780162638425827\n",
            "  batch 15 loss: 0.5227058105170727\n",
            "LOSS train 0.5227058105170727\n",
            "EPOCH 19568:\n",
            "  batch 5 loss: 0.5936327755451203\n",
            "  batch 10 loss: 0.7771086782217026\n",
            "  batch 15 loss: 1.020052295923233\n",
            "LOSS train 1.020052295923233\n",
            "EPOCH 19569:\n",
            "  batch 5 loss: 0.5488799333572387\n",
            "  batch 10 loss: 0.32622637078166006\n",
            "  batch 15 loss: 0.7656834453344346\n",
            "LOSS train 0.7656834453344346\n",
            "EPOCH 19570:\n",
            "  batch 5 loss: 0.5724851042032242\n",
            "  batch 10 loss: 0.7012402921915054\n",
            "  batch 15 loss: 0.7381101965904235\n",
            "LOSS train 0.7381101965904235\n",
            "EPOCH 19571:\n",
            "  batch 5 loss: 0.5753673255443573\n",
            "  batch 10 loss: 0.7467639885842801\n",
            "  batch 15 loss: 0.872623187303543\n",
            "LOSS train 0.872623187303543\n",
            "EPOCH 19572:\n",
            "  batch 5 loss: 0.35314587205648423\n",
            "  batch 10 loss: 0.833320826292038\n",
            "  batch 15 loss: 0.7817044019699096\n",
            "LOSS train 0.7817044019699096\n",
            "EPOCH 19573:\n",
            "  batch 5 loss: 0.9875871121883393\n",
            "  batch 10 loss: 0.5740166217088699\n",
            "  batch 15 loss: 0.6930159881711007\n",
            "LOSS train 0.6930159881711007\n",
            "EPOCH 19574:\n",
            "  batch 5 loss: 0.9993810057640076\n",
            "  batch 10 loss: 0.61514941919595\n",
            "  batch 15 loss: 0.37979171276092527\n",
            "LOSS train 0.37979171276092527\n",
            "EPOCH 19575:\n",
            "  batch 5 loss: 0.5336146235466004\n",
            "  batch 10 loss: 0.5810583613812923\n",
            "  batch 15 loss: 0.6904703214764595\n",
            "LOSS train 0.6904703214764595\n",
            "EPOCH 19576:\n",
            "  batch 5 loss: 0.8660719275474549\n",
            "  batch 10 loss: 0.4859041154384613\n",
            "  batch 15 loss: 0.48814062476158143\n",
            "LOSS train 0.48814062476158143\n",
            "EPOCH 19577:\n",
            "  batch 5 loss: 0.6885829508304596\n",
            "  batch 10 loss: 0.5609380565583706\n",
            "  batch 15 loss: 0.699896651506424\n",
            "LOSS train 0.699896651506424\n",
            "EPOCH 19578:\n",
            "  batch 5 loss: 0.4801465094089508\n",
            "  batch 10 loss: 0.8119143486022949\n",
            "  batch 15 loss: 0.47216705083847044\n",
            "LOSS train 0.47216705083847044\n",
            "EPOCH 19579:\n",
            "  batch 5 loss: 1.0829011082649231\n",
            "  batch 10 loss: 0.6816900491714477\n",
            "  batch 15 loss: 0.6279199540615081\n",
            "LOSS train 0.6279199540615081\n",
            "EPOCH 19580:\n",
            "  batch 5 loss: 0.9330041766166687\n",
            "  batch 10 loss: 0.6711867332458497\n",
            "  batch 15 loss: 0.6221908330917358\n",
            "LOSS train 0.6221908330917358\n",
            "EPOCH 19581:\n",
            "  batch 5 loss: 0.5701606184244156\n",
            "  batch 10 loss: 0.46466018706560136\n",
            "  batch 15 loss: 0.7090804509818553\n",
            "LOSS train 0.7090804509818553\n",
            "EPOCH 19582:\n",
            "  batch 5 loss: 0.7725474119186402\n",
            "  batch 10 loss: 0.6403785780072212\n",
            "  batch 15 loss: 0.7236105799674988\n",
            "LOSS train 0.7236105799674988\n",
            "EPOCH 19583:\n",
            "  batch 5 loss: 0.6541749954223632\n",
            "  batch 10 loss: 0.4958323746919632\n",
            "  batch 15 loss: 0.43307124078273773\n",
            "LOSS train 0.43307124078273773\n",
            "EPOCH 19584:\n",
            "  batch 5 loss: 0.7589763581752778\n",
            "  batch 10 loss: 0.7765254989266396\n",
            "  batch 15 loss: 0.560743747651577\n",
            "LOSS train 0.560743747651577\n",
            "EPOCH 19585:\n",
            "  batch 5 loss: 0.5235770300030709\n",
            "  batch 10 loss: 0.6086994394659996\n",
            "  batch 15 loss: 0.7371806830167771\n",
            "LOSS train 0.7371806830167771\n",
            "EPOCH 19586:\n",
            "  batch 5 loss: 0.7246439933776856\n",
            "  batch 10 loss: 0.7605504222214222\n",
            "  batch 15 loss: 0.6508621215820313\n",
            "LOSS train 0.6508621215820313\n",
            "EPOCH 19587:\n",
            "  batch 5 loss: 0.557594508677721\n",
            "  batch 10 loss: 0.994482958316803\n",
            "  batch 15 loss: 0.5194016605615616\n",
            "LOSS train 0.5194016605615616\n",
            "EPOCH 19588:\n",
            "  batch 5 loss: 0.5403618946671486\n",
            "  batch 10 loss: 0.9462954282760621\n",
            "  batch 15 loss: 0.7888611197471619\n",
            "LOSS train 0.7888611197471619\n",
            "EPOCH 19589:\n",
            "  batch 5 loss: 0.5999959468841553\n",
            "  batch 10 loss: 0.7027217745780945\n",
            "  batch 15 loss: 0.7320343554019928\n",
            "LOSS train 0.7320343554019928\n",
            "EPOCH 19590:\n",
            "  batch 5 loss: 0.7427011370658875\n",
            "  batch 10 loss: 0.8805935919284821\n",
            "  batch 15 loss: 0.8228406608104706\n",
            "LOSS train 0.8228406608104706\n",
            "EPOCH 19591:\n",
            "  batch 5 loss: 0.6041090592741967\n",
            "  batch 10 loss: 0.7798141062259674\n",
            "  batch 15 loss: 0.5165720462799073\n",
            "LOSS train 0.5165720462799073\n",
            "EPOCH 19592:\n",
            "  batch 5 loss: 0.9146948754787445\n",
            "  batch 10 loss: 0.5526026278734207\n",
            "  batch 15 loss: 0.3782769083976746\n",
            "LOSS train 0.3782769083976746\n",
            "EPOCH 19593:\n",
            "  batch 5 loss: 0.835673189163208\n",
            "  batch 10 loss: 0.702406159043312\n",
            "  batch 15 loss: 1.093866193294525\n",
            "LOSS train 1.093866193294525\n",
            "EPOCH 19594:\n",
            "  batch 5 loss: 1.0646284580230714\n",
            "  batch 10 loss: 0.7294837653636932\n",
            "  batch 15 loss: 0.7719034850597382\n",
            "LOSS train 0.7719034850597382\n",
            "EPOCH 19595:\n",
            "  batch 5 loss: 0.7057610005140305\n",
            "  batch 10 loss: 0.847144627571106\n",
            "  batch 15 loss: 0.5483631826937199\n",
            "LOSS train 0.5483631826937199\n",
            "EPOCH 19596:\n",
            "  batch 5 loss: 0.7563485592603684\n",
            "  batch 10 loss: 0.9640932679176331\n",
            "  batch 15 loss: 0.8518369525671006\n",
            "LOSS train 0.8518369525671006\n",
            "EPOCH 19597:\n",
            "  batch 5 loss: 0.7506027355790138\n",
            "  batch 10 loss: 0.8110595583915711\n",
            "  batch 15 loss: 0.491666641831398\n",
            "LOSS train 0.491666641831398\n",
            "EPOCH 19598:\n",
            "  batch 5 loss: 1.0441578865051269\n",
            "  batch 10 loss: 0.6678187489509583\n",
            "  batch 15 loss: 0.7594842076301574\n",
            "LOSS train 0.7594842076301574\n",
            "EPOCH 19599:\n",
            "  batch 5 loss: 0.7627828925848007\n",
            "  batch 10 loss: 0.6873922169208526\n",
            "  batch 15 loss: 0.7711949646472931\n",
            "LOSS train 0.7711949646472931\n",
            "EPOCH 19600:\n",
            "  batch 5 loss: 1.1563795894384383\n",
            "  batch 10 loss: 0.8810485228896141\n",
            "  batch 15 loss: 0.6763867676258087\n",
            "LOSS train 0.6763867676258087\n",
            "EPOCH 19601:\n",
            "  batch 5 loss: 0.6402703240513802\n",
            "  batch 10 loss: 0.8149155527353287\n",
            "  batch 15 loss: 0.6872317790985107\n",
            "LOSS train 0.6872317790985107\n",
            "EPOCH 19602:\n",
            "  batch 5 loss: 0.7307599902153015\n",
            "  batch 10 loss: 0.5833400800824166\n",
            "  batch 15 loss: 0.7037831231951713\n",
            "LOSS train 0.7037831231951713\n",
            "EPOCH 19603:\n",
            "  batch 5 loss: 0.7647217750549317\n",
            "  batch 10 loss: 0.6010754451155662\n",
            "  batch 15 loss: 0.8534734129905701\n",
            "LOSS train 0.8534734129905701\n",
            "EPOCH 19604:\n",
            "  batch 5 loss: 0.9125665783882141\n",
            "  batch 10 loss: 0.7608195602893829\n",
            "  batch 15 loss: 0.742435522377491\n",
            "LOSS train 0.742435522377491\n",
            "EPOCH 19605:\n",
            "  batch 5 loss: 0.7882286012172699\n",
            "  batch 10 loss: 0.8769913196563721\n",
            "  batch 15 loss: 0.5160829335451126\n",
            "LOSS train 0.5160829335451126\n",
            "EPOCH 19606:\n",
            "  batch 5 loss: 0.9785504758358001\n",
            "  batch 10 loss: 0.3695539399981499\n",
            "  batch 15 loss: 0.5300831377506257\n",
            "LOSS train 0.5300831377506257\n",
            "EPOCH 19607:\n",
            "  batch 5 loss: 0.6505960762500763\n",
            "  batch 10 loss: 0.8086124181747436\n",
            "  batch 15 loss: 0.8393989086151123\n",
            "LOSS train 0.8393989086151123\n",
            "EPOCH 19608:\n",
            "  batch 5 loss: 0.6822274148464202\n",
            "  batch 10 loss: 0.5668019145727158\n",
            "  batch 15 loss: 0.6826960742473602\n",
            "LOSS train 0.6826960742473602\n",
            "EPOCH 19609:\n",
            "  batch 5 loss: 0.8049783736467362\n",
            "  batch 10 loss: 0.6560236692428589\n",
            "  batch 15 loss: 0.973988676071167\n",
            "LOSS train 0.973988676071167\n",
            "EPOCH 19610:\n",
            "  batch 5 loss: 0.51936576962471\n",
            "  batch 10 loss: 0.5079492330551147\n",
            "  batch 15 loss: 0.7335636973381042\n",
            "LOSS train 0.7335636973381042\n",
            "EPOCH 19611:\n",
            "  batch 5 loss: 0.5169397026300431\n",
            "  batch 10 loss: 0.9035377919673919\n",
            "  batch 15 loss: 0.7610926404595375\n",
            "LOSS train 0.7610926404595375\n",
            "EPOCH 19612:\n",
            "  batch 5 loss: 0.6615789126604795\n",
            "  batch 10 loss: 0.653333255648613\n",
            "  batch 15 loss: 0.6510546743869782\n",
            "LOSS train 0.6510546743869782\n",
            "EPOCH 19613:\n",
            "  batch 5 loss: 0.8793465778231621\n",
            "  batch 10 loss: 0.8812880098819733\n",
            "  batch 15 loss: 0.7514529585838318\n",
            "LOSS train 0.7514529585838318\n",
            "EPOCH 19614:\n",
            "  batch 5 loss: 0.6308889418840409\n",
            "  batch 10 loss: 0.912934410572052\n",
            "  batch 15 loss: 0.7053733244538307\n",
            "LOSS train 0.7053733244538307\n",
            "EPOCH 19615:\n",
            "  batch 5 loss: 0.7519493937492371\n",
            "  batch 10 loss: 0.5563373953104019\n",
            "  batch 15 loss: 0.617335544526577\n",
            "LOSS train 0.617335544526577\n",
            "EPOCH 19616:\n",
            "  batch 5 loss: 0.8030099511146546\n",
            "  batch 10 loss: 0.40041608512401583\n",
            "  batch 15 loss: 0.5165885124355555\n",
            "LOSS train 0.5165885124355555\n",
            "EPOCH 19617:\n",
            "  batch 5 loss: 0.6527493372559547\n",
            "  batch 10 loss: 0.76585623472929\n",
            "  batch 15 loss: 0.5665401831269264\n",
            "LOSS train 0.5665401831269264\n",
            "EPOCH 19618:\n",
            "  batch 5 loss: 0.9829727292060852\n",
            "  batch 10 loss: 0.6311608195304871\n",
            "  batch 15 loss: 0.746141517162323\n",
            "LOSS train 0.746141517162323\n",
            "EPOCH 19619:\n",
            "  batch 5 loss: 0.47451701313257216\n",
            "  batch 10 loss: 0.6912157505750656\n",
            "  batch 15 loss: 0.7004140093922615\n",
            "LOSS train 0.7004140093922615\n",
            "EPOCH 19620:\n",
            "  batch 5 loss: 0.31411510780453683\n",
            "  batch 10 loss: 0.3728883922100067\n",
            "  batch 15 loss: 0.8172282502055168\n",
            "LOSS train 0.8172282502055168\n",
            "EPOCH 19621:\n",
            "  batch 5 loss: 0.5525092780590057\n",
            "  batch 10 loss: 0.6900760442018509\n",
            "  batch 15 loss: 0.9030534908175468\n",
            "LOSS train 0.9030534908175468\n",
            "EPOCH 19622:\n",
            "  batch 5 loss: 0.6888641864061356\n",
            "  batch 10 loss: 0.6271734371781349\n",
            "  batch 15 loss: 0.6531052231788635\n",
            "LOSS train 0.6531052231788635\n",
            "EPOCH 19623:\n",
            "  batch 5 loss: 0.7209279209375381\n",
            "  batch 10 loss: 1.1268348932266234\n",
            "  batch 15 loss: 0.2279554173350334\n",
            "LOSS train 0.2279554173350334\n",
            "EPOCH 19624:\n",
            "  batch 5 loss: 0.6339044213294983\n",
            "  batch 10 loss: 0.4841859444975853\n",
            "  batch 15 loss: 0.6013185545802117\n",
            "LOSS train 0.6013185545802117\n",
            "EPOCH 19625:\n",
            "  batch 5 loss: 0.6917722672224045\n",
            "  batch 10 loss: 0.5954567819833756\n",
            "  batch 15 loss: 0.541151212900877\n",
            "LOSS train 0.541151212900877\n",
            "EPOCH 19626:\n",
            "  batch 5 loss: 0.6467072442173958\n",
            "  batch 10 loss: 0.7788042545318603\n",
            "  batch 15 loss: 0.827574861049652\n",
            "LOSS train 0.827574861049652\n",
            "EPOCH 19627:\n",
            "  batch 5 loss: 0.5687391251325608\n",
            "  batch 10 loss: 0.7149365395307541\n",
            "  batch 15 loss: 0.6695369243621826\n",
            "LOSS train 0.6695369243621826\n",
            "EPOCH 19628:\n",
            "  batch 5 loss: 0.39998691380023954\n",
            "  batch 10 loss: 0.6507621645927429\n",
            "  batch 15 loss: 0.6897257924079895\n",
            "LOSS train 0.6897257924079895\n",
            "EPOCH 19629:\n",
            "  batch 5 loss: 0.39361637160182\n",
            "  batch 10 loss: 1.0056290030479431\n",
            "  batch 15 loss: 0.5748005211353302\n",
            "LOSS train 0.5748005211353302\n",
            "EPOCH 19630:\n",
            "  batch 5 loss: 0.9068829536437988\n",
            "  batch 10 loss: 0.5598163798451423\n",
            "  batch 15 loss: 0.7403241872787476\n",
            "LOSS train 0.7403241872787476\n",
            "EPOCH 19631:\n",
            "  batch 5 loss: 0.7951655417680741\n",
            "  batch 10 loss: 0.4865262404084206\n",
            "  batch 15 loss: 0.6916414737701416\n",
            "LOSS train 0.6916414737701416\n",
            "EPOCH 19632:\n",
            "  batch 5 loss: 0.9572845578193665\n",
            "  batch 10 loss: 0.49303220510482787\n",
            "  batch 15 loss: 0.6923910081386566\n",
            "LOSS train 0.6923910081386566\n",
            "EPOCH 19633:\n",
            "  batch 5 loss: 0.6187649488449096\n",
            "  batch 10 loss: 0.5579996168613434\n",
            "  batch 15 loss: 0.7660440921783447\n",
            "LOSS train 0.7660440921783447\n",
            "EPOCH 19634:\n",
            "  batch 5 loss: 0.6208294630050659\n",
            "  batch 10 loss: 0.9441594362258912\n",
            "  batch 15 loss: 0.5371561944484711\n",
            "LOSS train 0.5371561944484711\n",
            "EPOCH 19635:\n",
            "  batch 5 loss: 0.6883303180336953\n",
            "  batch 10 loss: 0.803325766324997\n",
            "  batch 15 loss: 1.0192613124847412\n",
            "LOSS train 1.0192613124847412\n",
            "EPOCH 19636:\n",
            "  batch 5 loss: 0.3956256821751595\n",
            "  batch 10 loss: 0.8946828007698059\n",
            "  batch 15 loss: 0.820257169008255\n",
            "LOSS train 0.820257169008255\n",
            "EPOCH 19637:\n",
            "  batch 5 loss: 0.44066222906112673\n",
            "  batch 10 loss: 0.7013460665941238\n",
            "  batch 15 loss: 0.700705224275589\n",
            "LOSS train 0.700705224275589\n",
            "EPOCH 19638:\n",
            "  batch 5 loss: 0.45917758345603943\n",
            "  batch 10 loss: 0.4332507334649563\n",
            "  batch 15 loss: 0.52075896859169\n",
            "LOSS train 0.52075896859169\n",
            "EPOCH 19639:\n",
            "  batch 5 loss: 0.8051296830177307\n",
            "  batch 10 loss: 0.7864800274372101\n",
            "  batch 15 loss: 0.7153647117316723\n",
            "LOSS train 0.7153647117316723\n",
            "EPOCH 19640:\n",
            "  batch 5 loss: 0.829513555765152\n",
            "  batch 10 loss: 0.4181658625602722\n",
            "  batch 15 loss: 0.4763468042016029\n",
            "LOSS train 0.4763468042016029\n",
            "EPOCH 19641:\n",
            "  batch 5 loss: 0.6867664873600006\n",
            "  batch 10 loss: 0.9219099640846252\n",
            "  batch 15 loss: 1.025436782836914\n",
            "LOSS train 1.025436782836914\n",
            "EPOCH 19642:\n",
            "  batch 5 loss: 0.5440398663282394\n",
            "  batch 10 loss: 0.6978898257017135\n",
            "  batch 15 loss: 0.284728467464447\n",
            "LOSS train 0.284728467464447\n",
            "EPOCH 19643:\n",
            "  batch 5 loss: 0.5307845592498779\n",
            "  batch 10 loss: 0.558802655339241\n",
            "  batch 15 loss: 4.683635753393173\n",
            "LOSS train 4.683635753393173\n",
            "EPOCH 19644:\n",
            "  batch 5 loss: 0.9246427595615387\n",
            "  batch 10 loss: 0.9352561593055725\n",
            "  batch 15 loss: 0.7080347239971161\n",
            "LOSS train 0.7080347239971161\n",
            "EPOCH 19645:\n",
            "  batch 5 loss: 0.614791838824749\n",
            "  batch 10 loss: 0.7704832315444946\n",
            "  batch 15 loss: 0.493735234439373\n",
            "LOSS train 0.493735234439373\n",
            "EPOCH 19646:\n",
            "  batch 5 loss: 0.6782487154006958\n",
            "  batch 10 loss: 0.41136965379118917\n",
            "  batch 15 loss: 0.4710341185331345\n",
            "LOSS train 0.4710341185331345\n",
            "EPOCH 19647:\n",
            "  batch 5 loss: 0.8089902937412262\n",
            "  batch 10 loss: 0.52823536247015\n",
            "  batch 15 loss: 0.9363980174064637\n",
            "LOSS train 0.9363980174064637\n",
            "EPOCH 19648:\n",
            "  batch 5 loss: 0.5088554330170154\n",
            "  batch 10 loss: 1.1032371163368224\n",
            "  batch 15 loss: 0.9051763474941253\n",
            "LOSS train 0.9051763474941253\n",
            "EPOCH 19649:\n",
            "  batch 5 loss: 0.5129125207662583\n",
            "  batch 10 loss: 0.389999595656991\n",
            "  batch 15 loss: 0.4996082052588463\n",
            "LOSS train 0.4996082052588463\n",
            "EPOCH 19650:\n",
            "  batch 5 loss: 0.8668716557323932\n",
            "  batch 10 loss: 0.6208099167793989\n",
            "  batch 15 loss: 0.7716076374053955\n",
            "LOSS train 0.7716076374053955\n",
            "EPOCH 19651:\n",
            "  batch 5 loss: 0.5600180864334107\n",
            "  batch 10 loss: 0.6843886822462082\n",
            "  batch 15 loss: 0.8946232441812754\n",
            "LOSS train 0.8946232441812754\n",
            "EPOCH 19652:\n",
            "  batch 5 loss: 0.8376960575580596\n",
            "  batch 10 loss: 0.7934971511363983\n",
            "  batch 15 loss: 0.8749886393547058\n",
            "LOSS train 0.8749886393547058\n",
            "EPOCH 19653:\n",
            "  batch 5 loss: 0.8239850968122482\n",
            "  batch 10 loss: 0.7354070544242859\n",
            "  batch 15 loss: 0.7852471619844437\n",
            "LOSS train 0.7852471619844437\n",
            "EPOCH 19654:\n",
            "  batch 5 loss: 0.7034489870071411\n",
            "  batch 10 loss: 0.4139650590717793\n",
            "  batch 15 loss: 0.9066097021102906\n",
            "LOSS train 0.9066097021102906\n",
            "EPOCH 19655:\n",
            "  batch 5 loss: 0.5829090237617492\n",
            "  batch 10 loss: 1.0467017889022827\n",
            "  batch 15 loss: 0.817956292629242\n",
            "LOSS train 0.817956292629242\n",
            "EPOCH 19656:\n",
            "  batch 5 loss: 0.5661054976284504\n",
            "  batch 10 loss: 0.5946287140250206\n",
            "  batch 15 loss: 0.9081140518188476\n",
            "LOSS train 0.9081140518188476\n",
            "EPOCH 19657:\n",
            "  batch 5 loss: 0.8908531785011291\n",
            "  batch 10 loss: 0.47356752678751945\n",
            "  batch 15 loss: 0.6824464112520218\n",
            "LOSS train 0.6824464112520218\n",
            "EPOCH 19658:\n",
            "  batch 5 loss: 0.6019131004810333\n",
            "  batch 10 loss: 0.4491157948970795\n",
            "  batch 15 loss: 0.8483455657958985\n",
            "LOSS train 0.8483455657958985\n",
            "EPOCH 19659:\n",
            "  batch 5 loss: 0.5698834419250488\n",
            "  batch 10 loss: 0.4691642239689827\n",
            "  batch 15 loss: 0.7712310969829559\n",
            "LOSS train 0.7712310969829559\n",
            "EPOCH 19660:\n",
            "  batch 5 loss: 0.7300039827823639\n",
            "  batch 10 loss: 0.798104214668274\n",
            "  batch 15 loss: 0.978362774848938\n",
            "LOSS train 0.978362774848938\n",
            "EPOCH 19661:\n",
            "  batch 5 loss: 0.8340818285942078\n",
            "  batch 10 loss: 0.6449639573693275\n",
            "  batch 15 loss: 0.5884415000677109\n",
            "LOSS train 0.5884415000677109\n",
            "EPOCH 19662:\n",
            "  batch 5 loss: 0.5314628347754479\n",
            "  batch 10 loss: 0.6185977458953857\n",
            "  batch 15 loss: 0.7333607196807861\n",
            "LOSS train 0.7333607196807861\n",
            "EPOCH 19663:\n",
            "  batch 5 loss: 0.7317771062254905\n",
            "  batch 10 loss: 0.6632427215576172\n",
            "  batch 15 loss: 0.8145846784114837\n",
            "LOSS train 0.8145846784114837\n",
            "EPOCH 19664:\n",
            "  batch 5 loss: 0.7184617817401886\n",
            "  batch 10 loss: 0.8204469561576844\n",
            "  batch 15 loss: 0.6094880610704422\n",
            "LOSS train 0.6094880610704422\n",
            "EPOCH 19665:\n",
            "  batch 5 loss: 0.95171217918396\n",
            "  batch 10 loss: 0.6666767477989197\n",
            "  batch 15 loss: 0.5563829451799392\n",
            "LOSS train 0.5563829451799392\n",
            "EPOCH 19666:\n",
            "  batch 5 loss: 0.6088195532560349\n",
            "  batch 10 loss: 0.4752149611711502\n",
            "  batch 15 loss: 0.4873708814382553\n",
            "LOSS train 0.4873708814382553\n",
            "EPOCH 19667:\n",
            "  batch 5 loss: 0.5636217067018151\n",
            "  batch 10 loss: 0.6875712871551514\n",
            "  batch 15 loss: 0.757768589258194\n",
            "LOSS train 0.757768589258194\n",
            "EPOCH 19668:\n",
            "  batch 5 loss: 0.7384418487548828\n",
            "  batch 10 loss: 0.787503445148468\n",
            "  batch 15 loss: 0.6453634560108185\n",
            "LOSS train 0.6453634560108185\n",
            "EPOCH 19669:\n",
            "  batch 5 loss: 0.4787485182285309\n",
            "  batch 10 loss: 0.8050656914710999\n",
            "  batch 15 loss: 0.3471993885934353\n",
            "LOSS train 0.3471993885934353\n",
            "EPOCH 19670:\n",
            "  batch 5 loss: 0.49326992928981783\n",
            "  batch 10 loss: 0.6742951989173889\n",
            "  batch 15 loss: 0.3886351466178894\n",
            "LOSS train 0.3886351466178894\n",
            "EPOCH 19671:\n",
            "  batch 5 loss: 0.9094795942306518\n",
            "  batch 10 loss: 0.404533139243722\n",
            "  batch 15 loss: 0.9445143431425095\n",
            "LOSS train 0.9445143431425095\n",
            "EPOCH 19672:\n",
            "  batch 5 loss: 0.404001259803772\n",
            "  batch 10 loss: 1.0745755672454833\n",
            "  batch 15 loss: 0.5137728199362754\n",
            "LOSS train 0.5137728199362754\n",
            "EPOCH 19673:\n",
            "  batch 5 loss: 0.7676994740962982\n",
            "  batch 10 loss: 0.7710843801498413\n",
            "  batch 15 loss: 0.8213204085826874\n",
            "LOSS train 0.8213204085826874\n",
            "EPOCH 19674:\n",
            "  batch 5 loss: 0.7308153927326202\n",
            "  batch 10 loss: 0.8036064386367798\n",
            "  batch 15 loss: 1.0272953510284424\n",
            "LOSS train 1.0272953510284424\n",
            "EPOCH 19675:\n",
            "  batch 5 loss: 0.7005700916051865\n",
            "  batch 10 loss: 1.045894491672516\n",
            "  batch 15 loss: 0.5047622412443161\n",
            "LOSS train 0.5047622412443161\n",
            "EPOCH 19676:\n",
            "  batch 5 loss: 0.837429141998291\n",
            "  batch 10 loss: 0.9096297144889831\n",
            "  batch 15 loss: 0.9305099844932556\n",
            "LOSS train 0.9305099844932556\n",
            "EPOCH 19677:\n",
            "  batch 5 loss: 1.2898211121559142\n",
            "  batch 10 loss: 0.6429958641529083\n",
            "  batch 15 loss: 0.553997403383255\n",
            "LOSS train 0.553997403383255\n",
            "EPOCH 19678:\n",
            "  batch 5 loss: 0.5511457651853562\n",
            "  batch 10 loss: 0.9274664759635926\n",
            "  batch 15 loss: 0.6553557485342025\n",
            "LOSS train 0.6553557485342025\n",
            "EPOCH 19679:\n",
            "  batch 5 loss: 0.6263534426689148\n",
            "  batch 10 loss: 0.7876509964466095\n",
            "  batch 15 loss: 0.5694234609603882\n",
            "LOSS train 0.5694234609603882\n",
            "EPOCH 19680:\n",
            "  batch 5 loss: 0.8856816530227661\n",
            "  batch 10 loss: 0.7844010591506958\n",
            "  batch 15 loss: 0.5184909641742707\n",
            "LOSS train 0.5184909641742707\n",
            "EPOCH 19681:\n",
            "  batch 5 loss: 0.4596246087923646\n",
            "  batch 10 loss: 0.8537176012992859\n",
            "  batch 15 loss: 0.5465500861406326\n",
            "LOSS train 0.5465500861406326\n",
            "EPOCH 19682:\n",
            "  batch 5 loss: 0.963811719417572\n",
            "  batch 10 loss: 0.8873738706111908\n",
            "  batch 15 loss: 0.7902469396591186\n",
            "LOSS train 0.7902469396591186\n",
            "EPOCH 19683:\n",
            "  batch 5 loss: 0.5763789057731629\n",
            "  batch 10 loss: 0.7108496844768524\n",
            "  batch 15 loss: 0.5849672615528106\n",
            "LOSS train 0.5849672615528106\n",
            "EPOCH 19684:\n",
            "  batch 5 loss: 0.6811367869377136\n",
            "  batch 10 loss: 0.6680764228105545\n",
            "  batch 15 loss: 0.7380725383758545\n",
            "LOSS train 0.7380725383758545\n",
            "EPOCH 19685:\n",
            "  batch 5 loss: 0.304594586789608\n",
            "  batch 10 loss: 0.6889863580465316\n",
            "  batch 15 loss: 0.8455809772014617\n",
            "LOSS train 0.8455809772014617\n",
            "EPOCH 19686:\n",
            "  batch 5 loss: 0.7408456489443779\n",
            "  batch 10 loss: 0.7475171625614166\n",
            "  batch 15 loss: 0.49460662603378297\n",
            "LOSS train 0.49460662603378297\n",
            "EPOCH 19687:\n",
            "  batch 5 loss: 0.5167170912027359\n",
            "  batch 10 loss: 0.7399475574493408\n",
            "  batch 15 loss: 0.556291377171874\n",
            "LOSS train 0.556291377171874\n",
            "EPOCH 19688:\n",
            "  batch 5 loss: 1.006185030937195\n",
            "  batch 10 loss: 0.6722161889076232\n",
            "  batch 15 loss: 0.9083401024341583\n",
            "LOSS train 0.9083401024341583\n",
            "EPOCH 19689:\n",
            "  batch 5 loss: 0.5286238670349122\n",
            "  batch 10 loss: 0.32155347764492037\n",
            "  batch 15 loss: 0.571710216999054\n",
            "LOSS train 0.571710216999054\n",
            "EPOCH 19690:\n",
            "  batch 5 loss: 0.3763187378644943\n",
            "  batch 10 loss: 0.6824900925159454\n",
            "  batch 15 loss: 1.0457343578338623\n",
            "LOSS train 1.0457343578338623\n",
            "EPOCH 19691:\n",
            "  batch 5 loss: 0.8507000625133514\n",
            "  batch 10 loss: 0.4668265223503113\n",
            "  batch 15 loss: 0.7498385965824127\n",
            "LOSS train 0.7498385965824127\n",
            "EPOCH 19692:\n",
            "  batch 5 loss: 0.5548726320266724\n",
            "  batch 10 loss: 0.9624737501144409\n",
            "  batch 15 loss: 1.024306458234787\n",
            "LOSS train 1.024306458234787\n",
            "EPOCH 19693:\n",
            "  batch 5 loss: 0.8436389207839966\n",
            "  batch 10 loss: 0.5787826992571354\n",
            "  batch 15 loss: 0.7593620743602514\n",
            "LOSS train 0.7593620743602514\n",
            "EPOCH 19694:\n",
            "  batch 5 loss: 0.6574173666536808\n",
            "  batch 10 loss: 0.5480808615684509\n",
            "  batch 15 loss: 0.7320050358772278\n",
            "LOSS train 0.7320050358772278\n",
            "EPOCH 19695:\n",
            "  batch 5 loss: 0.7510957747697831\n",
            "  batch 10 loss: 0.7395058751106263\n",
            "  batch 15 loss: 0.4156208664178848\n",
            "LOSS train 0.4156208664178848\n",
            "EPOCH 19696:\n",
            "  batch 5 loss: 0.6800762325525284\n",
            "  batch 10 loss: 0.4565344799309969\n",
            "  batch 15 loss: 0.42450130879879\n",
            "LOSS train 0.42450130879879\n",
            "EPOCH 19697:\n",
            "  batch 5 loss: 0.629307109117508\n",
            "  batch 10 loss: 0.7200982362031937\n",
            "  batch 15 loss: 0.6883291117846966\n",
            "LOSS train 0.6883291117846966\n",
            "EPOCH 19698:\n",
            "  batch 5 loss: 0.6021800510585308\n",
            "  batch 10 loss: 0.6083528518676757\n",
            "  batch 15 loss: 0.8140493154525756\n",
            "LOSS train 0.8140493154525756\n",
            "EPOCH 19699:\n",
            "  batch 5 loss: 0.6925040245056152\n",
            "  batch 10 loss: 0.7949866056442261\n",
            "  batch 15 loss: 0.8613116979598999\n",
            "LOSS train 0.8613116979598999\n",
            "EPOCH 19700:\n",
            "  batch 5 loss: 0.8287719503045082\n",
            "  batch 10 loss: 0.7975102663040161\n",
            "  batch 15 loss: 0.9550219297409057\n",
            "LOSS train 0.9550219297409057\n",
            "EPOCH 19701:\n",
            "  batch 5 loss: 0.6469284474849701\n",
            "  batch 10 loss: 0.555556683242321\n",
            "  batch 15 loss: 0.8735739827156067\n",
            "LOSS train 0.8735739827156067\n",
            "EPOCH 19702:\n",
            "  batch 5 loss: 0.3797426074743271\n",
            "  batch 10 loss: 0.7166961431503296\n",
            "  batch 15 loss: 0.8969455242156983\n",
            "LOSS train 0.8969455242156983\n",
            "EPOCH 19703:\n",
            "  batch 5 loss: 0.7325319848954678\n",
            "  batch 10 loss: 0.6158287182450295\n",
            "  batch 15 loss: 0.6117048263549805\n",
            "LOSS train 0.6117048263549805\n",
            "EPOCH 19704:\n",
            "  batch 5 loss: 0.5806567192077636\n",
            "  batch 10 loss: 0.6989172667264938\n",
            "  batch 15 loss: 0.5311213046312332\n",
            "LOSS train 0.5311213046312332\n",
            "EPOCH 19705:\n",
            "  batch 5 loss: 0.8614708423614502\n",
            "  batch 10 loss: 0.5794796705245971\n",
            "  batch 15 loss: 0.7045773059129715\n",
            "LOSS train 0.7045773059129715\n",
            "EPOCH 19706:\n",
            "  batch 5 loss: 0.6264628887176513\n",
            "  batch 10 loss: 0.583362845890224\n",
            "  batch 15 loss: 0.6737665414810181\n",
            "LOSS train 0.6737665414810181\n",
            "EPOCH 19707:\n",
            "  batch 5 loss: 1.0294028997421265\n",
            "  batch 10 loss: 0.4428928568959236\n",
            "  batch 15 loss: 0.527584183216095\n",
            "LOSS train 0.527584183216095\n",
            "EPOCH 19708:\n",
            "  batch 5 loss: 0.7295860201120377\n",
            "  batch 10 loss: 0.537355762720108\n",
            "  batch 15 loss: 0.36986895352602006\n",
            "LOSS train 0.36986895352602006\n",
            "EPOCH 19709:\n",
            "  batch 5 loss: 0.4665845885872841\n",
            "  batch 10 loss: 0.5947354078292847\n",
            "  batch 15 loss: 0.7608308464288711\n",
            "LOSS train 0.7608308464288711\n",
            "EPOCH 19710:\n",
            "  batch 5 loss: 0.8069900035858154\n",
            "  batch 10 loss: 0.807903242111206\n",
            "  batch 15 loss: 0.863441675901413\n",
            "LOSS train 0.863441675901413\n",
            "EPOCH 19711:\n",
            "  batch 5 loss: 0.6972409009933471\n",
            "  batch 10 loss: 0.6727944977581501\n",
            "  batch 15 loss: 0.8054429799318313\n",
            "LOSS train 0.8054429799318313\n",
            "EPOCH 19712:\n",
            "  batch 5 loss: 0.9917505741119385\n",
            "  batch 10 loss: 0.4949301093816757\n",
            "  batch 15 loss: 1.2885325133800507\n",
            "LOSS train 1.2885325133800507\n",
            "EPOCH 19713:\n",
            "  batch 5 loss: 0.36536129117012023\n",
            "  batch 10 loss: 0.5850877195596695\n",
            "  batch 15 loss: 0.43883351385593417\n",
            "LOSS train 0.43883351385593417\n",
            "EPOCH 19714:\n",
            "  batch 5 loss: 0.7566863894462585\n",
            "  batch 10 loss: 0.874185386300087\n",
            "  batch 15 loss: 0.45043542683124543\n",
            "LOSS train 0.45043542683124543\n",
            "EPOCH 19715:\n",
            "  batch 5 loss: 0.8946552634239197\n",
            "  batch 10 loss: 1.236897075176239\n",
            "  batch 15 loss: 0.6861747741699219\n",
            "LOSS train 0.6861747741699219\n",
            "EPOCH 19716:\n",
            "  batch 5 loss: 0.5953495472669601\n",
            "  batch 10 loss: 0.6816741824150085\n",
            "  batch 15 loss: 0.9206392645835877\n",
            "LOSS train 0.9206392645835877\n",
            "EPOCH 19717:\n",
            "  batch 5 loss: 0.5940415002405643\n",
            "  batch 10 loss: 0.5338256478309631\n",
            "  batch 15 loss: 0.7331412315368653\n",
            "LOSS train 0.7331412315368653\n",
            "EPOCH 19718:\n",
            "  batch 5 loss: 0.6546195209026336\n",
            "  batch 10 loss: 0.572246128320694\n",
            "  batch 15 loss: 0.7596846938133239\n",
            "LOSS train 0.7596846938133239\n",
            "EPOCH 19719:\n",
            "  batch 5 loss: 0.6136322513222694\n",
            "  batch 10 loss: 0.590632626414299\n",
            "  batch 15 loss: 0.8711876988410949\n",
            "LOSS train 0.8711876988410949\n",
            "EPOCH 19720:\n",
            "  batch 5 loss: 0.7476561598479747\n",
            "  batch 10 loss: 0.9512804716825485\n",
            "  batch 15 loss: 0.6450016528367997\n",
            "LOSS train 0.6450016528367997\n",
            "EPOCH 19721:\n",
            "  batch 5 loss: 0.44853284358978274\n",
            "  batch 10 loss: 0.3761133275926113\n",
            "  batch 15 loss: 0.5425035573542119\n",
            "LOSS train 0.5425035573542119\n",
            "EPOCH 19722:\n",
            "  batch 5 loss: 0.6170358091592789\n",
            "  batch 10 loss: 0.7491030395030975\n",
            "  batch 15 loss: 0.6734140977263451\n",
            "LOSS train 0.6734140977263451\n",
            "EPOCH 19723:\n",
            "  batch 5 loss: 0.6553640842437745\n",
            "  batch 10 loss: 0.6622866719961167\n",
            "  batch 15 loss: 0.6316788077354432\n",
            "LOSS train 0.6316788077354432\n",
            "EPOCH 19724:\n",
            "  batch 5 loss: 0.9096561312675476\n",
            "  batch 10 loss: 0.3013354778289795\n",
            "  batch 15 loss: 0.7358028411865234\n",
            "LOSS train 0.7358028411865234\n",
            "EPOCH 19725:\n",
            "  batch 5 loss: 0.8305686712265015\n",
            "  batch 10 loss: 0.849741455540061\n",
            "  batch 15 loss: 0.7570165693759918\n",
            "LOSS train 0.7570165693759918\n",
            "EPOCH 19726:\n",
            "  batch 5 loss: 0.7366962403059005\n",
            "  batch 10 loss: 0.61468003988266\n",
            "  batch 15 loss: 0.5325746238231659\n",
            "LOSS train 0.5325746238231659\n",
            "EPOCH 19727:\n",
            "  batch 5 loss: 0.681418365240097\n",
            "  batch 10 loss: 0.7267324179410934\n",
            "  batch 15 loss: 0.6173523366451263\n",
            "LOSS train 0.6173523366451263\n",
            "EPOCH 19728:\n",
            "  batch 5 loss: 0.8614248275756836\n",
            "  batch 10 loss: 0.7994719922542572\n",
            "  batch 15 loss: 0.5875064324587583\n",
            "LOSS train 0.5875064324587583\n",
            "EPOCH 19729:\n",
            "  batch 5 loss: 0.571378655731678\n",
            "  batch 10 loss: 0.5432996779680253\n",
            "  batch 15 loss: 0.6720501236617565\n",
            "LOSS train 0.6720501236617565\n",
            "EPOCH 19730:\n",
            "  batch 5 loss: 0.7561499595642089\n",
            "  batch 10 loss: 0.4673102289438248\n",
            "  batch 15 loss: 0.6020513415336609\n",
            "LOSS train 0.6020513415336609\n",
            "EPOCH 19731:\n",
            "  batch 5 loss: 0.7266346186399459\n",
            "  batch 10 loss: 0.7500984832644463\n",
            "  batch 15 loss: 0.6785227321088314\n",
            "LOSS train 0.6785227321088314\n",
            "EPOCH 19732:\n",
            "  batch 5 loss: 0.6391187399625778\n",
            "  batch 10 loss: 1.0358882069587707\n",
            "  batch 15 loss: 0.6189706802368165\n",
            "LOSS train 0.6189706802368165\n",
            "EPOCH 19733:\n",
            "  batch 5 loss: 0.5325659692287446\n",
            "  batch 10 loss: 0.6544636800885201\n",
            "  batch 15 loss: 0.6382422909140587\n",
            "LOSS train 0.6382422909140587\n",
            "EPOCH 19734:\n",
            "  batch 5 loss: 0.5949653148651123\n",
            "  batch 10 loss: 0.6948467135429383\n",
            "  batch 15 loss: 0.47030481696128845\n",
            "LOSS train 0.47030481696128845\n",
            "EPOCH 19735:\n",
            "  batch 5 loss: 0.7414314270019531\n",
            "  batch 10 loss: 0.8405576109886169\n",
            "  batch 15 loss: 0.788384860754013\n",
            "LOSS train 0.788384860754013\n",
            "EPOCH 19736:\n",
            "  batch 5 loss: 0.697229415178299\n",
            "  batch 10 loss: 0.363797502964735\n",
            "  batch 15 loss: 0.679859672486782\n",
            "LOSS train 0.679859672486782\n",
            "EPOCH 19737:\n",
            "  batch 5 loss: 0.47418463677167894\n",
            "  batch 10 loss: 0.7467496752738952\n",
            "  batch 15 loss: 0.5132985413074493\n",
            "LOSS train 0.5132985413074493\n",
            "EPOCH 19738:\n",
            "  batch 5 loss: 0.9313824117183686\n",
            "  batch 10 loss: 1.0230906128883361\n",
            "  batch 15 loss: 0.718618419766426\n",
            "LOSS train 0.718618419766426\n",
            "EPOCH 19739:\n",
            "  batch 5 loss: 0.5426369160413742\n",
            "  batch 10 loss: 0.897675895690918\n",
            "  batch 15 loss: 1.0701610803604127\n",
            "LOSS train 1.0701610803604127\n",
            "EPOCH 19740:\n",
            "  batch 5 loss: 0.5737924069166184\n",
            "  batch 10 loss: 0.7159914612770081\n",
            "  batch 15 loss: 0.727340042591095\n",
            "LOSS train 0.727340042591095\n",
            "EPOCH 19741:\n",
            "  batch 5 loss: 0.7182628333568573\n",
            "  batch 10 loss: 0.7705964207649231\n",
            "  batch 15 loss: 0.639478349685669\n",
            "LOSS train 0.639478349685669\n",
            "EPOCH 19742:\n",
            "  batch 5 loss: 0.6766491264104844\n",
            "  batch 10 loss: 0.812922990322113\n",
            "  batch 15 loss: 1.032607328891754\n",
            "LOSS train 1.032607328891754\n",
            "EPOCH 19743:\n",
            "  batch 5 loss: 0.6491800010204315\n",
            "  batch 10 loss: 0.7004987925291062\n",
            "  batch 15 loss: 0.7791294693946839\n",
            "LOSS train 0.7791294693946839\n",
            "EPOCH 19744:\n",
            "  batch 5 loss: 0.9568858742713928\n",
            "  batch 10 loss: 0.48533459901809695\n",
            "  batch 15 loss: 0.953249704837799\n",
            "LOSS train 0.953249704837799\n",
            "EPOCH 19745:\n",
            "  batch 5 loss: 0.7566561937332154\n",
            "  batch 10 loss: 0.7856836974620819\n",
            "  batch 15 loss: 0.8890254676342011\n",
            "LOSS train 0.8890254676342011\n",
            "EPOCH 19746:\n",
            "  batch 5 loss: 0.8425682604312896\n",
            "  batch 10 loss: 0.45437185615301134\n",
            "  batch 15 loss: 0.6899178333580493\n",
            "LOSS train 0.6899178333580493\n",
            "EPOCH 19747:\n",
            "  batch 5 loss: 0.5559478655457497\n",
            "  batch 10 loss: 0.5706932187080384\n",
            "  batch 15 loss: 0.5980218276381493\n",
            "LOSS train 0.5980218276381493\n",
            "EPOCH 19748:\n",
            "  batch 5 loss: 0.6320751905441284\n",
            "  batch 10 loss: 0.48845252841711045\n",
            "  batch 15 loss: 0.987784492969513\n",
            "LOSS train 0.987784492969513\n",
            "EPOCH 19749:\n",
            "  batch 5 loss: 0.8027165662497282\n",
            "  batch 10 loss: 0.6440351843833924\n",
            "  batch 15 loss: 0.9362453341484069\n",
            "LOSS train 0.9362453341484069\n",
            "EPOCH 19750:\n",
            "  batch 5 loss: 0.6899414479732513\n",
            "  batch 10 loss: 0.5608183059841394\n",
            "  batch 15 loss: 0.7613508880138398\n",
            "LOSS train 0.7613508880138398\n",
            "EPOCH 19751:\n",
            "  batch 5 loss: 0.4775647960603237\n",
            "  batch 10 loss: 0.6393587231636048\n",
            "  batch 15 loss: 0.7601834200322628\n",
            "LOSS train 0.7601834200322628\n",
            "EPOCH 19752:\n",
            "  batch 5 loss: 1.0381174564361573\n",
            "  batch 10 loss: 0.7525927901268006\n",
            "  batch 15 loss: 0.82424236536026\n",
            "LOSS train 0.82424236536026\n",
            "EPOCH 19753:\n",
            "  batch 5 loss: 0.7139676600694657\n",
            "  batch 10 loss: 0.953031861782074\n",
            "  batch 15 loss: 0.7054542571306228\n",
            "LOSS train 0.7054542571306228\n",
            "EPOCH 19754:\n",
            "  batch 5 loss: 0.6210986524820328\n",
            "  batch 10 loss: 0.8317798137664795\n",
            "  batch 15 loss: 0.7299501478672028\n",
            "LOSS train 0.7299501478672028\n",
            "EPOCH 19755:\n",
            "  batch 5 loss: 0.4664912447333336\n",
            "  batch 10 loss: 0.6245777159929276\n",
            "  batch 15 loss: 0.6252227649092674\n",
            "LOSS train 0.6252227649092674\n",
            "EPOCH 19756:\n",
            "  batch 5 loss: 0.8264375627040863\n",
            "  batch 10 loss: 0.794177120923996\n",
            "  batch 15 loss: 0.5705883800983429\n",
            "LOSS train 0.5705883800983429\n",
            "EPOCH 19757:\n",
            "  batch 5 loss: 0.5576110750436782\n",
            "  batch 10 loss: 0.801139485836029\n",
            "  batch 15 loss: 0.6927699580788612\n",
            "LOSS train 0.6927699580788612\n",
            "EPOCH 19758:\n",
            "  batch 5 loss: 0.8968008279800415\n",
            "  batch 10 loss: 0.9952621400356293\n",
            "  batch 15 loss: 0.6650798916816711\n",
            "LOSS train 0.6650798916816711\n",
            "EPOCH 19759:\n",
            "  batch 5 loss: 0.7592009529471397\n",
            "  batch 10 loss: 0.8659715592861176\n",
            "  batch 15 loss: 0.4859322052448988\n",
            "LOSS train 0.4859322052448988\n",
            "EPOCH 19760:\n",
            "  batch 5 loss: 0.48590863943099977\n",
            "  batch 10 loss: 0.5630273401737214\n",
            "  batch 15 loss: 0.6183717399835587\n",
            "LOSS train 0.6183717399835587\n",
            "EPOCH 19761:\n",
            "  batch 5 loss: 1.157775604724884\n",
            "  batch 10 loss: 0.5603967890143394\n",
            "  batch 15 loss: 1.1199837923049927\n",
            "LOSS train 1.1199837923049927\n",
            "EPOCH 19762:\n",
            "  batch 5 loss: 0.3794809378683567\n",
            "  batch 10 loss: 0.7744455218315125\n",
            "  batch 15 loss: 0.43686541020870207\n",
            "LOSS train 0.43686541020870207\n",
            "EPOCH 19763:\n",
            "  batch 5 loss: 0.6421554744243622\n",
            "  batch 10 loss: 0.7832747042179108\n",
            "  batch 15 loss: 0.566301453113556\n",
            "LOSS train 0.566301453113556\n",
            "EPOCH 19764:\n",
            "  batch 5 loss: 1.1083211183547974\n",
            "  batch 10 loss: 0.5432617425918579\n",
            "  batch 15 loss: 0.8932866513729095\n",
            "LOSS train 0.8932866513729095\n",
            "EPOCH 19765:\n",
            "  batch 5 loss: 0.5566735006868839\n",
            "  batch 10 loss: 0.45064142942428587\n",
            "  batch 15 loss: 0.5809740900993348\n",
            "LOSS train 0.5809740900993348\n",
            "EPOCH 19766:\n",
            "  batch 5 loss: 0.6566960960626602\n",
            "  batch 10 loss: 0.8515447854995728\n",
            "  batch 15 loss: 0.9229477941989899\n",
            "LOSS train 0.9229477941989899\n",
            "EPOCH 19767:\n",
            "  batch 5 loss: 0.7666612863540649\n",
            "  batch 10 loss: 0.6222854793071747\n",
            "  batch 15 loss: 0.660148561000824\n",
            "LOSS train 0.660148561000824\n",
            "EPOCH 19768:\n",
            "  batch 5 loss: 0.7191911861300468\n",
            "  batch 10 loss: 0.7995838224887848\n",
            "  batch 15 loss: 1.040318763256073\n",
            "LOSS train 1.040318763256073\n",
            "EPOCH 19769:\n",
            "  batch 5 loss: 1.0806999802589417\n",
            "  batch 10 loss: 0.39070869982242584\n",
            "  batch 15 loss: 0.6700970888137817\n",
            "LOSS train 0.6700970888137817\n",
            "EPOCH 19770:\n",
            "  batch 5 loss: 0.5574213847517967\n",
            "  batch 10 loss: 0.5288837313652038\n",
            "  batch 15 loss: 0.9528754830360413\n",
            "LOSS train 0.9528754830360413\n",
            "EPOCH 19771:\n",
            "  batch 5 loss: 0.7314543008804322\n",
            "  batch 10 loss: 0.49567733108997347\n",
            "  batch 15 loss: 0.6233797967433929\n",
            "LOSS train 0.6233797967433929\n",
            "EPOCH 19772:\n",
            "  batch 5 loss: 0.5485273003578186\n",
            "  batch 10 loss: 0.5023294225335121\n",
            "  batch 15 loss: 0.6199492111802101\n",
            "LOSS train 0.6199492111802101\n",
            "EPOCH 19773:\n",
            "  batch 5 loss: 0.4143431603908539\n",
            "  batch 10 loss: 0.9954335570335389\n",
            "  batch 15 loss: 0.828667402267456\n",
            "LOSS train 0.828667402267456\n",
            "EPOCH 19774:\n",
            "  batch 5 loss: 0.5356315031647683\n",
            "  batch 10 loss: 0.6562858849763871\n",
            "  batch 15 loss: 0.6050914004445076\n",
            "LOSS train 0.6050914004445076\n",
            "EPOCH 19775:\n",
            "  batch 5 loss: 1.038783860206604\n",
            "  batch 10 loss: 0.8434927463531494\n",
            "  batch 15 loss: 0.7896893084049225\n",
            "LOSS train 0.7896893084049225\n",
            "EPOCH 19776:\n",
            "  batch 5 loss: 1.2087742924690246\n",
            "  batch 10 loss: 0.8037719666957855\n",
            "  batch 15 loss: 0.465322744846344\n",
            "LOSS train 0.465322744846344\n",
            "EPOCH 19777:\n",
            "  batch 5 loss: 0.32003098726272583\n",
            "  batch 10 loss: 0.9047774586826562\n",
            "  batch 15 loss: 0.5109184116125107\n",
            "LOSS train 0.5109184116125107\n",
            "EPOCH 19778:\n",
            "  batch 5 loss: 0.6436339855194092\n",
            "  batch 10 loss: 0.6335961699485779\n",
            "  batch 15 loss: 0.660345384478569\n",
            "LOSS train 0.660345384478569\n",
            "EPOCH 19779:\n",
            "  batch 5 loss: 0.7664479792118073\n",
            "  batch 10 loss: 0.7130668729543685\n",
            "  batch 15 loss: 0.9801911294460297\n",
            "LOSS train 0.9801911294460297\n",
            "EPOCH 19780:\n",
            "  batch 5 loss: 0.3044361352920532\n",
            "  batch 10 loss: 0.8307321786880493\n",
            "  batch 15 loss: 0.720980754494667\n",
            "LOSS train 0.720980754494667\n",
            "EPOCH 19781:\n",
            "  batch 5 loss: 0.588359859585762\n",
            "  batch 10 loss: 0.35188380219042303\n",
            "  batch 15 loss: 0.6757099568843842\n",
            "LOSS train 0.6757099568843842\n",
            "EPOCH 19782:\n",
            "  batch 5 loss: 0.6926259189844132\n",
            "  batch 10 loss: 0.5265100359916687\n",
            "  batch 15 loss: 0.7593668684363365\n",
            "LOSS train 0.7593668684363365\n",
            "EPOCH 19783:\n",
            "  batch 5 loss: 0.4956091970205307\n",
            "  batch 10 loss: 0.6756328701972961\n",
            "  batch 15 loss: 0.7857444167137146\n",
            "LOSS train 0.7857444167137146\n",
            "EPOCH 19784:\n",
            "  batch 5 loss: 0.7316267848014831\n",
            "  batch 10 loss: 0.7741252303123474\n",
            "  batch 15 loss: 0.9374757423996926\n",
            "LOSS train 0.9374757423996926\n",
            "EPOCH 19785:\n",
            "  batch 5 loss: 0.6947395592927933\n",
            "  batch 10 loss: 0.8344706356525421\n",
            "  batch 15 loss: 0.90497405230999\n",
            "LOSS train 0.90497405230999\n",
            "EPOCH 19786:\n",
            "  batch 5 loss: 0.9166120529174805\n",
            "  batch 10 loss: 0.6762142390012741\n",
            "  batch 15 loss: 0.6448811262845993\n",
            "LOSS train 0.6448811262845993\n",
            "EPOCH 19787:\n",
            "  batch 5 loss: 0.5971251204609871\n",
            "  batch 10 loss: 0.6942304730415344\n",
            "  batch 15 loss: 0.5395318001508713\n",
            "LOSS train 0.5395318001508713\n",
            "EPOCH 19788:\n",
            "  batch 5 loss: 0.4467452883720398\n",
            "  batch 10 loss: 0.6594693433493376\n",
            "  batch 15 loss: 0.7715591847896576\n",
            "LOSS train 0.7715591847896576\n",
            "EPOCH 19789:\n",
            "  batch 5 loss: 1.0924051761627198\n",
            "  batch 10 loss: 0.6899365216493607\n",
            "  batch 15 loss: 0.625822837650776\n",
            "LOSS train 0.625822837650776\n",
            "EPOCH 19790:\n",
            "  batch 5 loss: 0.3750921621918678\n",
            "  batch 10 loss: 0.5708292096853256\n",
            "  batch 15 loss: 0.7035538673400878\n",
            "LOSS train 0.7035538673400878\n",
            "EPOCH 19791:\n",
            "  batch 5 loss: 0.9359306931495667\n",
            "  batch 10 loss: 0.6742538273334503\n",
            "  batch 15 loss: 0.6815876364707947\n",
            "LOSS train 0.6815876364707947\n",
            "EPOCH 19792:\n",
            "  batch 5 loss: 0.2953347712755203\n",
            "  batch 10 loss: 0.6904355257749557\n",
            "  batch 15 loss: 0.5559142798185348\n",
            "LOSS train 0.5559142798185348\n",
            "EPOCH 19793:\n",
            "  batch 5 loss: 0.737349870800972\n",
            "  batch 10 loss: 0.8533924221992493\n",
            "  batch 15 loss: 0.7794391810894012\n",
            "LOSS train 0.7794391810894012\n",
            "EPOCH 19794:\n",
            "  batch 5 loss: 0.6322910457849502\n",
            "  batch 10 loss: 0.8436811357736588\n",
            "  batch 15 loss: 0.728931474685669\n",
            "LOSS train 0.728931474685669\n",
            "EPOCH 19795:\n",
            "  batch 5 loss: 0.7900291793048382\n",
            "  batch 10 loss: 0.6473460376262665\n",
            "  batch 15 loss: 0.5964962244033813\n",
            "LOSS train 0.5964962244033813\n",
            "EPOCH 19796:\n",
            "  batch 5 loss: 0.8975156307220459\n",
            "  batch 10 loss: 0.7836087107658386\n",
            "  batch 15 loss: 0.6790467739105225\n",
            "LOSS train 0.6790467739105225\n",
            "EPOCH 19797:\n",
            "  batch 5 loss: 0.5189090430736542\n",
            "  batch 10 loss: 0.5449244849383831\n",
            "  batch 15 loss: 0.7587820053100586\n",
            "LOSS train 0.7587820053100586\n",
            "EPOCH 19798:\n",
            "  batch 5 loss: 0.6571256220340729\n",
            "  batch 10 loss: 0.8779032528400421\n",
            "  batch 15 loss: 0.675746476650238\n",
            "LOSS train 0.675746476650238\n",
            "EPOCH 19799:\n",
            "  batch 5 loss: 0.6485766649246216\n",
            "  batch 10 loss: 0.6003160893917083\n",
            "  batch 15 loss: 0.45164853930473325\n",
            "LOSS train 0.45164853930473325\n",
            "EPOCH 19800:\n",
            "  batch 5 loss: 0.6010441839694977\n",
            "  batch 10 loss: 0.3901482969522476\n",
            "  batch 15 loss: 0.5341593980789184\n",
            "LOSS train 0.5341593980789184\n",
            "EPOCH 19801:\n",
            "  batch 5 loss: 0.5903320431709289\n",
            "  batch 10 loss: 0.5318017259240151\n",
            "  batch 15 loss: 0.6830928444862365\n",
            "LOSS train 0.6830928444862365\n",
            "EPOCH 19802:\n",
            "  batch 5 loss: 0.351933965086937\n",
            "  batch 10 loss: 0.6974068224430084\n",
            "  batch 15 loss: 0.6767776906490326\n",
            "LOSS train 0.6767776906490326\n",
            "EPOCH 19803:\n",
            "  batch 5 loss: 0.4634541630744934\n",
            "  batch 10 loss: 0.748854112625122\n",
            "  batch 15 loss: 0.8687578916549683\n",
            "LOSS train 0.8687578916549683\n",
            "EPOCH 19804:\n",
            "  batch 5 loss: 0.6040375649929046\n",
            "  batch 10 loss: 0.8906636118888855\n",
            "  batch 15 loss: 0.7084375023841858\n",
            "LOSS train 0.7084375023841858\n",
            "EPOCH 19805:\n",
            "  batch 5 loss: 0.871078759431839\n",
            "  batch 10 loss: 0.9641516923904419\n",
            "  batch 15 loss: 0.7612666189670563\n",
            "LOSS train 0.7612666189670563\n",
            "EPOCH 19806:\n",
            "  batch 5 loss: 0.6110332190990448\n",
            "  batch 10 loss: 0.48243643045425416\n",
            "  batch 15 loss: 0.8851075887680053\n",
            "LOSS train 0.8851075887680053\n",
            "EPOCH 19807:\n",
            "  batch 5 loss: 0.742131307721138\n",
            "  batch 10 loss: 0.4044646695256233\n",
            "  batch 15 loss: 0.6784129559993743\n",
            "LOSS train 0.6784129559993743\n",
            "EPOCH 19808:\n",
            "  batch 5 loss: 0.622120839357376\n",
            "  batch 10 loss: 0.6930774092674256\n",
            "  batch 15 loss: 0.6205056965351105\n",
            "LOSS train 0.6205056965351105\n",
            "EPOCH 19809:\n",
            "  batch 5 loss: 0.9129977334290743\n",
            "  batch 10 loss: 0.715728884190321\n",
            "  batch 15 loss: 0.5354251265525818\n",
            "LOSS train 0.5354251265525818\n",
            "EPOCH 19810:\n",
            "  batch 5 loss: 0.6303988933563233\n",
            "  batch 10 loss: 0.7934456110000611\n",
            "  batch 15 loss: 0.6760935187339783\n",
            "LOSS train 0.6760935187339783\n",
            "EPOCH 19811:\n",
            "  batch 5 loss: 0.8387733340263367\n",
            "  batch 10 loss: 0.5310681238770485\n",
            "  batch 15 loss: 0.8263759613037109\n",
            "LOSS train 0.8263759613037109\n",
            "EPOCH 19812:\n",
            "  batch 5 loss: 0.46899247244000436\n",
            "  batch 10 loss: 0.7645493090152741\n",
            "  batch 15 loss: 0.9790911376476288\n",
            "LOSS train 0.9790911376476288\n",
            "EPOCH 19813:\n",
            "  batch 5 loss: 1.0059563159942626\n",
            "  batch 10 loss: 0.36258684694766996\n",
            "  batch 15 loss: 0.8079026341438293\n",
            "LOSS train 0.8079026341438293\n",
            "EPOCH 19814:\n",
            "  batch 5 loss: 0.7648767471313477\n",
            "  batch 10 loss: 0.5324574552476407\n",
            "  batch 15 loss: 0.8491775691509247\n",
            "LOSS train 0.8491775691509247\n",
            "EPOCH 19815:\n",
            "  batch 5 loss: 0.4695026159286499\n",
            "  batch 10 loss: 0.4003900337964296\n",
            "  batch 15 loss: 0.5299651578068734\n",
            "LOSS train 0.5299651578068734\n",
            "EPOCH 19816:\n",
            "  batch 5 loss: 0.657959258556366\n",
            "  batch 10 loss: 0.8306003212928772\n",
            "  batch 15 loss: 0.4884792983531952\n",
            "LOSS train 0.4884792983531952\n",
            "EPOCH 19817:\n",
            "  batch 5 loss: 0.5321061298251152\n",
            "  batch 10 loss: 0.7725711166858673\n",
            "  batch 15 loss: 0.6107169270515442\n",
            "LOSS train 0.6107169270515442\n",
            "EPOCH 19818:\n",
            "  batch 5 loss: 0.887016874551773\n",
            "  batch 10 loss: 0.48141281604766845\n",
            "  batch 15 loss: 0.8918115496635437\n",
            "LOSS train 0.8918115496635437\n",
            "EPOCH 19819:\n",
            "  batch 5 loss: 0.749064701795578\n",
            "  batch 10 loss: 0.4710648968815804\n",
            "  batch 15 loss: 0.487299370765686\n",
            "LOSS train 0.487299370765686\n",
            "EPOCH 19820:\n",
            "  batch 5 loss: 0.6280803680419922\n",
            "  batch 10 loss: 0.5924463123083115\n",
            "  batch 15 loss: 0.7447279095649719\n",
            "LOSS train 0.7447279095649719\n",
            "EPOCH 19821:\n",
            "  batch 5 loss: 0.7197388887405396\n",
            "  batch 10 loss: 0.9884074926376343\n",
            "  batch 15 loss: 0.6396025516092777\n",
            "LOSS train 0.6396025516092777\n",
            "EPOCH 19822:\n",
            "  batch 5 loss: 0.6053791232407093\n",
            "  batch 10 loss: 0.3113701708614826\n",
            "  batch 15 loss: 0.9139135658740998\n",
            "LOSS train 0.9139135658740998\n",
            "EPOCH 19823:\n",
            "  batch 5 loss: 0.9980401277542115\n",
            "  batch 10 loss: 0.3456021025776863\n",
            "  batch 15 loss: 0.6233303070068359\n",
            "LOSS train 0.6233303070068359\n",
            "EPOCH 19824:\n",
            "  batch 5 loss: 0.7940877676010132\n",
            "  batch 10 loss: 0.6795750439167023\n",
            "  batch 15 loss: 0.9737238883972168\n",
            "LOSS train 0.9737238883972168\n",
            "EPOCH 19825:\n",
            "  batch 5 loss: 0.7218052297830582\n",
            "  batch 10 loss: 0.4994183361530304\n",
            "  batch 15 loss: 0.801585215330124\n",
            "LOSS train 0.801585215330124\n",
            "EPOCH 19826:\n",
            "  batch 5 loss: 0.8465828180313111\n",
            "  batch 10 loss: 0.3470711216330528\n",
            "  batch 15 loss: 0.7410166382789611\n",
            "LOSS train 0.7410166382789611\n",
            "EPOCH 19827:\n",
            "  batch 5 loss: 0.6678669333457947\n",
            "  batch 10 loss: 0.30588556826114655\n",
            "  batch 15 loss: 0.4090070575475693\n",
            "LOSS train 0.4090070575475693\n",
            "EPOCH 19828:\n",
            "  batch 5 loss: 0.8824208378791809\n",
            "  batch 10 loss: 0.7868589758872986\n",
            "  batch 15 loss: 0.936872923374176\n",
            "LOSS train 0.936872923374176\n",
            "EPOCH 19829:\n",
            "  batch 5 loss: 0.6531118839979172\n",
            "  batch 10 loss: 0.8985357642173767\n",
            "  batch 15 loss: 0.6713135570287705\n",
            "LOSS train 0.6713135570287705\n",
            "EPOCH 19830:\n",
            "  batch 5 loss: 0.6120859533548355\n",
            "  batch 10 loss: 0.8420411109924316\n",
            "  batch 15 loss: 0.47483323104679587\n",
            "LOSS train 0.47483323104679587\n",
            "EPOCH 19831:\n",
            "  batch 5 loss: 0.4191912285983562\n",
            "  batch 10 loss: 0.7068416893482208\n",
            "  batch 15 loss: 0.6514884270727634\n",
            "LOSS train 0.6514884270727634\n",
            "EPOCH 19832:\n",
            "  batch 5 loss: 0.8590544208884239\n",
            "  batch 10 loss: 0.8177817344665528\n",
            "  batch 15 loss: 0.819397610425949\n",
            "LOSS train 0.819397610425949\n",
            "EPOCH 19833:\n",
            "  batch 5 loss: 1.0262443244457244\n",
            "  batch 10 loss: 0.3799272656440735\n",
            "  batch 15 loss: 0.8002680674195289\n",
            "LOSS train 0.8002680674195289\n",
            "EPOCH 19834:\n",
            "  batch 5 loss: 0.5209166288375855\n",
            "  batch 10 loss: 0.8805086970329284\n",
            "  batch 15 loss: 0.9794264316558838\n",
            "LOSS train 0.9794264316558838\n",
            "EPOCH 19835:\n",
            "  batch 5 loss: 0.6536549091339111\n",
            "  batch 10 loss: 0.48333007358014585\n",
            "  batch 15 loss: 0.7706442892551422\n",
            "LOSS train 0.7706442892551422\n",
            "EPOCH 19836:\n",
            "  batch 5 loss: 0.6943832546472549\n",
            "  batch 10 loss: 0.7539676070213318\n",
            "  batch 15 loss: 0.9307577013969421\n",
            "LOSS train 0.9307577013969421\n",
            "EPOCH 19837:\n",
            "  batch 5 loss: 18.890329205989836\n",
            "  batch 10 loss: 0.4011052519083023\n",
            "  batch 15 loss: 0.7780598811805248\n",
            "LOSS train 0.7780598811805248\n",
            "EPOCH 19838:\n",
            "  batch 5 loss: 0.723550683259964\n",
            "  batch 10 loss: 0.7104983031749725\n",
            "  batch 15 loss: 0.6686824321746826\n",
            "LOSS train 0.6686824321746826\n",
            "EPOCH 19839:\n",
            "  batch 5 loss: 0.6752939909696579\n",
            "  batch 10 loss: 0.6585212230682373\n",
            "  batch 15 loss: 0.6618284597992897\n",
            "LOSS train 0.6618284597992897\n",
            "EPOCH 19840:\n",
            "  batch 5 loss: 1.0326264441013335\n",
            "  batch 10 loss: 0.8794724531471729\n",
            "  batch 15 loss: 1.030080533027649\n",
            "LOSS train 1.030080533027649\n",
            "EPOCH 19841:\n",
            "  batch 5 loss: 0.561702373623848\n",
            "  batch 10 loss: 0.8187564432621002\n",
            "  batch 15 loss: 0.48591938316822053\n",
            "LOSS train 0.48591938316822053\n",
            "EPOCH 19842:\n",
            "  batch 5 loss: 0.693045261502266\n",
            "  batch 10 loss: 0.3802332065999508\n",
            "  batch 15 loss: 0.7193438053131104\n",
            "LOSS train 0.7193438053131104\n",
            "EPOCH 19843:\n",
            "  batch 5 loss: 0.7051986455917358\n",
            "  batch 10 loss: 0.796982204914093\n",
            "  batch 15 loss: 0.5210091471672058\n",
            "LOSS train 0.5210091471672058\n",
            "EPOCH 19844:\n",
            "  batch 5 loss: 0.7175693213939667\n",
            "  batch 10 loss: 0.8241706967353821\n",
            "  batch 15 loss: 0.6618366837501526\n",
            "LOSS train 0.6618366837501526\n",
            "EPOCH 19845:\n",
            "  batch 5 loss: 0.47073992192745207\n",
            "  batch 10 loss: 0.8300854619592428\n",
            "  batch 15 loss: 0.6182198524475098\n",
            "LOSS train 0.6182198524475098\n",
            "EPOCH 19846:\n",
            "  batch 5 loss: 0.6590852856636047\n",
            "  batch 10 loss: 0.7416616261005402\n",
            "  batch 15 loss: 0.8016958951950073\n",
            "LOSS train 0.8016958951950073\n",
            "EPOCH 19847:\n",
            "  batch 5 loss: 0.9589852929115296\n",
            "  batch 10 loss: 0.6379665732383728\n",
            "  batch 15 loss: 0.48230162262916565\n",
            "LOSS train 0.48230162262916565\n",
            "EPOCH 19848:\n",
            "  batch 5 loss: 0.5635199241340161\n",
            "  batch 10 loss: 0.8000723510980606\n",
            "  batch 15 loss: 0.6288644671440125\n",
            "LOSS train 0.6288644671440125\n",
            "EPOCH 19849:\n",
            "  batch 5 loss: 0.6739914119243622\n",
            "  batch 10 loss: 0.5231116831302642\n",
            "  batch 15 loss: 0.5221714362502098\n",
            "LOSS train 0.5221714362502098\n",
            "EPOCH 19850:\n",
            "  batch 5 loss: 0.3154305383563042\n",
            "  batch 10 loss: 0.48732638657093047\n",
            "  batch 15 loss: 0.7898000597953796\n",
            "LOSS train 0.7898000597953796\n",
            "EPOCH 19851:\n",
            "  batch 5 loss: 0.9236578941345215\n",
            "  batch 10 loss: 0.7422036826610565\n",
            "  batch 15 loss: 0.489290851354599\n",
            "LOSS train 0.489290851354599\n",
            "EPOCH 19852:\n",
            "  batch 5 loss: 0.6310541361570359\n",
            "  batch 10 loss: 0.7261464029550553\n",
            "  batch 15 loss: 0.5067684926092625\n",
            "LOSS train 0.5067684926092625\n",
            "EPOCH 19853:\n",
            "  batch 5 loss: 0.6122863411903381\n",
            "  batch 10 loss: 0.327571901679039\n",
            "  batch 15 loss: 0.792739388346672\n",
            "LOSS train 0.792739388346672\n",
            "EPOCH 19854:\n",
            "  batch 5 loss: 1.0572084784507751\n",
            "  batch 10 loss: 0.6707971319556236\n",
            "  batch 15 loss: 0.993902838230133\n",
            "LOSS train 0.993902838230133\n",
            "EPOCH 19855:\n",
            "  batch 5 loss: 0.8598088592290878\n",
            "  batch 10 loss: 0.6085334122180939\n",
            "  batch 15 loss: 0.7064645946025848\n",
            "LOSS train 0.7064645946025848\n",
            "EPOCH 19856:\n",
            "  batch 5 loss: 0.5460217535495758\n",
            "  batch 10 loss: 0.2844993366859853\n",
            "  batch 15 loss: 0.9475402772426605\n",
            "LOSS train 0.9475402772426605\n",
            "EPOCH 19857:\n",
            "  batch 5 loss: 0.8149283468723297\n",
            "  batch 10 loss: 0.7812401056289673\n",
            "  batch 15 loss: 0.8981969237327576\n",
            "LOSS train 0.8981969237327576\n",
            "EPOCH 19858:\n",
            "  batch 5 loss: 0.6659988284111023\n",
            "  batch 10 loss: 0.6108324527740479\n",
            "  batch 15 loss: 0.9422482848167419\n",
            "LOSS train 0.9422482848167419\n",
            "EPOCH 19859:\n",
            "  batch 5 loss: 0.7025073289871215\n",
            "  batch 10 loss: 1.0448610424995421\n",
            "  batch 15 loss: 0.9252253204584122\n",
            "LOSS train 0.9252253204584122\n",
            "EPOCH 19860:\n",
            "  batch 5 loss: 0.9021407246589661\n",
            "  batch 10 loss: 0.4990220941603184\n",
            "  batch 15 loss: 0.6937863022089005\n",
            "LOSS train 0.6937863022089005\n",
            "EPOCH 19861:\n",
            "  batch 5 loss: 0.8688408493995666\n",
            "  batch 10 loss: 0.71696862205863\n",
            "  batch 15 loss: 0.7372893154621124\n",
            "LOSS train 0.7372893154621124\n",
            "EPOCH 19862:\n",
            "  batch 5 loss: 0.6031150162220001\n",
            "  batch 10 loss: 0.5349056914448738\n",
            "  batch 15 loss: 1.0279743134975434\n",
            "LOSS train 1.0279743134975434\n",
            "EPOCH 19863:\n",
            "  batch 5 loss: 0.7046507060527801\n",
            "  batch 10 loss: 0.9235512733459472\n",
            "  batch 15 loss: 0.6896968640387058\n",
            "LOSS train 0.6896968640387058\n",
            "EPOCH 19864:\n",
            "  batch 5 loss: 0.8767402231693268\n",
            "  batch 10 loss: 1.0745900630950929\n",
            "  batch 15 loss: 0.7848509162664413\n",
            "LOSS train 0.7848509162664413\n",
            "EPOCH 19865:\n",
            "  batch 5 loss: 0.755196487903595\n",
            "  batch 10 loss: 0.447316312789917\n",
            "  batch 15 loss: 0.42535526156425474\n",
            "LOSS train 0.42535526156425474\n",
            "EPOCH 19866:\n",
            "  batch 5 loss: 0.8699514389038085\n",
            "  batch 10 loss: 0.5822644095867873\n",
            "  batch 15 loss: 0.46100547462701796\n",
            "LOSS train 0.46100547462701796\n",
            "EPOCH 19867:\n",
            "  batch 5 loss: 0.743307226896286\n",
            "  batch 10 loss: 0.7081701815128326\n",
            "  batch 15 loss: 0.8079704523086548\n",
            "LOSS train 0.8079704523086548\n",
            "EPOCH 19868:\n",
            "  batch 5 loss: 0.583547031879425\n",
            "  batch 10 loss: 0.6486718833446503\n",
            "  batch 15 loss: 0.9776353359222412\n",
            "LOSS train 0.9776353359222412\n",
            "EPOCH 19869:\n",
            "  batch 5 loss: 0.38532209396362305\n",
            "  batch 10 loss: 0.6571026608347893\n",
            "  batch 15 loss: 0.7138432860374451\n",
            "LOSS train 0.7138432860374451\n",
            "EPOCH 19870:\n",
            "  batch 5 loss: 0.7221984624862671\n",
            "  batch 10 loss: 0.8328864932060241\n",
            "  batch 15 loss: 0.407263845205307\n",
            "LOSS train 0.407263845205307\n",
            "EPOCH 19871:\n",
            "  batch 5 loss: 0.5808440666645766\n",
            "  batch 10 loss: 0.4286053627729416\n",
            "  batch 15 loss: 0.44042991697788236\n",
            "LOSS train 0.44042991697788236\n",
            "EPOCH 19872:\n",
            "  batch 5 loss: 0.5770992159843444\n",
            "  batch 10 loss: 0.8908145785331726\n",
            "  batch 15 loss: 0.6661909729242325\n",
            "LOSS train 0.6661909729242325\n",
            "EPOCH 19873:\n",
            "  batch 5 loss: 0.8668047070503235\n",
            "  batch 10 loss: 0.7353291600942612\n",
            "  batch 15 loss: 0.6432342231273651\n",
            "LOSS train 0.6432342231273651\n",
            "EPOCH 19874:\n",
            "  batch 5 loss: 0.6580956816673279\n",
            "  batch 10 loss: 0.5772858619689941\n",
            "  batch 15 loss: 0.641395902633667\n",
            "LOSS train 0.641395902633667\n",
            "EPOCH 19875:\n",
            "  batch 5 loss: 0.4538127824664116\n",
            "  batch 10 loss: 0.9770805776119232\n",
            "  batch 15 loss: 0.9812257170677186\n",
            "LOSS train 0.9812257170677186\n",
            "EPOCH 19876:\n",
            "  batch 5 loss: 1.0399753332138062\n",
            "  batch 10 loss: 0.7699939422309399\n",
            "  batch 15 loss: 0.6773786082863807\n",
            "LOSS train 0.6773786082863807\n",
            "EPOCH 19877:\n",
            "  batch 5 loss: 0.7393551617860794\n",
            "  batch 10 loss: 1.009126877784729\n",
            "  batch 15 loss: 0.6756928205490113\n",
            "LOSS train 0.6756928205490113\n",
            "EPOCH 19878:\n",
            "  batch 5 loss: 0.519159660488367\n",
            "  batch 10 loss: 0.5383377768099308\n",
            "  batch 15 loss: 0.8035565495491028\n",
            "LOSS train 0.8035565495491028\n",
            "EPOCH 19879:\n",
            "  batch 5 loss: 0.46431506872177125\n",
            "  batch 10 loss: 0.7283045530319214\n",
            "  batch 15 loss: 0.8756538808345795\n",
            "LOSS train 0.8756538808345795\n",
            "EPOCH 19880:\n",
            "  batch 5 loss: 0.6512613326311112\n",
            "  batch 10 loss: 0.4135442942380905\n",
            "  batch 15 loss: 0.6590848624706268\n",
            "LOSS train 0.6590848624706268\n",
            "EPOCH 19881:\n",
            "  batch 5 loss: 0.6949101388454437\n",
            "  batch 10 loss: 0.7533090814948082\n",
            "  batch 15 loss: 0.41757586151361464\n",
            "LOSS train 0.41757586151361464\n",
            "EPOCH 19882:\n",
            "  batch 5 loss: 0.7698070235550404\n",
            "  batch 10 loss: 0.6744459837675094\n",
            "  batch 15 loss: 0.5629165917634964\n",
            "LOSS train 0.5629165917634964\n",
            "EPOCH 19883:\n",
            "  batch 5 loss: 1.170179432630539\n",
            "  batch 10 loss: 0.656508493423462\n",
            "  batch 15 loss: 0.37994821965694425\n",
            "LOSS train 0.37994821965694425\n",
            "EPOCH 19884:\n",
            "  batch 5 loss: 0.34379994571208955\n",
            "  batch 10 loss: 0.6373760163784027\n",
            "  batch 15 loss: 0.9502368211746216\n",
            "LOSS train 0.9502368211746216\n",
            "EPOCH 19885:\n",
            "  batch 5 loss: 0.5690661370754242\n",
            "  batch 10 loss: 0.8846480488777161\n",
            "  batch 15 loss: 0.1878173090517521\n",
            "LOSS train 0.1878173090517521\n",
            "EPOCH 19886:\n",
            "  batch 5 loss: 0.8428630709648133\n",
            "  batch 10 loss: 0.6626114994287491\n",
            "  batch 15 loss: 0.5731616377830505\n",
            "LOSS train 0.5731616377830505\n",
            "EPOCH 19887:\n",
            "  batch 5 loss: 0.16967058107256888\n",
            "  batch 10 loss: 0.5601075455546379\n",
            "  batch 15 loss: 0.37696927785873413\n",
            "LOSS train 0.37696927785873413\n",
            "EPOCH 19888:\n",
            "  batch 5 loss: 0.9116848349571228\n",
            "  batch 10 loss: 0.8318865656852722\n",
            "  batch 15 loss: 0.8366291880607605\n",
            "LOSS train 0.8366291880607605\n",
            "EPOCH 19889:\n",
            "  batch 5 loss: 0.47216791808605196\n",
            "  batch 10 loss: 0.4178446352481842\n",
            "  batch 15 loss: 0.8338935732841491\n",
            "LOSS train 0.8338935732841491\n",
            "EPOCH 19890:\n",
            "  batch 5 loss: 0.9306555390357971\n",
            "  batch 10 loss: 0.8232330322265625\n",
            "  batch 15 loss: 0.5196379065513611\n",
            "LOSS train 0.5196379065513611\n",
            "EPOCH 19891:\n",
            "  batch 5 loss: 0.6411323189735413\n",
            "  batch 10 loss: 0.7174199312925339\n",
            "  batch 15 loss: 0.6561132222414017\n",
            "LOSS train 0.6561132222414017\n",
            "EPOCH 19892:\n",
            "  batch 5 loss: 0.684353918209672\n",
            "  batch 10 loss: 0.38955223113298415\n",
            "  batch 15 loss: 0.4616830348968506\n",
            "LOSS train 0.4616830348968506\n",
            "EPOCH 19893:\n",
            "  batch 5 loss: 0.8838740944862366\n",
            "  batch 10 loss: 0.5048505783081054\n",
            "  batch 15 loss: 0.8371874153614044\n",
            "LOSS train 0.8371874153614044\n",
            "EPOCH 19894:\n",
            "  batch 5 loss: 0.5916529357433319\n",
            "  batch 10 loss: 0.8348490178585053\n",
            "  batch 15 loss: 0.745599377155304\n",
            "LOSS train 0.745599377155304\n",
            "EPOCH 19895:\n",
            "  batch 5 loss: 0.5489710569381714\n",
            "  batch 10 loss: 0.4013012245297432\n",
            "  batch 15 loss: 0.7205085933208466\n",
            "LOSS train 0.7205085933208466\n",
            "EPOCH 19896:\n",
            "  batch 5 loss: 0.8036680698394776\n",
            "  batch 10 loss: 0.5956163749098777\n",
            "  batch 15 loss: 0.6180137634277344\n",
            "LOSS train 0.6180137634277344\n",
            "EPOCH 19897:\n",
            "  batch 5 loss: 0.5139860898256302\n",
            "  batch 10 loss: 0.6252855271100998\n",
            "  batch 15 loss: 0.7899845987558365\n",
            "LOSS train 0.7899845987558365\n",
            "EPOCH 19898:\n",
            "  batch 5 loss: 0.5901179909706116\n",
            "  batch 10 loss: 1.044737732410431\n",
            "  batch 15 loss: 0.6247753798961639\n",
            "LOSS train 0.6247753798961639\n",
            "EPOCH 19899:\n",
            "  batch 5 loss: 0.8472786962985992\n",
            "  batch 10 loss: 0.6788470029830933\n",
            "  batch 15 loss: 0.5060530215501785\n",
            "LOSS train 0.5060530215501785\n",
            "EPOCH 19900:\n",
            "  batch 5 loss: 0.6520132392644882\n",
            "  batch 10 loss: 0.9863329887390136\n",
            "  batch 15 loss: 0.9010311722755432\n",
            "LOSS train 0.9010311722755432\n",
            "EPOCH 19901:\n",
            "  batch 5 loss: 0.48300708532333375\n",
            "  batch 10 loss: 0.7907758116722107\n",
            "  batch 15 loss: 0.8677428007125855\n",
            "LOSS train 0.8677428007125855\n",
            "EPOCH 19902:\n",
            "  batch 5 loss: 0.49735762514173987\n",
            "  batch 10 loss: 0.8937967658042908\n",
            "  batch 15 loss: 0.7860646843910217\n",
            "LOSS train 0.7860646843910217\n",
            "EPOCH 19903:\n",
            "  batch 5 loss: 0.7775358602404594\n",
            "  batch 10 loss: 0.460614275932312\n",
            "  batch 15 loss: 0.6148575395345688\n",
            "LOSS train 0.6148575395345688\n",
            "EPOCH 19904:\n",
            "  batch 5 loss: 0.7123618647456169\n",
            "  batch 10 loss: 0.8515193581581115\n",
            "  batch 15 loss: 0.9248237013816833\n",
            "LOSS train 0.9248237013816833\n",
            "EPOCH 19905:\n",
            "  batch 5 loss: 0.5150180280208587\n",
            "  batch 10 loss: 0.5992150634527207\n",
            "  batch 15 loss: 0.9087385714054108\n",
            "LOSS train 0.9087385714054108\n",
            "EPOCH 19906:\n",
            "  batch 5 loss: 0.6822082757949829\n",
            "  batch 10 loss: 0.7090491354465485\n",
            "  batch 15 loss: 0.7134000897407532\n",
            "LOSS train 0.7134000897407532\n",
            "EPOCH 19907:\n",
            "  batch 5 loss: 0.7597508788108825\n",
            "  batch 10 loss: 0.9296371266245842\n",
            "  batch 15 loss: 0.7582278713583946\n",
            "LOSS train 0.7582278713583946\n",
            "EPOCH 19908:\n",
            "  batch 5 loss: 0.5191723525524139\n",
            "  batch 10 loss: 0.36151967346668246\n",
            "  batch 15 loss: 0.6748868525028229\n",
            "LOSS train 0.6748868525028229\n",
            "EPOCH 19909:\n",
            "  batch 5 loss: 0.6908159978687763\n",
            "  batch 10 loss: 0.8597565829753876\n",
            "  batch 15 loss: 0.6730276815593242\n",
            "LOSS train 0.6730276815593242\n",
            "EPOCH 19910:\n",
            "  batch 5 loss: 0.8614951252937317\n",
            "  batch 10 loss: 0.5749597176909447\n",
            "  batch 15 loss: 0.55372813642025\n",
            "LOSS train 0.55372813642025\n",
            "EPOCH 19911:\n",
            "  batch 5 loss: 0.5707801729440689\n",
            "  batch 10 loss: 0.5573592185974121\n",
            "  batch 15 loss: 0.803191214799881\n",
            "LOSS train 0.803191214799881\n",
            "EPOCH 19912:\n",
            "  batch 5 loss: 0.9035534508526325\n",
            "  batch 10 loss: 0.752982097864151\n",
            "  batch 15 loss: 0.50200075507164\n",
            "LOSS train 0.50200075507164\n",
            "EPOCH 19913:\n",
            "  batch 5 loss: 0.4114406585693359\n",
            "  batch 10 loss: 0.9076867818832397\n",
            "  batch 15 loss: 0.8591162860393524\n",
            "LOSS train 0.8591162860393524\n",
            "EPOCH 19914:\n",
            "  batch 5 loss: 0.5087743297219276\n",
            "  batch 10 loss: 0.701945698261261\n",
            "  batch 15 loss: 0.8276628732681275\n",
            "LOSS train 0.8276628732681275\n",
            "EPOCH 19915:\n",
            "  batch 5 loss: 0.9157752633094788\n",
            "  batch 10 loss: 0.6759727537631989\n",
            "  batch 15 loss: 0.682268662750721\n",
            "LOSS train 0.682268662750721\n",
            "EPOCH 19916:\n",
            "  batch 5 loss: 0.6252380266785622\n",
            "  batch 10 loss: 0.8973389744758606\n",
            "  batch 15 loss: 0.8535679578781128\n",
            "LOSS train 0.8535679578781128\n",
            "EPOCH 19917:\n",
            "  batch 5 loss: 0.619787186384201\n",
            "  batch 10 loss: 0.6575287222862244\n",
            "  batch 15 loss: 0.4922466516494751\n",
            "LOSS train 0.4922466516494751\n",
            "EPOCH 19918:\n",
            "  batch 5 loss: 0.7770886719226837\n",
            "  batch 10 loss: 1.151560914516449\n",
            "  batch 15 loss: 0.7552063345909119\n",
            "LOSS train 0.7552063345909119\n",
            "EPOCH 19919:\n",
            "  batch 5 loss: 0.5807219609618187\n",
            "  batch 10 loss: 0.500627800822258\n",
            "  batch 15 loss: 0.7825773090124131\n",
            "LOSS train 0.7825773090124131\n",
            "EPOCH 19920:\n",
            "  batch 5 loss: 0.8387827754020691\n",
            "  batch 10 loss: 1.055465030670166\n",
            "  batch 15 loss: 0.6972681313753128\n",
            "LOSS train 0.6972681313753128\n",
            "EPOCH 19921:\n",
            "  batch 5 loss: 0.4802021741867065\n",
            "  batch 10 loss: 0.4812988370656967\n",
            "  batch 15 loss: 0.6513734459877014\n",
            "LOSS train 0.6513734459877014\n",
            "EPOCH 19922:\n",
            "  batch 5 loss: 0.6365765690803528\n",
            "  batch 10 loss: 0.6612636964768172\n",
            "  batch 15 loss: 0.6885007500648499\n",
            "LOSS train 0.6885007500648499\n",
            "EPOCH 19923:\n",
            "  batch 5 loss: 0.7219109803438186\n",
            "  batch 10 loss: 0.27599445134401324\n",
            "  batch 15 loss: 0.9477785289287567\n",
            "LOSS train 0.9477785289287567\n",
            "EPOCH 19924:\n",
            "  batch 5 loss: 12.556027607619763\n",
            "  batch 10 loss: 0.8316348314285278\n",
            "  batch 15 loss: 1.0736817121505737\n",
            "LOSS train 1.0736817121505737\n",
            "EPOCH 19925:\n",
            "  batch 5 loss: 0.9301116764545441\n",
            "  batch 10 loss: 0.7850533217191696\n",
            "  batch 15 loss: 0.6030225604772568\n",
            "LOSS train 0.6030225604772568\n",
            "EPOCH 19926:\n",
            "  batch 5 loss: 0.8599920868873596\n",
            "  batch 10 loss: 0.7672895073890686\n",
            "  batch 15 loss: 0.6472874462604523\n",
            "LOSS train 0.6472874462604523\n",
            "EPOCH 19927:\n",
            "  batch 5 loss: 0.7796693444252014\n",
            "  batch 10 loss: 0.6431864023208618\n",
            "  batch 15 loss: 0.8778097003698349\n",
            "LOSS train 0.8778097003698349\n",
            "EPOCH 19928:\n",
            "  batch 5 loss: 1.1607271373271941\n",
            "  batch 10 loss: 0.958703339099884\n",
            "  batch 15 loss: 0.8628538504242897\n",
            "LOSS train 0.8628538504242897\n",
            "EPOCH 19929:\n",
            "  batch 5 loss: 0.8702437222003937\n",
            "  batch 10 loss: 0.7368205860257149\n",
            "  batch 15 loss: 0.5698299549520016\n",
            "LOSS train 0.5698299549520016\n",
            "EPOCH 19930:\n",
            "  batch 5 loss: 0.5926096096634865\n",
            "  batch 10 loss: 0.7368484079837799\n",
            "  batch 15 loss: 0.8740375220775605\n",
            "LOSS train 0.8740375220775605\n",
            "EPOCH 19931:\n",
            "  batch 5 loss: 0.8299716979265213\n",
            "  batch 10 loss: 0.7416166424751282\n",
            "  batch 15 loss: 0.8465290009975434\n",
            "LOSS train 0.8465290009975434\n",
            "EPOCH 19932:\n",
            "  batch 5 loss: 0.8123083770275116\n",
            "  batch 10 loss: 0.5464377671480178\n",
            "  batch 15 loss: 0.7932039260864258\n",
            "LOSS train 0.7932039260864258\n",
            "EPOCH 19933:\n",
            "  batch 5 loss: 0.7792262494564056\n",
            "  batch 10 loss: 0.8759682923555374\n",
            "  batch 15 loss: 0.6969030499458313\n",
            "LOSS train 0.6969030499458313\n",
            "EPOCH 19934:\n",
            "  batch 5 loss: 0.7275344535708428\n",
            "  batch 10 loss: 0.6577942700125277\n",
            "  batch 15 loss: 0.7305612444877625\n",
            "LOSS train 0.7305612444877625\n",
            "EPOCH 19935:\n",
            "  batch 5 loss: 0.709169139713049\n",
            "  batch 10 loss: 0.9175753712654113\n",
            "  batch 15 loss: 0.7416732668876648\n",
            "LOSS train 0.7416732668876648\n",
            "EPOCH 19936:\n",
            "  batch 5 loss: 0.6674782276153565\n",
            "  batch 10 loss: 1.7390177190303802\n",
            "  batch 15 loss: 0.7501169502735138\n",
            "LOSS train 0.7501169502735138\n",
            "EPOCH 19937:\n",
            "  batch 5 loss: 0.45691368244588376\n",
            "  batch 10 loss: 1.0356623888015748\n",
            "  batch 15 loss: 0.4292140930891037\n",
            "LOSS train 0.4292140930891037\n",
            "EPOCH 19938:\n",
            "  batch 5 loss: 0.48744411319494246\n",
            "  batch 10 loss: 0.7014805197715759\n",
            "  batch 15 loss: 0.2586517587304115\n",
            "LOSS train 0.2586517587304115\n",
            "EPOCH 19939:\n",
            "  batch 5 loss: 0.5640397280454635\n",
            "  batch 10 loss: 0.3771745003759861\n",
            "  batch 15 loss: 0.6844109535217285\n",
            "LOSS train 0.6844109535217285\n",
            "EPOCH 19940:\n",
            "  batch 5 loss: 0.5435085088014603\n",
            "  batch 10 loss: 0.6199873685836792\n",
            "  batch 15 loss: 0.5475878607481718\n",
            "LOSS train 0.5475878607481718\n",
            "EPOCH 19941:\n",
            "  batch 5 loss: 0.5306154325604439\n",
            "  batch 10 loss: 0.624142049998045\n",
            "  batch 15 loss: 0.4941721737384796\n",
            "LOSS train 0.4941721737384796\n",
            "EPOCH 19942:\n",
            "  batch 5 loss: 0.91937096118927\n",
            "  batch 10 loss: 0.7089835345745087\n",
            "  batch 15 loss: 0.8514567524194717\n",
            "LOSS train 0.8514567524194717\n",
            "EPOCH 19943:\n",
            "  batch 5 loss: 0.662866735458374\n",
            "  batch 10 loss: 0.8215758293867111\n",
            "  batch 15 loss: 0.7938557624816894\n",
            "LOSS train 0.7938557624816894\n",
            "EPOCH 19944:\n",
            "  batch 5 loss: 0.609516641497612\n",
            "  batch 10 loss: 0.7323657155036927\n",
            "  batch 15 loss: 0.8005992770195007\n",
            "LOSS train 0.8005992770195007\n",
            "EPOCH 19945:\n",
            "  batch 5 loss: 0.7193871229887009\n",
            "  batch 10 loss: 0.6167585909366607\n",
            "  batch 15 loss: 0.7762835562229157\n",
            "LOSS train 0.7762835562229157\n",
            "EPOCH 19946:\n",
            "  batch 5 loss: 0.8117813192307949\n",
            "  batch 10 loss: 0.4688255310058594\n",
            "  batch 15 loss: 0.9797628343105316\n",
            "LOSS train 0.9797628343105316\n",
            "EPOCH 19947:\n",
            "  batch 5 loss: 0.8523315846920013\n",
            "  batch 10 loss: 0.5674037121236324\n",
            "  batch 15 loss: 0.619143670797348\n",
            "LOSS train 0.619143670797348\n",
            "EPOCH 19948:\n",
            "  batch 5 loss: 0.8553428411483764\n",
            "  batch 10 loss: 0.6822218149900436\n",
            "  batch 15 loss: 0.9462141484022141\n",
            "LOSS train 0.9462141484022141\n",
            "EPOCH 19949:\n",
            "  batch 5 loss: 0.6093204259872437\n",
            "  batch 10 loss: 0.7028964251279831\n",
            "  batch 15 loss: 0.6794411301612854\n",
            "LOSS train 0.6794411301612854\n",
            "EPOCH 19950:\n",
            "  batch 5 loss: 0.44727224111557007\n",
            "  batch 10 loss: 0.8340225577354431\n",
            "  batch 15 loss: 0.30032712444663046\n",
            "LOSS train 0.30032712444663046\n",
            "EPOCH 19951:\n",
            "  batch 5 loss: 0.7555880844593048\n",
            "  batch 10 loss: 0.7746302418410778\n",
            "  batch 15 loss: 0.5520819902420044\n",
            "LOSS train 0.5520819902420044\n",
            "EPOCH 19952:\n",
            "  batch 5 loss: 0.8461353421211243\n",
            "  batch 10 loss: 0.7446126908063888\n",
            "  batch 15 loss: 0.8867635607719422\n",
            "LOSS train 0.8867635607719422\n",
            "EPOCH 19953:\n",
            "  batch 5 loss: 0.8645074725151062\n",
            "  batch 10 loss: 0.5165358103811741\n",
            "  batch 15 loss: 0.523157550394535\n",
            "LOSS train 0.523157550394535\n",
            "EPOCH 19954:\n",
            "  batch 5 loss: 0.6612822115421295\n",
            "  batch 10 loss: 0.5971946388483047\n",
            "  batch 15 loss: 0.7968256950378418\n",
            "LOSS train 0.7968256950378418\n",
            "EPOCH 19955:\n",
            "  batch 5 loss: 0.7361489653587341\n",
            "  batch 10 loss: 0.9819147825241089\n",
            "  batch 15 loss: 0.5181736513972283\n",
            "LOSS train 0.5181736513972283\n",
            "EPOCH 19956:\n",
            "  batch 5 loss: 0.9269833445549012\n",
            "  batch 10 loss: 0.6479560166597367\n",
            "  batch 15 loss: 0.9041376233100891\n",
            "LOSS train 0.9041376233100891\n",
            "EPOCH 19957:\n",
            "  batch 5 loss: 0.8260735154151917\n",
            "  batch 10 loss: 1.0960980772972106\n",
            "  batch 15 loss: 0.5362378560006619\n",
            "LOSS train 0.5362378560006619\n",
            "EPOCH 19958:\n",
            "  batch 5 loss: 0.5208396732807159\n",
            "  batch 10 loss: 0.5607224620878697\n",
            "  batch 15 loss: 0.8224804610013962\n",
            "LOSS train 0.8224804610013962\n",
            "EPOCH 19959:\n",
            "  batch 5 loss: 0.41813223734498023\n",
            "  batch 10 loss: 0.5269548654556274\n",
            "  batch 15 loss: 0.5231844902038574\n",
            "LOSS train 0.5231844902038574\n",
            "EPOCH 19960:\n",
            "  batch 5 loss: 0.8652520418167114\n",
            "  batch 10 loss: 0.6993627727031708\n",
            "  batch 15 loss: 0.6014878511428833\n",
            "LOSS train 0.6014878511428833\n",
            "EPOCH 19961:\n",
            "  batch 5 loss: 0.5334394693374633\n",
            "  batch 10 loss: 0.7340260803699493\n",
            "  batch 15 loss: 0.8745306670665741\n",
            "LOSS train 0.8745306670665741\n",
            "EPOCH 19962:\n",
            "  batch 5 loss: 0.19036150127649307\n",
            "  batch 10 loss: 0.5373166471719741\n",
            "  batch 15 loss: 0.9102159142494202\n",
            "LOSS train 0.9102159142494202\n",
            "EPOCH 19963:\n",
            "  batch 5 loss: 0.7637029886245728\n",
            "  batch 10 loss: 0.6851430475711823\n",
            "  batch 15 loss: 0.42887009084224703\n",
            "LOSS train 0.42887009084224703\n",
            "EPOCH 19964:\n",
            "  batch 5 loss: 0.9008919298648834\n",
            "  batch 10 loss: 0.6249691903591156\n",
            "  batch 15 loss: 0.3143777266144753\n",
            "LOSS train 0.3143777266144753\n",
            "EPOCH 19965:\n",
            "  batch 5 loss: 0.5143338501453399\n",
            "  batch 10 loss: 0.7163655668497085\n",
            "  batch 15 loss: 0.5959948569536209\n",
            "LOSS train 0.5959948569536209\n",
            "EPOCH 19966:\n",
            "  batch 5 loss: 0.38691174387931826\n",
            "  batch 10 loss: 0.6097373068332672\n",
            "  batch 15 loss: 0.7676652848720551\n",
            "LOSS train 0.7676652848720551\n",
            "EPOCH 19967:\n",
            "  batch 5 loss: 0.9319669544696808\n",
            "  batch 10 loss: 0.6810288429260254\n",
            "  batch 15 loss: 0.618682511150837\n",
            "LOSS train 0.618682511150837\n",
            "EPOCH 19968:\n",
            "  batch 5 loss: 0.4676972717046738\n",
            "  batch 10 loss: 0.6831946805119514\n",
            "  batch 15 loss: 0.4471195928752422\n",
            "LOSS train 0.4471195928752422\n",
            "EPOCH 19969:\n",
            "  batch 5 loss: 0.7721476793289185\n",
            "  batch 10 loss: 0.5482102110981941\n",
            "  batch 15 loss: 0.8300262063741684\n",
            "LOSS train 0.8300262063741684\n",
            "EPOCH 19970:\n",
            "  batch 5 loss: 0.8397298812866211\n",
            "  batch 10 loss: 0.8830330163240433\n",
            "  batch 15 loss: 0.9076473653316498\n",
            "LOSS train 0.9076473653316498\n",
            "EPOCH 19971:\n",
            "  batch 5 loss: 0.6408680737018585\n",
            "  batch 10 loss: 0.8490878522396088\n",
            "  batch 15 loss: 0.5760195970535278\n",
            "LOSS train 0.5760195970535278\n",
            "EPOCH 19972:\n",
            "  batch 5 loss: 0.6371127352118492\n",
            "  batch 10 loss: 0.793040007352829\n",
            "  batch 15 loss: 0.9552381038665771\n",
            "LOSS train 0.9552381038665771\n",
            "EPOCH 19973:\n",
            "  batch 5 loss: 0.9023371815681458\n",
            "  batch 10 loss: 0.4997881203889847\n",
            "  batch 15 loss: 0.5188731729984284\n",
            "LOSS train 0.5188731729984284\n",
            "EPOCH 19974:\n",
            "  batch 5 loss: 0.6293911308050155\n",
            "  batch 10 loss: 0.7820040702819824\n",
            "  batch 15 loss: 0.7421840965747833\n",
            "LOSS train 0.7421840965747833\n",
            "EPOCH 19975:\n",
            "  batch 5 loss: 1.0055741488933563\n",
            "  batch 10 loss: 0.6147775992751121\n",
            "  batch 15 loss: 0.34698596596717834\n",
            "LOSS train 0.34698596596717834\n",
            "EPOCH 19976:\n",
            "  batch 5 loss: 1.0052268981933594\n",
            "  batch 10 loss: 0.6180589951574802\n",
            "  batch 15 loss: 0.5549882173538208\n",
            "LOSS train 0.5549882173538208\n",
            "EPOCH 19977:\n",
            "  batch 5 loss: 0.5165712922811508\n",
            "  batch 10 loss: 0.4323112815618515\n",
            "  batch 15 loss: 0.7471989750862121\n",
            "LOSS train 0.7471989750862121\n",
            "EPOCH 19978:\n",
            "  batch 5 loss: 0.6467395722866058\n",
            "  batch 10 loss: 0.817364227771759\n",
            "  batch 15 loss: 0.2749197006225586\n",
            "LOSS train 0.2749197006225586\n",
            "EPOCH 19979:\n",
            "  batch 5 loss: 0.47141450382769107\n",
            "  batch 10 loss: 0.41570510640740393\n",
            "  batch 15 loss: 0.5536685273051262\n",
            "LOSS train 0.5536685273051262\n",
            "EPOCH 19980:\n",
            "  batch 5 loss: 0.6687084615230561\n",
            "  batch 10 loss: 0.5335920870304107\n",
            "  batch 15 loss: 0.7883813679218292\n",
            "LOSS train 0.7883813679218292\n",
            "EPOCH 19981:\n",
            "  batch 5 loss: 0.7371224105358124\n",
            "  batch 10 loss: 0.7846519470214843\n",
            "  batch 15 loss: 0.8489217936992646\n",
            "LOSS train 0.8489217936992646\n",
            "EPOCH 19982:\n",
            "  batch 5 loss: 0.7045979589223862\n",
            "  batch 10 loss: 0.655060276389122\n",
            "  batch 15 loss: 0.843272352218628\n",
            "LOSS train 0.843272352218628\n",
            "EPOCH 19983:\n",
            "  batch 5 loss: 0.5983318015933037\n",
            "  batch 10 loss: 0.8498487949371338\n",
            "  batch 15 loss: 0.6885846227407455\n",
            "LOSS train 0.6885846227407455\n",
            "EPOCH 19984:\n",
            "  batch 5 loss: 0.7372149527072906\n",
            "  batch 10 loss: 0.7656990140676498\n",
            "  batch 15 loss: 0.6272380784153938\n",
            "LOSS train 0.6272380784153938\n",
            "EPOCH 19985:\n",
            "  batch 5 loss: 0.43910494819283485\n",
            "  batch 10 loss: 0.6024736523628235\n",
            "  batch 15 loss: 0.5467862069606781\n",
            "LOSS train 0.5467862069606781\n",
            "EPOCH 19986:\n",
            "  batch 5 loss: 0.7573896430432796\n",
            "  batch 10 loss: 0.6855067133903503\n",
            "  batch 15 loss: 0.7952710032463074\n",
            "LOSS train 0.7952710032463074\n",
            "EPOCH 19987:\n",
            "  batch 5 loss: 0.5336540892720223\n",
            "  batch 10 loss: 0.4923444926738739\n",
            "  batch 15 loss: 0.37628554701805117\n",
            "LOSS train 0.37628554701805117\n",
            "EPOCH 19988:\n",
            "  batch 5 loss: 0.9647479891777039\n",
            "  batch 10 loss: 1.0874120950698853\n",
            "  batch 15 loss: 0.6023932367563247\n",
            "LOSS train 0.6023932367563247\n",
            "EPOCH 19989:\n",
            "  batch 5 loss: 0.4843106471002102\n",
            "  batch 10 loss: 0.8342094656080008\n",
            "  batch 15 loss: 0.38756702169775964\n",
            "LOSS train 0.38756702169775964\n",
            "EPOCH 19990:\n",
            "  batch 5 loss: 1.0295295596122742\n",
            "  batch 10 loss: 0.7252650618553161\n",
            "  batch 15 loss: 0.6130816876888275\n",
            "LOSS train 0.6130816876888275\n",
            "EPOCH 19991:\n",
            "  batch 5 loss: 0.636248329281807\n",
            "  batch 10 loss: 0.7791453123092651\n",
            "  batch 15 loss: 0.98189218044281\n",
            "LOSS train 0.98189218044281\n",
            "EPOCH 19992:\n",
            "  batch 5 loss: 0.7410408020019531\n",
            "  batch 10 loss: 0.7239007234573365\n",
            "  batch 15 loss: 0.9985857129096984\n",
            "LOSS train 0.9985857129096984\n",
            "EPOCH 19993:\n",
            "  batch 5 loss: 0.588470259308815\n",
            "  batch 10 loss: 0.6404059037566185\n",
            "  batch 15 loss: 0.9304257273674011\n",
            "LOSS train 0.9304257273674011\n",
            "EPOCH 19994:\n",
            "  batch 5 loss: 0.5706867873668671\n",
            "  batch 10 loss: 1.2502768993377686\n",
            "  batch 15 loss: 0.6410451650619506\n",
            "LOSS train 0.6410451650619506\n",
            "EPOCH 19995:\n",
            "  batch 5 loss: 0.8342464953660965\n",
            "  batch 10 loss: 0.7644841194152832\n",
            "  batch 15 loss: 0.41240515038371084\n",
            "LOSS train 0.41240515038371084\n",
            "EPOCH 19996:\n",
            "  batch 5 loss: 0.5473046576604247\n",
            "  batch 10 loss: 0.6929065823554993\n",
            "  batch 15 loss: 0.6265956819057464\n",
            "LOSS train 0.6265956819057464\n",
            "EPOCH 19997:\n",
            "  batch 5 loss: 1.0312701791524888\n",
            "  batch 10 loss: 0.6973329514265061\n",
            "  batch 15 loss: 0.7267273873090744\n",
            "LOSS train 0.7267273873090744\n",
            "EPOCH 19998:\n",
            "  batch 5 loss: 0.7719524174928665\n",
            "  batch 10 loss: 0.6729725778102875\n",
            "  batch 15 loss: 0.5410044878721237\n",
            "LOSS train 0.5410044878721237\n",
            "EPOCH 19999:\n",
            "  batch 5 loss: 0.49093772023916243\n",
            "  batch 10 loss: 0.5287795305252075\n",
            "  batch 15 loss: 0.5478121310472488\n",
            "LOSS train 0.5478121310472488\n",
            "EPOCH 20000:\n",
            "  batch 5 loss: 0.7630791127681732\n",
            "  batch 10 loss: 0.7286051750183106\n",
            "  batch 15 loss: 0.614151781797409\n",
            "LOSS train 0.614151781797409\n",
            "Switching to L-BFGS for fine-tuning...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LBFGS.__init__() missing 1 required positional argument: 'params'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2336095233.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Initialize L-BFGS optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     lbfgs_optimizer = torch.optim.LBFGS(max_iter=1000, # Allow more iterations\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mtolerance_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Stricter gradient tolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtolerance_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# Stricter tolerance for parameter changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LBFGS.__init__() missing 1 required positional argument: 'params'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses[1]"
      ],
      "metadata": {
        "id": "rVPNMNN_hcPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #if training got interrupted manually, save\n",
        "# torch.save({'epoch': n_epochs,\n",
        "#                'model_state_dict': model.state_dict(),\n",
        "#                'optimizer_state_dict': optimizer.state_dict(),\n",
        "#                'loss': avg_loss\n",
        "#                }, f'boundary_pinn_interrupt.pt')"
      ],
      "metadata": {
        "id": "YxEwElAX1QmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Visualizing the training"
      ],
      "metadata": {
        "id": "AO4_yN84TeWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization for training losses across curriculum steps\n",
        "if nb_curriculum < 3:\n",
        "    # If the number of curricula is less than 3, plot only the last curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.loglog(losses[-1], label=f'Last Curriculum ({nb_curriculum}/{nb_curriculum})', color='C0')\n",
        "    plt.title(f'Training Loss for Curriculum PINN ({method})', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Loss (log scale)', fontsize=14)\n",
        "    plt.legend(fontsize=12, loc='upper right')\n",
        "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    # If there are 3 or more curricula, plot the 1st, middle, and last curves\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Determine which curricula to plot: first, middle, last\n",
        "    curricula_to_plot = [nb_curriculum // 3, 2 * nb_curriculum // 3, nb_curriculum - 1]\n",
        "    titles = [\n",
        "        f'Curriculum: {nb_curriculum // 3}/{nb_curriculum}',\n",
        "        f'Curriculum: {2 * nb_curriculum // 3}/{nb_curriculum}',\n",
        "        f'Final Curriculum: {nb_curriculum}/{nb_curriculum}'\n",
        "    ]\n",
        "\n",
        "    # Loop over the subplots to plot the chosen curricula\n",
        "    for i, ax in enumerate(axs):\n",
        "        ax.loglog(losses[curricula_to_plot[i]], label=titles[i], color=f'C{i}')\n",
        "        ax.set_title(titles[i], fontsize=14)\n",
        "        ax.set_xlabel('Epochs', fontsize=12)\n",
        "        ax.set_ylabel('Loss (log scale)', fontsize=12)\n",
        "        ax.legend(fontsize=10, loc='upper right')\n",
        "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
        "\n",
        "    # Adjust layout for better spacing\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fHEYUG0FTjQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6bis) Training for longer if convergence isn't attained [optional]"
      ],
      "metadata": {
        "id": "kT6gvCgBdUZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #reloading the previously saved checkpoint\n",
        "# checkpoint = torch.load(f'boundary_pinn_curriculum_{method}.pt')\n",
        "\n",
        "# #intialization of the model and optimizer\n",
        "# model = BoundaryPINN(power=power, width=width, depth=depth)\n",
        "\n",
        "# extra_epochs = 10_000\n",
        "# n_decreases = 100\n",
        "# learning_rate_adam = 1e-4\n",
        "# damping = 1e-2\n",
        "# gamma = damping**(1/n_decreases)\n",
        "\n",
        "# if method == 'Adam':\n",
        "#         optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_adam)\n",
        "#         scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\\\n",
        "#                                                     step_size=extra_epochs//n_decreases,\\\n",
        "#                                                     gamma=gamma)\n",
        "\n",
        "\n",
        "# #reloading of parameters from end of previous training\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# start_epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# #retrain for 'extra_epochs'\n",
        "# for epoch in range(start_epoch+1, start_epoch + extra_epochs):\n",
        "#         #epoch_number += 1\n",
        "#         print('EPOCH {}:'.format(epoch))\n",
        "\n",
        "#         # Make sure gradient tracking is on, and do a pass over the data\n",
        "#         model.train(True)\n",
        "#         avg_loss = train_one_epoch(model, optimizer, zeta, eps, losses[i])\n",
        "#         scheduler.step()\n",
        "#         print('LOSS train {}'.format(avg_loss))\n",
        "\n",
        "# #save the further trained model and reset optimizer\n",
        "# torch.save({'epoch': start_epoch + extra_epochs,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'loss': avg_loss\n",
        "#             }, f'boundary_pinn_curriculum_{method}.pt')"
      ],
      "metadata": {
        "id": "6DUzmzQ2eb-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.loglog(losses[0])\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Training Loss\")\n",
        "# plt.title('Loss w.r.t Epoch ({0})'.format(method))\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "PlS6eDY6tne5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Visualizing the learned solution"
      ],
      "metadata": {
        "id": "RIy6mdU8ToZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the model\n",
        "final_checkpoint = torch.load(f'boundary_pinn_curriculum_{nb_curriculum}.pt')\n",
        "model.load_state_dict(final_checkpoint['model_state_dict'])\n",
        "\n",
        "#evaluate the model on a uniform grid\n",
        "n_points = 150\n",
        "tt = np.linspace(-1, 1, n_points) * radius\n",
        "xx, yy = np.meshgrid(tt, tt)  # create unit square grid\n",
        "xx, yy = np.where(xx**2 + yy**2 <= radius**2, xx, 0), np.where(xx**2 + yy**2 <= radius**2 , yy, 0) #(https://stackoverflow.com/questions/15733530/)\n",
        "#zz_true = true_solution_vectorized(xx,yy)\n",
        "\n",
        "input = torch.from_numpy(np.vstack((xx.ravel(),yy.ravel())).T).float()#.requires_grad_(False)\n",
        "learned_sol = model(input)\n",
        "\n",
        "#plot\n",
        "learned_sol_np = learned_sol.detach().numpy().reshape(xx.shape)\n",
        "#learned_sol_smooth = ndimage.gaussian_filter(learned_sol_np, sigma=0.1, order=0) #smoothing for visualization\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(cx, cy,'k-', alpha=.2)\n",
        "contour = ax.contourf(xx, yy, learned_sol_np, levels=200)\n",
        "ax.set_title(f'Curriculum PINN solution ({method})')\n",
        "cb = fig.colorbar(contour, ax=ax)"
      ],
      "metadata": {
        "id": "H8ajidIPTrPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verify that the model is zero on the boundary\n",
        "circle = torch.from_numpy(np.vstack((cx.ravel(),cy.ravel())).T).float().requires_grad_(False)\n",
        "torch.sum(model(circle)**2) #== 0"
      ],
      "metadata": {
        "id": "zbAtgo_HTvdC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}