{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAzCTaF2LQ5Lb6OuzBibE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StratosFair/Mean_Escape_Time/blob/main/OU_process_2D/Models/%5BFINAL%5Dsimple_pinn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & FP64\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "import scipy.special as special\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "zWfcku6GqTt1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving for the MET of an Ornstein-Uhlenbeck process in a disk with \"Simple PINNs\": comparison with exact solution"
      ],
      "metadata": {
        "id": "wDHeduNpyl5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup\n",
        "\n",
        "For $\\theta,\\sigma,r >0$ some fixed parameters, we let $\\Omega := B_r \\equiv \\{x\\in\\mathbb R^d : \\|x\\|< r \\}$, and define the process ($d=2$ in our illustration) :\n",
        "\n",
        "$$\\begin{cases} dX_t &= -\\theta X_t dt + \\sigma dB_t \\\\\n",
        "X_0 &= x \\in \\Omega \\end{cases} $$\n",
        "\n",
        "For all $x\\in\\Omega$, let\n",
        "\n",
        "$$T(x) := \\inf\\{t\\ge 0 : X_t \\in\\partial\\Omega\\} $$\n",
        "\n",
        "and let its first moment be denoted\n",
        "\n",
        "$$\\tau(x) := \\mathbb E[T(x)] $$\n",
        "\n",
        "We can show under some regularity conditions on $\\Omega$ that $\\tau$ is the (unique) solution of the BVP :\n",
        "\n",
        "$$\\begin{cases} -\\mathcal{L}u(x) &= 1 \\text{ for all } x\\in\\Omega \\\\\n",
        "u(x) &= 0 \\text{ for all } x\\in\\partial\\Omega \\end{cases} $$\n",
        "\n",
        "where $\\mathcal L$ is the infinitesimal generator of the Ornstein-Uhlenbeck process, given by\n",
        "$$\\mathcal Lu : x \\mapsto -\\theta x \\cdot \\nabla u(x) + \\frac{\\sigma^2}{2}\\Delta u(x) $$"
      ],
      "metadata": {
        "id": "EpGLkz71ym36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nicely enough, for this problem, we can compare our solution with the known closed-form solution (see https://arxiv.org/abs/2208.04029) :\n",
        "\n",
        "$$ \\tau(x) := \\frac{1}{\\lambda^{d/2}\\sigma^2}\\int_\\rho^r z^{1-d} e^{\\lambda z^2} \\gamma(d/2, \\lambda z^2)\\ dz $$\n",
        "\n",
        "where $\\lambda := \\theta/\\sigma^2 $, $\\rho := \\|x\\| $ and $\\gamma$ is the upper incomplete gamma function :\n",
        "$$\\gamma(n,y) := \\int_0^y t^{n-1} e^{-t}\\ dt.  $$"
      ],
      "metadata": {
        "id": "ah5DvZTq7uP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem Parameters & True Solution\n",
        "R = 2.0\n",
        "theta = 3.0\n",
        "sigma2 = 2.0\n",
        "sigma = np.sqrt(sigma2)\n",
        "\n",
        "def true_tau(x, y, theta=theta, sigma=sigma, R=R):\n",
        "    lam = theta / sigma**2\n",
        "    rho = np.sqrt(x**2 + y**2)\n",
        "    integrand = lambda t: np.exp(lam * t**2) * special.gammainc(1, lam * t**2) / t\n",
        "    I, _ = integrate.quad(integrand, rho, R)\n",
        "    return I / theta\n",
        "\n",
        "true_tau_vec = np.vectorize(true_tau)"
      ],
      "metadata": {
        "id": "1lyRR4sIqUbT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_pts = 200\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(-R,R,n_pts),\n",
        "    np.linspace(-R,R,n_pts)\n",
        ")\n",
        "mask = xx**2 + yy**2 <= R**2\n",
        "pts = np.vstack([xx[mask], yy[mask]]).T\n",
        "\n",
        "Zp = np.zeros_like(xx)\n",
        "Zp[mask] = true_tau_vec(xx[mask], yy[mask])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "cf2 = ax.contourf(xx, yy, Zp, levels=50, cmap='viridis')\n",
        "ax.set_title('True tau')\n",
        "fig.colorbar(cf2, ax=ax, shrink=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "M8_HjKngjN6Q",
        "outputId": "5ec2d1cc-8ff7-4640-ebf2-3dd126672b8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Neural Network architecture and loss function\n",
        "\n",
        "We are implementing a standard PINN to solve the MET elliptic PDE. Our objective to minimize thus takes the form\n",
        "$$\\hat u := \\arg\\min_{u\\in\\mathcal{NN}}\\ \\frac{1}{n_c} \\sum_{i=1}^{n_c} (\\mathcal L u(x_i^c) + 1)^2 + \\frac{\\lambda}{n_b} \\sum_{i=1}^{n_b} u(x_i^b)^2  $$\n",
        "where $x_i^c$ are sampled i.i.d. with uniform distribution on $\\Omega$, $x_i^b$ are sampled i.i.d. with uniform distribution on $\\partial\\Omega$, and the hypothesis space is given by\n",
        "$$\\mathcal{NN}:=\\left\\{x\\mapsto T_L\\circ \\sigma \\circ T_{L-1}\\circ\\cdots\\circ \\sigma\\circ T_1 (x)\\right\\}, $$\n",
        "for\n",
        "$$T_\\ell : \\mathbb{R}^{\\ell-1}\\to\\mathbb{R}^\\ell $$\n",
        "affine-linear maps of appropriate input-output dimensions, where\n",
        "$$\\sigma :x \\mapsto \\begin{cases}x^2 &\\text{ if } x\\ge 0\\\\ 0 &\\text{ if } x\\le 0\\end{cases} \\quad \\text{OR }\\ \\ \\sigma : x\\mapsto \\operatorname{tanh}(x),$$\n",
        "is either the ReQU or hyperbolic tangent activation function, which is understood element-wise when applied to vectors."
      ],
      "metadata": {
        "id": "ipb5U7KL7yL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Standard PINN without matching boundary condition\n",
        "power = None #exponent k for relu^k, none for tanh\n",
        "width = 30\n",
        "depth = 3\n",
        "gain = 2.0 #magnitude of weights at initialization\n",
        "\n",
        "#define ReLU^k activation\n",
        "\n",
        "class RePU(nn.Module):\n",
        "    def __init__(self, power = power):\n",
        "        super(RePU, self).__init__()\n",
        "        self.power = power\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.pow(torch.relu(x), self.power)\n",
        "\n",
        "#define hypothesis space\n",
        "class SimplePINN(nn.Module):\n",
        "    def __init__(self, power=power, width=width, depth=depth):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(2, width))\n",
        "\n",
        "        # activation for the first hidden block\n",
        "        if isinstance(power, int):\n",
        "            self.layers.append(RePU(power))\n",
        "        else:\n",
        "            self.layers.append(nn.Tanh())\n",
        "\n",
        "        # hidden blocks\n",
        "        for _ in range(depth - 1):\n",
        "            self.layers.append(nn.Linear(width, width))\n",
        "            self.layers.append(nn.Tanh() if power is None else RePU(power))\n",
        "\n",
        "        # output layer (scalar)\n",
        "        self.layers.append(nn.Linear(width, 1))\n",
        "        self.mlp = nn.Sequential(*self.layers)\n",
        "\n",
        "        # learnable scaling factors (used for dynamic weighting)\n",
        "        self.log_sigma_pde = nn.Parameter(torch.tensor(-0.5, dtype=torch.float64))\n",
        "        self.log_sigma_data = nn.Parameter(torch.tensor(-0.5, dtype=torch.float64))\n",
        "        self.log_sigma_bc = nn.Parameter(torch.tensor(-0.5, dtype=torch.float64))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x).squeeze(-1)\n",
        "\n",
        "#weight initialization\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(m.weight, gain=gain)\n",
        "        m.bias.data.fill_(gain)"
      ],
      "metadata": {
        "id": "kNAMxUlRqa3D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining PDE Residual & Loss, enabling grad on x\n",
        "def pde_residual(model, x, theta, sigma, forcing = None):\n",
        "    # ensure x is on the right device, float64, and requires grad\n",
        "    x = x.clone().detach().to(device).requires_grad_(True)\n",
        "\n",
        "    # forward through PINN\n",
        "    tau = model(x)                                # [N]\n",
        "    # first derivatives\n",
        "    grads = torch.autograd.grad(\n",
        "        tau, x,\n",
        "        grad_outputs=torch.ones_like(tau),\n",
        "        create_graph=True,\n",
        "    )[0]                                        # [N,2]\n",
        "    tau_x, tau_y = grads[:,0], grads[:,1]\n",
        "\n",
        "    # second derivatives\n",
        "    tau_xx = torch.autograd.grad(\n",
        "        tau_x, x,\n",
        "        grad_outputs=torch.ones_like(tau_x),\n",
        "        create_graph=True\n",
        "    )[0][:,0]\n",
        "    tau_yy = torch.autograd.grad(\n",
        "        tau_y, x,\n",
        "        grad_outputs=torch.ones_like(tau_y),\n",
        "        create_graph=True\n",
        "    )[0][:,1]\n",
        "\n",
        "    # OUgenerator L[tau]\n",
        "    phys = -theta*(x[:,0]*tau_x + x[:,1]*tau_y) \\\n",
        "           + 0.5*sigma**2*(tau_xx + tau_yy)\n",
        "\n",
        "    if forcing is None:\n",
        "        # default constant 1\n",
        "        f_vals = -1.0\n",
        "    elif isinstance(forcing, (int, float)):\n",
        "        # constant forcing = that number\n",
        "        f_vals = float(forcing)\n",
        "    elif callable(forcing):\n",
        "        # call it on x\n",
        "        f_vals = forcing(x)\n",
        "        # flatten to [N]\n",
        "        if f_vals.dim() > 1:\n",
        "            f_vals = f_vals.view(-1)\n",
        "    else:\n",
        "        raise ValueError(f\"forcing must be None, float, or callable, got {type(forcing)}\")\n",
        "\n",
        "    # turn any scalar into a tensor of shape [N]\n",
        "    if isinstance(f_vals, float) or isinstance(f_vals, int):\n",
        "        f_vals = x.new_full((x.shape[0],), float(f_vals))\n",
        "\n",
        "    # 7) residual = L[tau] - f(x)\n",
        "    r = phys - f_vals              # shape [N]\n",
        "    return r\n",
        "\n",
        "def loss_fn(res):\n",
        "    return torch.mean(res.pow(2))"
      ],
      "metadata": {
        "id": "RDSBmM64qd26"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empirical_h2_norm(model, x_batch):\n",
        "    \"\"\"\n",
        "    Empirical H norm of the *raw* NN output u(x) = model.raw_forward(x)\n",
        "    computed exactly like your pde_residual (component-wise gradients).\n",
        "\n",
        "    Returns a scalar tensor (mean over the batch).\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1) Prepare the input exactly as in pde_residual\n",
        "    # ------------------------------------------------------------------\n",
        "    x = x_batch.clone().detach().requires_grad_(True)   # shape [N,2]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2) 0-th order term :  u\n",
        "    # ------------------------------------------------------------------\n",
        "    u = model(x)                # [N,1]\n",
        "    u_sq = torch.mean(u.pow(2))              # scalar\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3) 1-st order term :  |u|  =  u_x + u_y\n",
        "    # ------------------------------------------------------------------\n",
        "    grad_u = torch.autograd.grad(\n",
        "        u, x,\n",
        "        grad_outputs=torch.ones_like(u),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]                                     # [N,2]\n",
        "    u_x, u_y = grad_u[:, 0], grad_u[:, 1]\n",
        "\n",
        "    grad_sq = torch.mean(u_x.pow(2) + u_y.pow(2))   # scalar\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4) 2-nd order term :  ||u||_F  =  u_xx + u_xy + u_yx + u_yy\n",
        "    # ------------------------------------------------------------------\n",
        "    #   u_xx\n",
        "    u_xx = torch.autograd.grad(\n",
        "        u_x, x,\n",
        "        grad_outputs=torch.ones_like(u_x),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0][:, 0]                               # [N]\n",
        "\n",
        "    #   u_yy\n",
        "    u_yy = torch.autograd.grad(\n",
        "        u_y, x,\n",
        "        grad_outputs=torch.ones_like(u_y),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0][:, 1]                               # [N]\n",
        "\n",
        "    #   mixed derivatives u_xy = /y (u_x)  and  u_yx = /x (u_y)\n",
        "    #   (they are equal for C functions, but we compute both to be safe)\n",
        "    u_xy = torch.autograd.grad(\n",
        "        u_x, x,\n",
        "        grad_outputs=torch.ones_like(u_x),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0][:, 1]                               # /y of u_x   [N]\n",
        "\n",
        "    u_yx = torch.autograd.grad(\n",
        "        u_y, x,\n",
        "        grad_outputs=torch.ones_like(u_y),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0][:, 0]                               # /x of u_y   [N]\n",
        "\n",
        "    hessian_fro_sq = torch.mean(\n",
        "        u_xx.pow(2) + u_xy.pow(2) + u_yx.pow(2) + u_yy.pow(2)\n",
        "    )                                        # scalar\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 5) Assemble the full H norm (mean over the batch)\n",
        "    # ------------------------------------------------------------------\n",
        "    h2 = u_sq + grad_sq + hessian_fro_sq\n",
        "    return h2"
      ],
      "metadata": {
        "id": "fxKIqN7gO4PQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Computing an approximate data penalty regularization\n",
        "\n",
        "We sample a small subset $x_1, \\ldots, x_{n_{d}} \\in \\Omega$ of points for which we compute approximate values $\\tau^{MC}(x_1), \\ldots, \\tau^{MC}(x_{n_{d}}) $ by Monte Carlo. we will then use them to define a \"data-fidelity\" penalty term in the loss function:\n",
        "$$\\text{Penalty}(\\hat\\tau_{NN}) = \\frac{\\lambda_{d}}{n_{d}} \\sum_{i=1}^{n_d} \\left(\\tau^{MC}(x_i) - \\hat\\tau_{NN}(x_i)\\right)^2, $$\n",
        "where $\\lambda_{d}$ is a positive regularization parameter."
      ],
      "metadata": {
        "id": "xA77CH6N03KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generating some approximate true solutions in the domain\n",
        "\n",
        "# uniform sampling in disk of radius R\n",
        "@torch.no_grad()\n",
        "def sample_disk(batch_size, R):\n",
        "    \"\"\"\n",
        "    Sample uniformly in the disk of radius R.\n",
        "    \"\"\"\n",
        "    r = torch.sqrt(torch.rand(batch_size, device=device))  # sqrt for uniform area\n",
        "    theta = 2 * torch.pi * torch.rand(batch_size, device=device)\n",
        "    x = torch.stack([r * torch.cos(theta), r * torch.sin(theta)], dim=1)\n",
        "    return R * x  # uniform in disk of radius R\n",
        "\n",
        "\n",
        "# 2) monte-carlo (euler-maruyama) approximation of tau at these points\n",
        "@torch.no_grad()\n",
        "def mc_exit_time(x0, theta, sigma, R,\n",
        "                 n_paths=128, dt=1e-3, max_steps=20000):\n",
        "    \"\"\"\n",
        "    x0: [B,2] starting points\n",
        "    Returns tau_hat: [B] = mean exit time from each x0.\n",
        "    Any path still 'alive' after max_steps is counted as having exit time = max_steps*dt.\n",
        "    \"\"\"\n",
        "    B = x0.shape[0]\n",
        "    P = n_paths\n",
        "\n",
        "    # Expand to per-path positions\n",
        "    X = x0.unsqueeze(1).expand(B, P, 2).clone()  # [B,P,2]\n",
        "    t = torch.zeros(B, P, device=device)         # running clock\n",
        "    alive = torch.ones(B, P, dtype=torch.bool, device=device)\n",
        "    sqrt_dt = sigma * (dt ** 0.5)\n",
        "\n",
        "    # For progress tracking\n",
        "    print_interval = max(1, max_steps // 100)\n",
        "    total_paths = B * P\n",
        "    exited_count = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        if not alive.any():\n",
        "            break\n",
        "\n",
        "        # Drift + noise, but only update those still alive\n",
        "        X_alive = X[alive]\n",
        "        drift    = -theta * X_alive * dt\n",
        "        noise    = sqrt_dt * torch.randn_like(X_alive)\n",
        "        X[alive] = X_alive + drift + noise\n",
        "        t[alive] += dt\n",
        "\n",
        "        # Mark newly-exited paths\n",
        "        normsq = X[alive].pow(2).sum(dim=1)\n",
        "        just_exited = (normsq >= R*R)\n",
        "\n",
        "        if just_exited.any():\n",
        "            idx_alive = alive.nonzero(as_tuple=False)  # [N,2]\n",
        "            exited_idx = idx_alive[just_exited]\n",
        "            alive[exited_idx[:,0], exited_idx[:,1]] = False\n",
        "            exited_count += just_exited.sum().item()\n",
        "\n",
        "        # Progress print\n",
        "        if step % print_interval == 0 or step == max_steps - 1:\n",
        "            frac_alive = alive.float().mean().item()\n",
        "            current_t = step * dt\n",
        "            print(f\"Step {step:5d} | t = {current_t:6.2f} | alive: {frac_alive*100:5.2f}% \"\n",
        "                  f\"({total_paths - exited_count}/{total_paths} exited)\", flush=True)\n",
        "\n",
        "    # Paths still alive get t = max_steps*dt automatically from the loop\n",
        "    tau_hat = t.mean(dim=1)  # [B]\n",
        "\n",
        "    # Warn if many paths didn't exit\n",
        "    survived = alive.sum().item()\n",
        "    if survived > 0:\n",
        "        print(f\"WARNING: {survived}/{B*P} paths did NOT exit by t = {max_steps*dt:.2f}\")\n",
        "\n",
        "    return tau_hat  # no gradient flows back"
      ],
      "metadata": {
        "id": "c5kssEpIlEnh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Uniform Sampling functions on the disk and on the boundary\n",
        "def sample_uniform_disk(N, R=R):\n",
        "    theta = 2*np.pi * torch.rand(N, dtype=torch.float64, device=device)\n",
        "    rho = R    * torch.sqrt(torch.rand(N, dtype=torch.float64, device=device))\n",
        "    return torch.stack([rho*torch.cos(theta), rho*torch.sin(theta)], dim=1)  # [N,2]\n",
        "\n",
        "def sample_boundary(N, R=R):\n",
        "    theta = 2 * math.pi * torch.rand(N, device=device)\n",
        "    x = R * torch.cos(theta)\n",
        "    y = R * torch.sin(theta)\n",
        "    return torch.stack([x, y], dim=1)"
      ],
      "metadata": {
        "id": "IJI5xaOUqom1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Training loop"
      ],
      "metadata": {
        "id": "gkRR91T6_atw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 6.1) Training Parameters"
      ],
      "metadata": {
        "id": "Qo8UoTLI_lue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "pool_size        = 8192\n",
        "n_batches        = 16\n",
        "batch_size       = pool_size // n_batches\n",
        "n_epochs         = 10_000\n",
        "learning_rate    = 5e-4\n",
        "\n",
        "# model instantiation\n",
        "model = SimplePINN(power, width, depth).to(device)\n",
        "model.apply(init_weights)\n",
        "\n",
        "opt   = torch.optim.Adam(list(model.parameters()), lr=learning_rate)\n",
        "\n",
        "# scheduler: every `epochs_between_decays` epochs, multiply lr by gamma\n",
        "num_decays = 100\n",
        "epochs_between_decay = n_epochs // num_decays\n",
        "final_factor = 1e-3\n",
        "gamma = np.exp(np.log(final_factor) / num_decays)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    opt,\n",
        "    step_size=epochs_between_decay,  # decay every N epochs\n",
        "    gamma=gamma                      # LR *= gamma at each decay\n",
        ")"
      ],
      "metadata": {
        "id": "Oq-NigAc8Ag2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2) Generating the \"data-fidelity\" samples"
      ],
      "metadata": {
        "id": "7iyHryGJ_pU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample x_data\n",
        "x_data = sample_disk(batch_size//2, R = R)\n",
        "\n",
        "max_time = 30\n",
        "dt = 5e-4\n",
        "\n",
        "# precompute tau_data once (theta, sigma are fixed PDE params)\n",
        "tau_data = mc_exit_time(\n",
        "    x0       = x_data,\n",
        "    theta    = theta,\n",
        "    sigma    = sigma,\n",
        "    R        = R,\n",
        "    n_paths  = 256,\n",
        "    dt       = dt,\n",
        "    max_steps= int(max_time / dt)\n",
        ")"
      ],
      "metadata": {
        "id": "kepv7k3TzfBU",
        "outputId": "365207cc-eda0-490c-ee05-d9fe70b2cd38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step     0 | t =   0.00 | alive: 99.21% (65019/65536 exited)\n",
            "Step   600 | t =   0.30 | alive: 82.60% (54132/65536 exited)\n",
            "Step  1200 | t =   0.60 | alive: 80.51% (52762/65536 exited)\n",
            "Step  1800 | t =   0.90 | alive: 78.96% (51745/65536 exited)\n",
            "Step  2400 | t =   1.20 | alive: 77.33% (50678/65536 exited)\n",
            "Step  3000 | t =   1.50 | alive: 75.65% (49575/65536 exited)\n",
            "Step  3600 | t =   1.80 | alive: 74.24% (48653/65536 exited)\n",
            "Step  4200 | t =   2.10 | alive: 72.74% (47669/65536 exited)\n",
            "Step  4800 | t =   2.40 | alive: 71.26% (46699/65536 exited)\n",
            "Step  5400 | t =   2.70 | alive: 69.89% (45800/65536 exited)\n",
            "Step  6000 | t =   3.00 | alive: 68.55% (44927/65536 exited)\n",
            "Step  6600 | t =   3.30 | alive: 67.11% (43983/65536 exited)\n",
            "Step  7200 | t =   3.60 | alive: 65.72% (43071/65536 exited)\n",
            "Step  7800 | t =   3.90 | alive: 64.47% (42250/65536 exited)\n",
            "Step  8400 | t =   4.20 | alive: 63.21% (41426/65536 exited)\n",
            "Step  9000 | t =   4.50 | alive: 61.91% (40574/65536 exited)\n",
            "Step  9600 | t =   4.80 | alive: 60.66% (39752/65536 exited)\n",
            "Step 10200 | t =   5.10 | alive: 59.50% (38997/65536 exited)\n",
            "Step 10800 | t =   5.40 | alive: 58.28% (38194/65536 exited)\n",
            "Step 11400 | t =   5.70 | alive: 57.16% (37460/65536 exited)\n",
            "Step 12000 | t =   6.00 | alive: 55.99% (36696/65536 exited)\n",
            "Step 12600 | t =   6.30 | alive: 54.88% (35965/65536 exited)\n",
            "Step 13200 | t =   6.60 | alive: 53.85% (35293/65536 exited)\n",
            "Step 13800 | t =   6.90 | alive: 52.82% (34615/65536 exited)\n",
            "Step 14400 | t =   7.20 | alive: 51.73% (33900/65536 exited)\n",
            "Step 15000 | t =   7.50 | alive: 50.59% (33156/65536 exited)\n",
            "Step 15600 | t =   7.80 | alive: 49.55% (32476/65536 exited)\n",
            "Step 16200 | t =   8.10 | alive: 48.53% (31802/65536 exited)\n",
            "Step 16800 | t =   8.40 | alive: 47.58% (31180/65536 exited)\n",
            "Step 17400 | t =   8.70 | alive: 46.63% (30559/65536 exited)\n",
            "Step 18000 | t =   9.00 | alive: 45.72% (29962/65536 exited)\n",
            "Step 18600 | t =   9.30 | alive: 44.85% (29392/65536 exited)\n",
            "Step 19200 | t =   9.60 | alive: 43.90% (28772/65536 exited)\n",
            "Step 19800 | t =   9.90 | alive: 43.03% (28198/65536 exited)\n",
            "Step 20400 | t =  10.20 | alive: 42.20% (27653/65536 exited)\n",
            "Step 21000 | t =  10.50 | alive: 41.36% (27103/65536 exited)\n",
            "Step 21600 | t =  10.80 | alive: 40.53% (26559/65536 exited)\n",
            "Step 22200 | t =  11.10 | alive: 39.72% (26033/65536 exited)\n",
            "Step 22800 | t =  11.40 | alive: 38.91% (25497/65536 exited)\n",
            "Step 23400 | t =  11.70 | alive: 38.14% (24993/65536 exited)\n",
            "Step 24000 | t =  12.00 | alive: 37.42% (24526/65536 exited)\n",
            "Step 24600 | t =  12.30 | alive: 36.61% (23994/65536 exited)\n",
            "Step 25200 | t =  12.60 | alive: 35.81% (23468/65536 exited)\n",
            "Step 25800 | t =  12.90 | alive: 35.10% (23000/65536 exited)\n",
            "Step 26400 | t =  13.20 | alive: 34.44% (22573/65536 exited)\n",
            "Step 27000 | t =  13.50 | alive: 33.76% (22126/65536 exited)\n",
            "Step 27600 | t =  13.80 | alive: 33.08% (21678/65536 exited)\n",
            "Step 28200 | t =  14.10 | alive: 32.39% (21225/65536 exited)\n",
            "Step 28800 | t =  14.40 | alive: 31.75% (20809/65536 exited)\n",
            "Step 29400 | t =  14.70 | alive: 31.09% (20378/65536 exited)\n",
            "Step 30000 | t =  15.00 | alive: 30.45% (19958/65536 exited)\n",
            "Step 30600 | t =  15.30 | alive: 29.77% (19510/65536 exited)\n",
            "Step 31200 | t =  15.60 | alive: 29.14% (19095/65536 exited)\n",
            "Step 31800 | t =  15.90 | alive: 28.60% (18742/65536 exited)\n",
            "Step 32400 | t =  16.20 | alive: 27.98% (18340/65536 exited)\n",
            "Step 33000 | t =  16.50 | alive: 27.44% (17981/65536 exited)\n",
            "Step 33600 | t =  16.80 | alive: 26.90% (17629/65536 exited)\n",
            "Step 34200 | t =  17.10 | alive: 26.37% (17279/65536 exited)\n",
            "Step 34800 | t =  17.40 | alive: 25.84% (16936/65536 exited)\n",
            "Step 35400 | t =  17.70 | alive: 25.33% (16601/65536 exited)\n",
            "Step 36000 | t =  18.00 | alive: 24.81% (16260/65536 exited)\n",
            "Step 36600 | t =  18.30 | alive: 24.33% (15942/65536 exited)\n",
            "Step 37200 | t =  18.60 | alive: 23.82% (15613/65536 exited)\n",
            "Step 37800 | t =  18.90 | alive: 23.35% (15302/65536 exited)\n",
            "Step 38400 | t =  19.20 | alive: 22.91% (15016/65536 exited)\n",
            "Step 39000 | t =  19.50 | alive: 22.47% (14723/65536 exited)\n",
            "Step 39600 | t =  19.80 | alive: 22.02% (14430/65536 exited)\n",
            "Step 40200 | t =  20.10 | alive: 21.55% (14122/65536 exited)\n",
            "Step 40800 | t =  20.40 | alive: 21.10% (13831/65536 exited)\n",
            "Step 41400 | t =  20.70 | alive: 20.68% (13554/65536 exited)\n",
            "Step 42000 | t =  21.00 | alive: 20.31% (13308/65536 exited)\n",
            "Step 42600 | t =  21.30 | alive: 19.92% (13053/65536 exited)\n",
            "Step 43200 | t =  21.60 | alive: 19.52% (12790/65536 exited)\n",
            "Step 43800 | t =  21.90 | alive: 19.11% (12525/65536 exited)\n",
            "Step 44400 | t =  22.20 | alive: 18.76% (12292/65536 exited)\n",
            "Step 45000 | t =  22.50 | alive: 18.44% (12082/65536 exited)\n",
            "Step 45600 | t =  22.80 | alive: 18.12% (11876/65536 exited)\n",
            "Step 46200 | t =  23.10 | alive: 17.79% (11659/65536 exited)\n",
            "Step 46800 | t =  23.40 | alive: 17.38% (11392/65536 exited)\n",
            "Step 47400 | t =  23.70 | alive: 17.04% (11165/65536 exited)\n",
            "Step 48000 | t =  24.00 | alive: 16.68% (10934/65536 exited)\n",
            "Step 48600 | t =  24.30 | alive: 16.34% (10711/65536 exited)\n",
            "Step 49200 | t =  24.60 | alive: 16.05% (10517/65536 exited)\n",
            "Step 49800 | t =  24.90 | alive: 15.73% (10307/65536 exited)\n",
            "Step 50400 | t =  25.20 | alive: 15.43% (10109/65536 exited)\n",
            "Step 51000 | t =  25.50 | alive: 15.11% (9901/65536 exited)\n",
            "Step 51600 | t =  25.80 | alive: 14.77% (9680/65536 exited)\n",
            "Step 52200 | t =  26.10 | alive: 14.50% (9505/65536 exited)\n",
            "Step 52800 | t =  26.40 | alive: 14.23% (9325/65536 exited)\n",
            "Step 53400 | t =  26.70 | alive: 13.95% (9144/65536 exited)\n",
            "Step 54000 | t =  27.00 | alive: 13.67% (8959/65536 exited)\n",
            "Step 54600 | t =  27.30 | alive: 13.37% (8765/65536 exited)\n",
            "Step 55200 | t =  27.60 | alive: 13.12% (8597/65536 exited)\n",
            "Step 55800 | t =  27.90 | alive: 12.86% (8430/65536 exited)\n",
            "Step 56400 | t =  28.20 | alive: 12.62% (8270/65536 exited)\n",
            "Step 57000 | t =  28.50 | alive: 12.36% (8103/65536 exited)\n",
            "Step 57600 | t =  28.80 | alive: 12.15% (7963/65536 exited)\n",
            "Step 58200 | t =  29.10 | alive: 11.93% (7817/65536 exited)\n",
            "Step 58800 | t =  29.40 | alive: 11.70% (7665/65536 exited)\n",
            "Step 59400 | t =  29.70 | alive: 11.45% (7507/65536 exited)\n",
            "Step 59999 | t =  30.00 | alive: 11.25% (7372/65536 exited)\n",
            "WARNING: 7372/65536 paths did NOT exit by t = 30.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4) Start the Training with Adam"
      ],
      "metadata": {
        "id": "RSYL1T67_73u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop w/ Loss Logging\n",
        "\n",
        "# prep for bestmodel tracking\n",
        "best_loss       = float(\"inf\")\n",
        "adam_model_path = \"best_adam.pth\"\n",
        "best_epoch = 0\n",
        "eval_Xb = sample_uniform_disk(pool_size, R=R) #to evaluate the model\n",
        "eval_xbc = sample_boundary(pool_size//4)\n",
        "\n",
        "total_history = []\n",
        "pde_history   = []\n",
        "data_history  = []\n",
        "bc_history    = []\n",
        "\n",
        "model.train()\n",
        "for ep in range(1, n_epochs+1):\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    Xb = sample_uniform_disk(batch_size)#  [batch_size,2]\n",
        "\n",
        "    # PDE residual + loss\n",
        "    r = pde_residual(model, Xb, theta, sigma, forcing=None)\n",
        "    loss_pde = loss_fn(r)\n",
        "\n",
        "    tau_pred = model(x_data)\n",
        "    loss_data = (tau_pred - tau_data).pow(2).mean()\n",
        "\n",
        "    # sample boundary points and compute BC loss\n",
        "    x_bc = sample_boundary(batch_size)  # use same size as PDE batch for balance\n",
        "    bc_pred = model(x_bc)\n",
        "    loss_bc = (bc_pred ** 2).mean()\n",
        "\n",
        "    loss_total = (\n",
        "        torch.exp(-2 * model.log_sigma_pde) * loss_pde +\n",
        "        torch.exp(-2 * model.log_sigma_data) * loss_data +\n",
        "        torch.exp(-2 * model.log_sigma_bc) * loss_bc +\n",
        "        model.log_sigma_pde +\n",
        "        model.log_sigma_data +\n",
        "        model.log_sigma_bc\n",
        "    )\n",
        "    # 6) backward + step\n",
        "    loss_total.backward()\n",
        "    opt.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    #eval\n",
        "    r_eval        = pde_residual(model, eval_Xb, theta, sigma, forcing = None)  #evaluate the model on the true PDE\n",
        "    bc_eval       = model(eval_xbc)\n",
        "    loss_eval     = loss_fn(r_eval).item() + (bc_eval ** 2).mean().item()\n",
        "\n",
        "    if loss_eval < best_loss or ep - best_epoch >= epochs_between_decay * 10 :\n",
        "        best_loss = loss_eval\n",
        "        torch.save(model.state_dict(), adam_model_path)\n",
        "        best_epoch = ep\n",
        "\n",
        "    # 7) logging & histories\n",
        "    total_history.append(loss_total.item() \\\n",
        "                            - (model.log_sigma_pde.detach()\\\n",
        "                            + model.log_sigma_data.detach()\\\n",
        "                            + model.log_sigma_bc.detach() ).item())\n",
        "    pde_history.append(loss_pde.item())\n",
        "    data_history.append(loss_data.item())\n",
        "    bc_history.append(loss_bc.item())\n",
        "\n",
        "    if ep % 100 == 0:\n",
        "        print(\n",
        "            f\"[ep {ep:4d}/{n_epochs}] \"\n",
        "            f\"loss_pde={loss_pde:.2e}  \"\n",
        "            f\"loss_data={loss_data:.2e}  \"\n",
        "            f\"loss_bc={loss_bc:.2e}  \"\n",
        "        )\n",
        "    if ep % 500 == 0:\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"   epoch {ep:4d},  lr={lr:.2e}\")"
      ],
      "metadata": {
        "id": "wMX05ifLq36Z",
        "collapsed": true,
        "outputId": "c4918368-deb2-4e39-aff3-fe12b69fd7b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ep  100/10000] loss_pde=1.64e+00  loss_data=3.69e+01  loss_bc=2.84e+01  \n",
            "[ep  200/10000] loss_pde=1.83e+00  loss_data=3.61e+01  loss_bc=2.81e+01  \n",
            "[ep  300/10000] loss_pde=2.80e+00  loss_data=3.50e+01  loss_bc=2.74e+01  \n",
            "[ep  400/10000] loss_pde=2.62e+00  loss_data=3.33e+01  loss_bc=2.65e+01  \n",
            "[ep  500/10000] loss_pde=2.49e+00  loss_data=3.15e+01  loss_bc=2.57e+01  \n",
            "   epoch  500,  lr=3.54e-04\n",
            "[ep  600/10000] loss_pde=2.06e+00  loss_data=2.93e+01  loss_bc=2.58e+01  \n",
            "[ep  700/10000] loss_pde=2.02e+00  loss_data=2.78e+01  loss_bc=2.53e+01  \n",
            "[ep  800/10000] loss_pde=3.30e+00  loss_data=2.76e+01  loss_bc=2.35e+01  \n",
            "[ep  900/10000] loss_pde=3.30e+00  loss_data=2.57e+01  loss_bc=2.41e+01  \n",
            "[ep 1000/10000] loss_pde=2.92e+00  loss_data=2.50e+01  loss_bc=2.49e+01  \n",
            "   epoch 1000,  lr=2.51e-04\n",
            "[ep 1100/10000] loss_pde=3.26e+00  loss_data=2.34e+01  loss_bc=2.40e+01  \n",
            "[ep 1200/10000] loss_pde=4.19e+00  loss_data=2.29e+01  loss_bc=2.12e+01  \n",
            "[ep 1300/10000] loss_pde=3.27e+00  loss_data=2.19e+01  loss_bc=2.26e+01  \n",
            "[ep 1400/10000] loss_pde=3.37e+00  loss_data=2.14e+01  loss_bc=2.09e+01  \n",
            "[ep 1500/10000] loss_pde=4.41e+00  loss_data=2.06e+01  loss_bc=2.07e+01  \n",
            "   epoch 1500,  lr=1.77e-04\n",
            "[ep 1600/10000] loss_pde=2.91e+00  loss_data=1.98e+01  loss_bc=2.05e+01  \n",
            "[ep 1700/10000] loss_pde=5.00e+00  loss_data=1.94e+01  loss_bc=2.09e+01  \n",
            "[ep 1800/10000] loss_pde=3.45e+00  loss_data=1.80e+01  loss_bc=2.13e+01  \n",
            "[ep 1900/10000] loss_pde=5.54e+00  loss_data=1.78e+01  loss_bc=1.90e+01  \n",
            "[ep 2000/10000] loss_pde=3.42e+00  loss_data=1.72e+01  loss_bc=1.99e+01  \n",
            "   epoch 2000,  lr=1.26e-04\n",
            "[ep 2100/10000] loss_pde=7.09e+00  loss_data=1.67e+01  loss_bc=1.91e+01  \n",
            "[ep 2200/10000] loss_pde=4.58e+00  loss_data=1.63e+01  loss_bc=1.88e+01  \n",
            "[ep 2300/10000] loss_pde=4.02e+00  loss_data=1.59e+01  loss_bc=1.82e+01  \n",
            "[ep 2400/10000] loss_pde=3.81e+00  loss_data=1.53e+01  loss_bc=1.77e+01  \n",
            "[ep 2500/10000] loss_pde=4.60e+00  loss_data=1.50e+01  loss_bc=1.79e+01  \n",
            "   epoch 2500,  lr=8.89e-05\n",
            "[ep 2600/10000] loss_pde=4.84e+00  loss_data=1.46e+01  loss_bc=1.79e+01  \n",
            "[ep 2700/10000] loss_pde=5.52e+00  loss_data=1.43e+01  loss_bc=1.65e+01  \n",
            "[ep 2800/10000] loss_pde=3.48e+00  loss_data=1.40e+01  loss_bc=1.85e+01  \n",
            "[ep 2900/10000] loss_pde=4.21e+00  loss_data=1.37e+01  loss_bc=1.67e+01  \n",
            "[ep 3000/10000] loss_pde=4.71e+00  loss_data=1.33e+01  loss_bc=1.66e+01  \n",
            "   epoch 3000,  lr=6.29e-05\n",
            "[ep 3100/10000] loss_pde=6.34e+00  loss_data=1.30e+01  loss_bc=1.63e+01  \n",
            "[ep 3200/10000] loss_pde=4.65e+00  loss_data=1.28e+01  loss_bc=1.65e+01  \n",
            "[ep 3300/10000] loss_pde=6.24e+00  loss_data=1.25e+01  loss_bc=1.51e+01  \n",
            "[ep 3400/10000] loss_pde=5.27e+00  loss_data=1.22e+01  loss_bc=1.71e+01  \n",
            "[ep 3500/10000] loss_pde=3.70e+00  loss_data=1.21e+01  loss_bc=1.67e+01  \n",
            "   epoch 3500,  lr=4.46e-05\n",
            "[ep 3600/10000] loss_pde=4.76e+00  loss_data=1.20e+01  loss_bc=1.59e+01  \n",
            "[ep 3700/10000] loss_pde=4.26e+00  loss_data=1.18e+01  loss_bc=1.55e+01  \n",
            "[ep 3800/10000] loss_pde=5.45e+00  loss_data=1.17e+01  loss_bc=1.60e+01  \n",
            "[ep 3900/10000] loss_pde=5.94e+00  loss_data=1.17e+01  loss_bc=1.48e+01  \n",
            "[ep 4000/10000] loss_pde=4.71e+00  loss_data=1.16e+01  loss_bc=1.53e+01  \n",
            "   epoch 4000,  lr=3.15e-05\n",
            "[ep 4100/10000] loss_pde=6.53e+00  loss_data=1.15e+01  loss_bc=1.41e+01  \n",
            "[ep 4200/10000] loss_pde=4.94e+00  loss_data=1.12e+01  loss_bc=1.57e+01  \n",
            "[ep 4300/10000] loss_pde=4.72e+00  loss_data=1.12e+01  loss_bc=1.55e+01  \n",
            "[ep 4400/10000] loss_pde=4.36e+00  loss_data=1.12e+01  loss_bc=1.48e+01  \n",
            "[ep 4500/10000] loss_pde=6.43e+00  loss_data=1.10e+01  loss_bc=1.46e+01  \n",
            "   epoch 4500,  lr=2.23e-05\n",
            "[ep 4600/10000] loss_pde=5.60e+00  loss_data=1.09e+01  loss_bc=1.49e+01  \n",
            "[ep 4700/10000] loss_pde=4.13e+00  loss_data=1.09e+01  loss_bc=1.42e+01  \n",
            "[ep 4800/10000] loss_pde=4.77e+00  loss_data=1.09e+01  loss_bc=1.46e+01  \n",
            "[ep 4900/10000] loss_pde=6.30e+00  loss_data=1.08e+01  loss_bc=1.54e+01  \n",
            "[ep 5000/10000] loss_pde=7.26e+00  loss_data=1.07e+01  loss_bc=1.43e+01  \n",
            "   epoch 5000,  lr=1.58e-05\n",
            "[ep 5100/10000] loss_pde=4.73e+00  loss_data=1.06e+01  loss_bc=1.46e+01  \n",
            "[ep 5200/10000] loss_pde=6.33e+00  loss_data=1.06e+01  loss_bc=1.49e+01  \n",
            "[ep 5300/10000] loss_pde=6.11e+00  loss_data=1.04e+01  loss_bc=1.52e+01  \n",
            "[ep 5400/10000] loss_pde=6.45e+00  loss_data=1.06e+01  loss_bc=1.54e+01  \n",
            "[ep 5500/10000] loss_pde=4.83e+00  loss_data=1.05e+01  loss_bc=1.50e+01  \n",
            "   epoch 5500,  lr=1.12e-05\n",
            "[ep 5600/10000] loss_pde=6.05e+00  loss_data=1.05e+01  loss_bc=1.61e+01  \n",
            "[ep 5700/10000] loss_pde=6.27e+00  loss_data=1.04e+01  loss_bc=1.39e+01  \n",
            "[ep 5800/10000] loss_pde=4.83e+00  loss_data=1.03e+01  loss_bc=1.40e+01  \n",
            "[ep 5900/10000] loss_pde=4.39e+00  loss_data=1.03e+01  loss_bc=1.45e+01  \n",
            "[ep 6000/10000] loss_pde=6.60e+00  loss_data=1.03e+01  loss_bc=1.45e+01  \n",
            "   epoch 6000,  lr=7.92e-06\n",
            "[ep 6100/10000] loss_pde=5.93e+00  loss_data=1.02e+01  loss_bc=1.44e+01  \n",
            "[ep 6200/10000] loss_pde=4.96e+00  loss_data=1.02e+01  loss_bc=1.35e+01  \n",
            "[ep 6300/10000] loss_pde=6.42e+00  loss_data=1.02e+01  loss_bc=1.34e+01  \n",
            "[ep 6400/10000] loss_pde=6.59e+00  loss_data=1.02e+01  loss_bc=1.42e+01  \n",
            "[ep 6500/10000] loss_pde=7.80e+00  loss_data=1.02e+01  loss_bc=1.31e+01  \n",
            "   epoch 6500,  lr=5.61e-06\n",
            "[ep 6600/10000] loss_pde=4.55e+00  loss_data=1.01e+01  loss_bc=1.42e+01  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.5) L-BFGS Fine-Tuning"
      ],
      "metadata": {
        "id": "MYTAjR_mAHHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LBFGS fine-tuning\n",
        "\n",
        "# Reload best Adam snapshot\n",
        "print(f\"\\nLoading best Adam model (loss={best_loss:.2e}, epoch={best_epoch}) \")\n",
        "model.load_state_dict(torch.load(adam_model_path))\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# define L-BFGS parameters\n",
        "lbfgs = torch.optim.LBFGS(\n",
        "    model.parameters(),\n",
        "    lr=1.0,\n",
        "    max_iter=n_epochs//2,\n",
        "    history_size=1000,\n",
        "    tolerance_grad=1e-9,\n",
        "    tolerance_change=1e-9,\n",
        "    line_search_fn=\"strong_wolfe\"\n",
        ")\n",
        "\n",
        "max_eval = lbfgs.defaults.get('max_eval')\n",
        "\n",
        "# freeze one big PDE batch for the closure\n",
        "Xb_ft = sample_uniform_disk(pool_size, R=R)\n",
        "x_bc_ft = sample_boundary(pool_size//4)\n",
        "\n",
        "lbfgs_total = []\n",
        "lbfgs_pde   = []\n",
        "lbfgs_data  = []\n",
        "lbfgs_bc    = []\n",
        "\n",
        "#closure function\n",
        "def closure():\n",
        "    closure.calls += 1\n",
        "    lbfgs.zero_grad()\n",
        "    # PDE term\n",
        "    r_ft    = pde_residual(model, Xb_ft, theta, sigma, forcing = None)\n",
        "    pde_l   = loss_fn(r_ft)\n",
        "\n",
        "    # data term\n",
        "    tau_p   = model(x_data).squeeze(-1)\n",
        "    data_l  = (tau_p - tau_data).pow(2).mean()\n",
        "\n",
        "    # sample boundary points and compute BC loss\n",
        "    bc_pred = model(x_bc_ft)\n",
        "    bc_l    = (bc_pred ** 2).mean()\n",
        "\n",
        "    total_l = (torch.exp(-2 * model.log_sigma_pde) * pde_l\n",
        "            + torch.exp(-2 * model.log_sigma_data) * data_l\n",
        "            + torch.exp(-2 * model.log_sigma_bc)   * bc_l\n",
        "            + model.log_sigma_pde\n",
        "            + model.log_sigma_data\n",
        "            + model.log_sigma_bc\n",
        "    )\n",
        "    # record\n",
        "    lbfgs_total.append(total_l.item() - \\\n",
        "            (model.log_sigma_pde.detach()\n",
        "            + model.log_sigma_data.detach()\n",
        "            + model.log_sigma_bc.detach()).item())\n",
        "    lbfgs_pde.append(pde_l.item())\n",
        "    lbfgs_data.append(data_l.item())\n",
        "    lbfgs_bc.append(bc_l.item())\n",
        "\n",
        "    total_l.backward()\n",
        "\n",
        "    PRINT_EVERY = 100\n",
        "    if closure.calls % PRINT_EVERY == 0:\n",
        "        print(\n",
        "            f\"eval {closure.calls}/{max_eval} | \"\n",
        "            f\"loss pde {pde_l:.2e} | \"\n",
        "            f\"loss boundary {bc_l:.2e} | \"\n",
        "            f\"loss data {data_l:.2e}\"\n",
        "        )\n",
        "    return total_l\n",
        "\n",
        "closure.calls = 0"
      ],
      "metadata": {
        "id": "6Xu_iuYS2b2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# report losses before/after lbfgs\n",
        "# make sure model is in eval mode so e.g. Dropout/BatchNorm wont move\n",
        "model.eval()\n",
        "\n",
        "# PDE loss\n",
        "r_before = pde_residual(model, Xb_ft, theta, sigma, forcing = None)\n",
        "before_pde = loss_fn(r_before).item()\n",
        "\n",
        "# empirical Sobolev norm\n",
        "#before_h2 = empirical_h2_norm(model, Xb_ft).item()\n",
        "\n",
        "# data loss (doesn't need grads)\n",
        "with torch.no_grad():\n",
        "    tau_p       = model(x_data).squeeze(-1)\n",
        "    before_data = (tau_p - tau_data).pow(2).mean()\n",
        "\n",
        "#boundary condition loss\n",
        "before_bc_pred = model(x_bc_ft)\n",
        "before_bc  = (before_bc_pred ** 2).mean()\n",
        "\n",
        "\n",
        "print(f\"Before L-BFGS  PDE {before_pde:.3e}, DATA {before_data:.3e}, BC: {before_bc:.3e}\")#, SOBOLEV {before_h2:.2e})\n",
        "\n",
        "# running LBFGS\n",
        "print(\" Running L-BFGS...\")\n",
        "loss_after = lbfgs.step(closure)\n",
        "print(f\"L-BFGS did {closure.calls} closure calls, final total loss = {loss_after:.2e}\")"
      ],
      "metadata": {
        "id": "Tq8eGZNl31KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after L-BFGS, same pattern:\n",
        "model.eval()\n",
        "r_after = pde_residual(model, Xb_ft, theta, sigma, forcing = None)\n",
        "after_pde = loss_fn(r_after).item()\n",
        "#after_h2 = empirical_h2_norm(model, Xb_ft).item()\n",
        "with torch.no_grad():\n",
        "    tau_p       = model(x_data).squeeze(-1)\n",
        "    after_data = (tau_p - tau_data).pow(2).mean()\n",
        "after_bc_pred = model(x_bc_ft)\n",
        "after_bc  = (after_bc_pred ** 2).mean()\n",
        "print(f\" After L-BFGS  PDE {after_pde:.2e}, DATA {after_data:.2e}, BC: {after_bc:.2e}\")#, SOBOLEV {after_h2:.2e}\"\n",
        "\n",
        "# saving the L-BFGS fine-tuned model\n",
        "lbfgs_model_path = 'lbfgs_finetuned.pth'\n",
        "torch.save(model.state_dict(), lbfgs_model_path)"
      ],
      "metadata": {
        "id": "e2Jm9VR6q3Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Plotting the results"
      ],
      "metadata": {
        "id": "CpHta0VwANgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1) Training curves"
      ],
      "metadata": {
        "id": "ShkQeYZSAQVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting three separate loss evolutions\n",
        "n = min(n_epochs, len(total_history))\n",
        "total_history = total_history + lbfgs_total\n",
        "pde_history   = pde_history   + lbfgs_pde\n",
        "data_history  = data_history  + lbfgs_data\n",
        "bc_history    = bc_history    + lbfgs_bc\n",
        "\n",
        "\n",
        "# a) Total Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n), total_history[:n], \\\n",
        "             color = 'blue', label = \"ADAM\")\n",
        "plt.semilogy(np.arange(n, len(total_history)), total_history[n:], \\\n",
        "             color = 'green', label = \"L-BFGS\")\n",
        "plt.title(\"Total Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step (Adam epochs or L-BFGS iter)\")\n",
        "plt.ylabel(\"loss_total\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "# b) PDE Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n), pde_history[:n], \\\n",
        "             color = 'blue', label = \"ADAM\")\n",
        "plt.semilogy(np.arange(n, len(pde_history)), pde_history[n:], \\\n",
        "             color = 'green', label = \"L-BFGS\")\n",
        "plt.title(\"PDE Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss_pde\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "# c) Data Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n), data_history[:n], \\\n",
        "             color = 'blue', label = \"ADAM\")\n",
        "plt.semilogy(np.arange(n, len(data_history)), data_history[n:], \\\n",
        "             color = 'green', label = \"L-BFGS\")\n",
        "plt.title(\"Data Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss_data\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "# d) BC Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n), bc_history[:n], \\\n",
        "             color = 'blue', label = \"ADAM\")\n",
        "plt.semilogy(np.arange(n, len(bc_history)), bc_history[n:], \\\n",
        "             color = 'green', label = \"L-BFGS\")\n",
        "plt.title(\"BC Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss_bc\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "\n",
        "plt.show()\n",
        "# # c) Data Loss with homotopy\n",
        "# plt.figure(figsize=(6,4))\n",
        "# plt.semilogy(np.arange(n_hom), data_history[:n_hom], \\\n",
        "#              color = 'blue', label = \"ADAM with homotopy\")\n",
        "# plt.semilogy(np.arange(n_hom, n_epochs), data_history[n_hom: n_epochs], \\\n",
        "#              color = 'orange', label = \"Adam on true PDE\")\n",
        "# plt.semilogy(np.arange(n_epochs, len(pde_history)), data_history[n_epochs:], \\\n",
        "#              color = 'green', label = \"L-BFGS on true PDE\")\n",
        "# plt.title(\"Data Loss vs Epoch / L-BFGS step\")\n",
        "# plt.xlabel(\"step\")\n",
        "# plt.ylabel(\"loss_data\")\n",
        "# plt.legend()\n",
        "# plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "QC2cFlG3q6mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2) Learned Solution vs True Solution"
      ],
      "metadata": {
        "id": "dqHCGWxwAW-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#choose to load the model fine-tuned with lbfgs or just the one trained with adam\n",
        "load_fine_tuned = True #set to False for Adam-only model\n",
        "model = SimplePINN(power, width, depth)\n",
        "\n",
        "if load_fine_tuned:\n",
        "    model.load_state_dict(torch.load(lbfgs_model_path))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(adam_model_path))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "T3yVFuE1rCRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Visualize PINN vs True tau\n",
        "\n",
        "n_pts = 200\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(-R,R,n_pts),\n",
        "    np.linspace(-R,R,n_pts)\n",
        ")\n",
        "mask = xx**2 + yy**2 <= R**2\n",
        "pts = np.vstack([xx[mask], yy[mask]]).T\n",
        "\n",
        "with torch.no_grad():\n",
        "    inp = torch.from_numpy(pts).to(device)\n",
        "    pred = model(inp).cpu().numpy()#.squeeze(-1)\n",
        "\n",
        "Zp = np.zeros_like(xx); Zt = np.zeros_like(xx)\n",
        "Zp[mask], Zt[mask] = pred, true_tau_vec(xx[mask], yy[mask])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
        "cf1 = ax1.contourf(xx, yy, Zp, levels=50, cmap='viridis')\n",
        "ax1.set_title('PINN tau')\n",
        "fig.colorbar(cf1, ax=ax1, shrink=0.8)\n",
        "\n",
        "cf2 = ax2.contourf(xx, yy, Zt, levels=50, cmap='viridis')\n",
        "ax2.set_title('True tau')\n",
        "fig.colorbar(cf2, ax=ax2, shrink=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mICNQZu_q96H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3) Relative and Pointwise error"
      ],
      "metadata": {
        "id": "37SwVkTGAcBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pointwise L1 error\n",
        "Z_err = np.abs(Zp - Zt)\n",
        "plt.figure(figsize=(6,5))\n",
        "cf = plt.contourf(xx, yy, Z_err, levels=50, cmap='RdBu_r')\n",
        "plt.colorbar(cf, label=r'$|\\tau_{PINN}-\\tau|$')\n",
        "plt.title('Pointwise absoluteerror Field')\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GZSdlI0pyicy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average relative L2 error\n",
        "#    tau_pinn  tau_true / tau_true   (empirical L() norm)\n",
        "pred_vals = pred\n",
        "true_vals = true_tau_vec(pts[:,0], pts[:,1])\n",
        "\n",
        "# Empirical L norm of true solution: ( (1/n)  _true )\n",
        "tau_l2_norm = np.sqrt(np.mean(true_vals**2))\n",
        "glob_rel_L2 = np.sqrt(np.mean((pred_vals - true_vals)**2)) / tau_l2_norm\n",
        "print(f\"Global relative L2 error: {glob_rel_L2:.3e} (true solution L2 norm: {tau_l2_norm:.3e})\")\n",
        "\n",
        "# average relative L1 error\n",
        "#     tau_pinn  tau_true_1 / tau_true_1   (empirical L() norm)\n",
        "tau_l1_norm = np.mean(np.abs(true_vals))\n",
        "glob_rel_L1 = np.mean(np.abs(pred_vals - true_vals)) / tau_l1_norm\n",
        "print(f\"Global relative L1 error: {glob_rel_L1:.3e} (true solution L1 norm: {tau_l1_norm:.3e})\")\n",
        "\n",
        "# Sobolev H1 and H2 errors (finite diff on full grid)\n",
        "h = (2 * R) / (n_pts - 1)\n",
        "Z_err = Zp - Zt\n",
        "derr_dy, derr_dx = np.gradient(Z_err, h, h)\n",
        "grad_err_sq = derr_dx[mask]**2 + derr_dy[mask]**2\n",
        "d2err_dx2 = np.gradient(derr_dx, h, axis=1)\n",
        "d2err_dy2 = np.gradient(derr_dy, h, axis=0)\n",
        "d2err_dxdy = np.gradient(derr_dy, h, axis=1)\n",
        "hess_err_sq = d2err_dx2[mask]**2 + d2err_dy2[mask]**2 + 2 * d2err_dxdy[mask]**2\n",
        "\n",
        "# True solution norms\n",
        "dt_dy, dt_dx = np.gradient(Zt, h, h)\n",
        "grad_t_sq = dt_dx[mask]**2 + dt_dy[mask]**2\n",
        "d2t_dx2 = np.gradient(dt_dx, h, axis=1)\n",
        "d2t_dy2 = np.gradient(dt_dy, h, axis=0)\n",
        "d2t_dxdy = np.gradient(dt_dy, h, axis=1)\n",
        "hess_t_sq = d2t_dx2[mask]**2 + d2t_dy2[mask]**2 + 2 * d2t_dxdy[mask]**2\n",
        "\n",
        "tau_h1_norm = np.sqrt(np.mean(Zt[mask]**2 + grad_t_sq))\n",
        "tau_h2_norm = np.sqrt(np.mean(Zt[mask]**2 + grad_t_sq + hess_t_sq))\n",
        "glob_rel_H1 = np.sqrt(np.mean(Z_err[mask]**2 + grad_err_sq)) / tau_h1_norm\n",
        "glob_rel_H2 = np.sqrt(np.mean(Z_err[mask]**2 + grad_err_sq + hess_err_sq)) / tau_h2_norm\n",
        "print(f\"Global relative H1 error: {glob_rel_H1:.3e} (true solution H1 norm: {tau_h1_norm:.3e})\")\n",
        "print(f\"Global relative H2 error: {glob_rel_H2:.3e} (true solution H2 norm: {tau_h2_norm:.3e})\")\n",
        "\n",
        "print(f\"Final PDE loss: {after_pde:.3e}\")\n",
        "print(f\"Final boundary loss: {after_bc:.3e}\")\n",
        "print(f\"Final data loss: {after_data:.3e}\")"
      ],
      "metadata": {
        "id": "tGYTnvqCijJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aMD27GvIsAB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('pde_history_simple.npy', np.array(pde_history))\n",
        "np.save('data_history_simple.npy', np.array(data_history))"
      ],
      "metadata": {
        "id": "ERtgM3KXsAeK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}