{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ReLU\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#radius of the ball\n",
    "radius = 2\n",
    "\n",
    "#parameters of the OU process\n",
    "theta = 1\n",
    "sigma = 0.5\n",
    "lambda_ = theta/sigma**2\n",
    "\n",
    "#definition of the true solution for comparison\n",
    "\n",
    "def true_solution(x, y, theta=theta, lambda_=lambda_):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    integral, _ = integrate.quad(lambda t : np.exp(lambda_ * t**2) * special.gammainc(1, lambda_ * t**2) / t, rho, radius)\n",
    "    return integral/theta\n",
    "\n",
    "#make the true_solution compatible with numpy arrays\n",
    "true_solution_vectorized = np.vectorize(true_solution)\n",
    "\n",
    "#plotting the function (inspiration taken from https://stackoverflow.com/questions/27606079)\n",
    "n_points = 400\n",
    "tt = np.linspace(-1, 1, n_points) * radius\n",
    "xx, yy = np.meshgrid(tt, tt)  # create unit square grid\n",
    "\n",
    "xx, yy = np.where(xx**2 + yy**2 <= radius**2, xx, 0), np.where(xx**2 + yy**2 <= radius**2 , yy, 0) #(https://stackoverflow.com/questions/15733530/)\n",
    "zz = true_solution_vectorized(xx,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#circle\n",
    "a = np.linspace(0, 2*np.pi, 50)\n",
    "cx,cy = np.cos(a) * radius , np.sin(a)*radius\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cx, cy,'k-', alpha=.2)\n",
    "\n",
    "contour = ax.contourf(xx, yy, zz, levels=50)  # 50 contour levels\n",
    "cb = fig.colorbar(contour, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the true solution blows up extremely fast away from the boundary, and is thus likely to be hard to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define ReLU^k activation\n",
    "\n",
    "class RePU(nn.Module):\n",
    "\n",
    "    def __init__(self, power = 2):\n",
    "        super(RePU, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.pow(torch.relu(x), self.power)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "iter = 0\n",
    "width = 1000\n",
    "losses = []\n",
    "\n",
    "class StandardPINN(nn.Module):\n",
    "\n",
    "    def __init__(self, power = 2, width = width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(torch.nn.Linear(2, width),\n",
    "                                          RePU(power),\n",
    "                                          torch.nn.Linear(width, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def derivative(dy: torch.Tensor, x: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function calculates the derivative of the model at x_f\n",
    "    \"\"\"\n",
    "    for i in range(order):\n",
    "        dy = torch.autograd.grad(\n",
    "            dy, x, grad_outputs = torch.ones_like(dy), create_graph=True, retain_graph=True\n",
    "        )[0]\n",
    "    return dy\n",
    "\n",
    "def u_function(model: StandardPINN, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function evaluates the model on the input x\n",
    "    \"\"\"\n",
    "    model_input = torch.stack((x, y), axis = 1)\n",
    "    return model(model_input)\n",
    "\n",
    "\n",
    "def residual(model, x_f, y_f):\n",
    "    u = u_function(model, x_f, y_f)\n",
    "    u_x = derivative(u, x_f, order=1)\n",
    "    u_y = derivative(u, y_f, order=1)\n",
    "    u_xx = derivative(u, x_f, order=2)\n",
    "    u_yy = derivative(u, y_f, order=2)\n",
    "    res = - theta * (x_f * u_x + y_f * u_y) \\\n",
    "        + sigma**2 * (u_xx + u_yy)/2 \\\n",
    "        + 1\n",
    "    return res\n",
    "\n",
    "def loss_function(model: StandardPINN, x_c: torch.Tensor, y_c: torch.Tensor, x_b: torch.Tensor, y_b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function evaluates the physics governing the model on the input x_f\n",
    "    \"\"\"\n",
    "    domain_residual = residual(model, x_c, y_c).pow(2).mean() #residual\n",
    "    boundary_residual = (u_function(model, x_b, y_b)).pow(2).mean() #boundary\n",
    "    return domain_residual + boundary_residual\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "def closure(model: StandardPINN, optimizer, X_c_train: torch.Tensor, X_b_train:torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In order to use the LBFGS optimizer, we need to define a closure function. This function is called by the optimizer\n",
    "    and the optimizer contains the inner loop for the optimization and it continues until the tolerance is met.\n",
    "    \"\"\"\n",
    "    x_c = X_c_train[:, 0]\n",
    "    y_c = X_c_train[:, 1]\n",
    "    x_b = X_b_train[:, 0]\n",
    "    y_b = X_b_train[:, 1]\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_function(model, x_c, y_c, x_b, y_b)\n",
    "    loss.backward()\n",
    "    global iter\n",
    "    iter += 1\n",
    "    print(f\" iteration: {iter}  loss: {loss.item()}\")\n",
    "    losses.append(loss.item())\n",
    "    return loss\n",
    "\n",
    "def train(model, X_c_train, X_b_train):\n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(),\n",
    "                                    lr=1,\n",
    "                                    #max_iter=50000,\n",
    "                                    #max_eval=50000,\n",
    "                                    #history_size=50,\n",
    "                                    tolerance_grad=0,\n",
    "                                    #tolerance_change=0.5 * np.finfo(float).eps,\n",
    "                                    line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "    # the optimizer.step requires the closure function to be a callable function without inputs\n",
    "    # therefore we need to define a partial function and pass it to the optimizer\n",
    "    closure_fn = partial(closure, model, optimizer, X_c_train, X_b_train)\n",
    "    optimizer.step(closure_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "radius = 2 #radius of the circle\n",
    "theta = 1\n",
    "sigma = 0.5 #parameters of the OU process\n",
    "\n",
    "N_c = 250 #number of points in the domain\n",
    "N_b = 2 * N_c #number of points on the boundary\n",
    "\n",
    "#definition of X_b_train : N_b points on the boundary\n",
    "t = np.linspace(0, 2*np.pi, N_b, endpoint=False)\n",
    "x_b = radius * np.cos(t)\n",
    "y_b = radius * np.sin(t)\n",
    "X_b_train = np.vstack( (x_b, y_b) )\n",
    "\n",
    "#shuffling X_b_train\n",
    "index = np.arange(0, N_b)\n",
    "np.random.shuffle(index)\n",
    "X_b_train = X_b_train[:, index]\n",
    "\n",
    "#definition of X_c_train : N_c points in the disk\n",
    "t = np.random.uniform(0,2*np.pi, N_c)\n",
    "rho = np.random.uniform(0,radius, N_c) ** 0.5 #uniform distribution on the disk\n",
    "x_c = rho * np.cos(t)\n",
    "y_c = rho * np.sin(t)\n",
    "X_c_train = np.vstack( (x_c, y_c) )\n",
    "\n",
    "#shuffling X_c_train\n",
    "index = np.arange(0, N_c)\n",
    "np.random.shuffle(index)\n",
    "X_c_train = X_c_train[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#model instantiation\n",
    "model = StandardPINN()\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Training\n",
    "losses = []\n",
    "X_b_train = torch.from_numpy(X_b_train).requires_grad_(True).float()\n",
    "X_c_train = torch.from_numpy(X_c_train).requires_grad_(True).float()\n",
    "\n",
    "model.train()\n",
    "train(model, X_c_train, X_b_train)\n",
    "plt.plot(losses, label='Training Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'standard_pinn_LBFGS.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = StandardPINN()\n",
    "model.load_state_dict(\\\n",
    "torch.load('/content/drive/MyDrive/Colab Notebooks/Mean_Escape_Time/models/OU_process/model_standard_pinn_LBFGS.pt'))\n",
    "\n",
    "#evaluate the model on a uniform grid\n",
    "n_points = 40\n",
    "tt = np.linspace(-1, 1, n_points) * radius\n",
    "xx, yy = np.meshgrid(tt, tt)  # create unit square grid\n",
    "xx, yy = np.where(xx**2 + yy**2 <= radius**2, xx, 0), np.where(xx**2 + yy**2 <= radius**2 , yy, 0) #(https://stackoverflow.com/questions/15733530/)\n",
    "zz_true = true_solution_vectorized(xx,yy)\n",
    "\n",
    "input = torch.from_numpy(np.vstack((xx.ravel(),yy.ravel())).T).float()#.requires_grad_(False)\n",
    "learned_sol = model(input)\n",
    "\n",
    "#plot\n",
    "learned_sol_np = learned_sol.detach().numpy().reshape(xx.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cx, cy,'k-', alpha=.2)\n",
    "\n",
    "contour = ax.contourf(xx, yy, learned_sol_np, levels=500)  # 50 contour levels\n",
    "cb = fig.colorbar(contour, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
