{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuHHG86H96VlcMJdt9AM9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StratosFair/Mean_Escape_Time/blob/main/Double_Well_2D/Models%20/adapted_pinn_medium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & FP64\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.integrate as integrate\n",
        "import scipy.special as special\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_default_dtype(torch.float64)"
      ],
      "metadata": {
        "id": "zWfcku6GqTt1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving for the MET of an Ornstein-Uhlenbeck process in a disk with \"Adapted Architecture PINNs\" : comparison with exact solution"
      ],
      "metadata": {
        "id": "wDHeduNpyl5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup\n",
        "\n",
        "For $\\theta,\\sigma,r >0$ some fixed parameters, we let $\\Omega := B_r \\equiv \\{x\\in\\mathbb R^d : \\|x\\|< r \\}$, and define the process ($d=2$ in our illustration) :\n",
        "\n",
        "$$\\begin{cases} dX_t &= -\\theta X_t dt + \\sigma dB_t \\\\\n",
        "X_0 &= x \\in \\Omega \\end{cases} $$\n",
        "\n",
        "For all $x\\in\\Omega$, let\n",
        "\n",
        "$$T(x) := \\inf\\{t\\ge 0 : X_t \\in\\partial\\Omega\\} $$\n",
        "\n",
        "and let its first moment be denoted\n",
        "\n",
        "$$\\tau(x) := \\mathbb E[T(x)] $$\n",
        "\n",
        "We can show under some regularity conditions on $\\Omega$ that $\\tau$ is the (unique) solution of the BVP :\n",
        "\n",
        "$$\\begin{cases} -\\mathcal{L}u(x) &= 1 \\text{ for all } x\\in\\Omega \\\\\n",
        "u(x) &= 0 \\text{ for all } x\\in\\partial\\Omega \\end{cases} $$\n",
        "\n",
        "where $\\mathcal L$ is the infinitesimal generator of the Ornstein-Uhlenbeck process, given by\n",
        "$$\\mathcal Lu : x \\mapsto -\\theta x \\cdot \\nabla u(x) + \\frac{\\sigma^2}{2}\\Delta u(x) $$"
      ],
      "metadata": {
        "id": "EpGLkz71ym36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nicely enough, for this problem, we can compare our solution with the known closed-form solution (see https://arxiv.org/abs/2208.04029) :\n",
        "\n",
        "$$ \\tau(x) := \\frac{1}{\\lambda^{d/2}\\sigma^2}\\int_\\rho^r z^{1-d} e^{\\lambda z^2} \\gamma(d/2, \\lambda z^2)\\ dz $$\n",
        "\n",
        "where $\\lambda := \\theta/\\sigma^2 $, $\\rho := \\|x\\| $ and $\\gamma$ is the upper incomplete gamma function :\n",
        "$$\\gamma(n,y) := \\int_0^y t^{n-1} e^{-t}\\ dt.  $$"
      ],
      "metadata": {
        "id": "ah5DvZTq7uP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem Parameters & True Solution\n",
        "R = 2.0\n",
        "theta = 1.0\n",
        "sigma = 1.0\n",
        "\n",
        "def true_tau(x, y, theta=theta, sigma=sigma, R=R):\n",
        "    lam = theta / sigma**2\n",
        "    rho = np.sqrt(x**2 + y**2)\n",
        "    integrand = lambda t: np.exp(lam * t**2) * special.gammainc(1, lam * t**2) / t\n",
        "    I, _ = integrate.quad(integrand, rho, R)\n",
        "    return I / theta\n",
        "\n",
        "true_tau_vec = np.vectorize(true_tau)"
      ],
      "metadata": {
        "id": "1lyRR4sIqUbT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Neural Network architecture and loss function\n",
        "\n",
        "Unlike the standard PINN, we will take an hypothesis space of Neural Networks which satisfy the boundary conditions explicitly. For this problem, we have homogenous zero Dirichlet boundary conditions, which we can enforce by multiplying our Neural Networks with an appropriate \"smooth distance approximation\" (see https://arxiv.org/abs/2104.08426). In accordance with the mentioned paper, we will take\n",
        "$$\\varphi : x\\mapsto \\frac{r^2 - \\|x\\|^2}{2r}$$\n",
        "as our smooth distance approximation.  \n",
        "\n",
        "\n",
        "With this modification, our objective to minimize becomes\n",
        "$$\\hat u := \\arg\\min_{u\\in\\mathcal{NN}_\\varphi}\\ \\frac1n \\sum_{i=1}^n (\\mathcal L u(x_i^c) + 1)^2 $$\n",
        "where $x_i^c$ are sampled i.i.d. with uniform distribution on $\\Omega$,\n",
        "$$\\mathcal{NN}_\\varphi:=\\left\\{x\\mapsto \\varphi(x) \\cdot T_L\\circ \\sigma \\circ T_{L-1}\\circ\\cdots\\circ \\sigma\\circ T_1 (x)\\right\\}, $$\n",
        "for\n",
        "$$T_\\ell : \\mathbb{R}^{\\ell-1}\\to\\mathbb{R}^\\ell $$\n",
        "affine-linear maps of appropriate input-output dimensions, where\n",
        "$$\\sigma :x \\mapsto \\begin{cases}x^2 &\\text{ if } x\\ge 0\\\\ 0 &\\text{ if } x\\le 0\\end{cases} \\quad \\text{OR }\\ \\ \\sigma : x\\mapsto \\operatorname{tanh}(x),$$\n",
        "is either the ReQU or hyperbolic tangent activation function, which is understood element-wise when applied to vectors."
      ],
      "metadata": {
        "id": "ipb5U7KL7yL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining PINN w/ matching boundary condition\n",
        "power = 2 #exponent k for relu^k, none for tanh\n",
        "width = 50\n",
        "depth = 3\n",
        "gain = 1.0 #magnitude of weights at initialization\n",
        "\n",
        "#define ReLU^k activation\n",
        "\n",
        "class RePU(nn.Module):\n",
        "    def __init__(self, power = power):\n",
        "        super(RePU, self).__init__()\n",
        "        self.power = power\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.pow(torch.relu(x), self.power)\n",
        "\n",
        "#define the smooth distance approximation\n",
        "def smooth_distance(x):\n",
        "    norm_x = torch.linalg.norm(x, dim=-1)\n",
        "    return (R**2 - norm_x**2)/(2*R)\n",
        "\n",
        "#define hypothesis space\n",
        "class BoundaryPINN(nn.Module):\n",
        "    def __init__(self, power = power, width = width, depth = depth):\n",
        "        super(BoundaryPINN,self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(2, width))\n",
        "        if isinstance(power, int):\n",
        "            self.layers.append(RePU(power))\n",
        "            for _ in range(depth-1) :\n",
        "                self.layers.append(nn.Linear(width, width))\n",
        "                self.layers.append(RePU(power))\n",
        "        else :\n",
        "            self.layers.append(nn.Tanh())\n",
        "            for _ in range(depth-1) :\n",
        "                self.layers.append(nn.Linear(width, width))\n",
        "                self.layers.append(nn.Tanh())\n",
        "        self.layers.append(nn.Linear(width, 1))\n",
        "\n",
        "        #for dynamic weighting, first biased towards data fidelity\n",
        "        self.log_sigma_pde = nn.Parameter(torch.tensor(0.0))\n",
        "        self.log_sigma_data = nn.Parameter(torch.tensor(-np.log(2),\\\n",
        "                                                        dtype=torch.float64))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x\n",
        "        for layer in self.layers:\n",
        "            output = layer(output)\n",
        "        distance =  smooth_distance(x)\n",
        "        return output * distance.unsqueeze(-1)\n",
        "\n",
        "#weight initialization\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(m.weight, gain=gain)\n",
        "        m.bias.data.fill_(gain)"
      ],
      "metadata": {
        "id": "kNAMxUlRqa3D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining PDE Residual & Loss, enabling grad on x\n",
        "def pde_residual(model, x, theta, sigma, forcing = None):\n",
        "    # ensure x is on the right device, float64, and requires grad\n",
        "    x = x.clone().detach().to(device).requires_grad_(True)\n",
        "\n",
        "    # forward through PINN\n",
        "    tau = model(x)                                # [N]\n",
        "    # first derivatives\n",
        "    grads = torch.autograd.grad(\n",
        "        tau, x,\n",
        "        grad_outputs=torch.ones_like(tau),\n",
        "        create_graph=True,\n",
        "    )[0]                                        # [N,2]\n",
        "    tau_x, tau_y = grads[:,0], grads[:,1]\n",
        "\n",
        "    # second derivatives\n",
        "    tau_xx = torch.autograd.grad(\n",
        "        tau_x, x,\n",
        "        grad_outputs=torch.ones_like(tau_x),\n",
        "        create_graph=True\n",
        "    )[0][:,0]\n",
        "    tau_yy = torch.autograd.grad(\n",
        "        tau_y, x,\n",
        "        grad_outputs=torch.ones_like(tau_y),\n",
        "        create_graph=True\n",
        "    )[0][:,1]\n",
        "\n",
        "    # OU‐generator L[tau]\n",
        "    phys = -theta*(x[:,0]*tau_x + x[:,1]*tau_y) \\\n",
        "           + 0.5*sigma**2*(tau_xx + tau_yy)\n",
        "\n",
        "    if forcing is None:\n",
        "        # default constant −1\n",
        "        f_vals = -1.0\n",
        "    elif isinstance(forcing, (int, float)):\n",
        "        # constant forcing = that number\n",
        "        f_vals = float(forcing)\n",
        "    elif callable(forcing):\n",
        "        # call it on x\n",
        "        f_vals = forcing(x)\n",
        "        # flatten to [N]\n",
        "        if f_vals.dim() > 1:\n",
        "            f_vals = f_vals.view(-1)\n",
        "    else:\n",
        "        raise ValueError(f\"forcing must be None, float, or callable, got {type(forcing)}\")\n",
        "\n",
        "    # turn any scalar into a tensor of shape [N]\n",
        "    if isinstance(f_vals, float) or isinstance(f_vals, int):\n",
        "        f_vals = x.new_full((x.shape[0],), float(f_vals))\n",
        "\n",
        "    # 7) residual = L[tau] - f(x)\n",
        "    r = phys - f_vals              # shape [N]\n",
        "    return r\n",
        "\n",
        "def loss_fn(res):\n",
        "    return torch.mean(res.pow(2))"
      ],
      "metadata": {
        "id": "RDSBmM64qd26"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Computing an approximate data penalty regularization\n",
        "\n",
        "We sample a small subset $x_1, \\ldots, x_{n_{data}} \\in \\Omega$ of points for which we compute approximate values $\\tau^{MC}(x_1), \\ldots, \\tau^{MC}(x_{n_{data}}) $ by Monte Carlo. we will then use them to define a \"data-fidelity\" penalty term in the loss function:\n",
        "$$\\text{Penalty}(\\hat\\tau_{NN}) = \\frac{\\lambda_{data}}{n_{data}} \\sum_{i=1}^n \\left(\\tau^{MC}(x_i) - \\hat\\tau_{NN}(x_i)\\right)^2, $$\n",
        "where $\\lambda_{data}$ is a positive constant."
      ],
      "metadata": {
        "id": "xA77CH6N03KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generating some approximate true solutions in the domain\n",
        "\n",
        "#sampling anchor points, biased towards center (failure zone)\n",
        "def sample_disk(batch_size, R, radius_frac=0.6):\n",
        "    \"\"\"\n",
        "    Sample uniformly in the DISK of radius (radius_frac * R).\n",
        "    This is the simplest way to concentrate points near the centre.\n",
        "    \"\"\"\n",
        "    r = torch.sqrt(torch.rand(batch_size, device=device))  # uniform‐disk radius ∝ sqrt(U)\n",
        "    theta = 2 * torch.pi * torch.rand(batch_size, device=device)\n",
        "    x = torch.stack([r * torch.cos(theta), r * torch.sin(theta)], dim=1)\n",
        "    return radius_frac * R * x  # now uniform in disk of radius radius_frac*R\n",
        "\n",
        "\n",
        "# 2) monte-carlo (euler-maruyama) approximation of tau at these points\n",
        "@torch.no_grad()\n",
        "def mc_exit_time(x0, theta, sigma, R,\n",
        "                 n_paths=128, dt=1e-3, max_steps=20000):\n",
        "    \"\"\"\n",
        "    x0: [B,2] starting points\n",
        "    Returns tau_hat: [B] = mean exit time from each x0.\n",
        "    Any path still 'alive' after max_steps is counted as having exit time = max_steps*dt.\n",
        "    \"\"\"\n",
        "    B = x0.shape[0]\n",
        "    P = n_paths\n",
        "\n",
        "    # Expand to per‐path positions\n",
        "    X = x0.unsqueeze(1).expand(B, P, 2).clone()  # [B,P,2]\n",
        "    t = torch.zeros(B, P, device=device)         # running clock\n",
        "    alive = torch.ones(B, P, dtype=torch.bool, device=device)\n",
        "    sqrt_dt = sigma * (dt ** 0.5)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        if not alive.any():\n",
        "            break\n",
        "\n",
        "        # Drift + noise, but only update those still alive\n",
        "        X_alive = X[alive]\n",
        "        drift    = -theta * X_alive * dt\n",
        "        noise    = sqrt_dt * torch.randn_like(X_alive)\n",
        "        X[alive] += drift + noise\n",
        "        t[alive] += dt\n",
        "\n",
        "        # Mark newly‐exited paths\n",
        "        just_exited = (X[alive].pow(2).sum(dim=1) >= R*R)\n",
        "        idx_alive   = alive.nonzero(as_tuple=False)  # [[i1,j1], [i2,j2], ...]\n",
        "        exited_idx  = idx_alive[just_exited]\n",
        "        alive[exited_idx[:,0], exited_idx[:,1]] = False\n",
        "\n",
        "    # Paths still alive get t = max_steps*dt automatically from the loop\n",
        "    tau_hat = t.mean(dim=1)  # [B]\n",
        "    return tau_hat  # no gradient flows back"
      ],
      "metadata": {
        "id": "wWM1g0wlzSPW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Homotopy Regularization\n",
        "\n",
        "We define a smooth function $g(x)$ for regularizing the constant forcing term as\n",
        "\n",
        "$$\n",
        "g(x) = \\mathrm{magnitude} \\cdot \\sigma\\!\\left(\\frac{1}{\\sigma_{\\mathrm{raw}}}\\left[\\sum_{j=1}^{M} a_j\\cos\\Big(\\langle \\omega_j, x \\rangle + b_j\\Big) - \\mu\\right]\\right)\n",
        "\\cdot \\frac{\\max\\{R^2 - \\|x\\|^2,\\,0\\}}{2R},\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $a_j$, $\\omega_j$, and $b_j$ are random coefficients (with $\\omega_j$ scaled by a base frequency, and $b_j$ uniformly drawn from $[0,2\\pi]$),\n",
        "- The **raw Fourier sum** is\n",
        "  $$\n",
        "  G_{\\mathrm{raw}}(x) = \\sum_{j=1}^{M} a_j\\cos\\!\\Big(\\langle \\omega_j, x \\rangle + b_j\\Big),\n",
        "  $$\n",
        "  which is then normalized by subtracting its mean $\\mu$ and dividing by its standard deviation $\\sigma_{\\mathrm{raw}}$;\n",
        "- $\\sigma(\\cdot)$ is the sigmoid function that bounds the output to $(0,1)$;\n",
        "- The radial mask\n",
        "  $$\n",
        "  \\frac{\\max\\{R^2 - \\|x\\|^2,\\,0\\}}{2R}\n",
        "  $$\n",
        "  ensures that $g(x)$ smoothly decays to zero as $\\|x\\|$ approaches $R$.\n",
        "\n",
        "**Quick Intuition:** The function combines a randomized Fourier series with normalization, a sigmoid activation, and a radial decay. This results in a smooth, bounded perturbation to the forcing term, enhancing the regularity needed for improved convergence of the PINN solver."
      ],
      "metadata": {
        "id": "u7GNsuMn7qwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Fourier Homotopy g(x) to regularize the forcing term\n",
        "class RandomFourierHomotopy:\n",
        "    def __init__(self, M=200, freq_scale=None, R=R, magnitude=8.0):\n",
        "        \"\"\"\n",
        "        M           : number of random Fourier modes\n",
        "        freq_scale  : base frequency scale (if None, defaults to π/R)\n",
        "        R           : radius of the disk\n",
        "        magnitude   : overall output scale\n",
        "        \"\"\"\n",
        "        self.M         = M\n",
        "        self.R         = R\n",
        "        self.magnitude = magnitude\n",
        "\n",
        "        if freq_scale is None:\n",
        "            # pick a lower base frequency so the field is smooth\n",
        "            freq_scale = math.pi / R\n",
        "\n",
        "        # sample random directions & phases\n",
        "        # omega: [M,2], b: [M], a: [M]\n",
        "        self.omega = torch.randn(M, 2) * freq_scale\n",
        "        self.b     = 2 * math.pi * torch.rand(M)\n",
        "        # normalize by sqrt(M) so that raw variance ~1\n",
        "        self.a     = torch.randn(M) / math.sqrt(M)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        x: [N,2] tensor of (x,y) points\n",
        "        returns: [N] tensor of forcing values\n",
        "        \"\"\"\n",
        "        # 1) compute raw random Fourier sum\n",
        "        #    proj: [N,M] = x·omega^T + b\n",
        "        proj  = x @ self.omega.t() + self.b\n",
        "        g_raw = (self.a * torch.cos(proj)).sum(dim=1)    # [N]\n",
        "\n",
        "        # 2) normalize to zero mean, unit std dev (over this batch)\n",
        "        mean   = g_raw.mean()\n",
        "        stddev = g_raw.std(unbiased=False).clamp(min=1e-6)\n",
        "        g_norm = (g_raw - mean) / stddev                # [N]\n",
        "\n",
        "        # 3) nonlinearity: tanh keeps it in (–1,1) but nonzero everywhere\n",
        "        g_nl = torch.sigmoid(g_norm)                       # [N]\n",
        "\n",
        "        # 4) radial mask to fade to zero at |x|=R\n",
        "        r2   = (x**2).sum(dim=1)                        # [N]\n",
        "        mask = ((self.R**2 - r2).clamp(min=0)\n",
        "                / (2 * self.R))                       # [N]\n",
        "\n",
        "        # 5) scale to the desired magnitude\n",
        "        return self.magnitude * g_nl * mask             # [N]"
      ],
      "metadata": {
        "id": "9-A3bb5AqX1E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Adaptive sampling [TODO: add citation]\n",
        "The function `make_adaptive_batch` creates a mini-batch that focuses training on areas with high PDE residuals:\n",
        "\n",
        "1. **Residual Computation:**  \n",
        "   A candidate pool `Xp` is sampled uniformly over the disk. For each point $x$, the PDE residual is computed via  \n",
        "   $$\n",
        "   r(x) = \\texttt{pde_residual(model, x, theta, sigma, forcing)}\n",
        "   $$  \n",
        "   and the absolute residual is defined as  \n",
        "   $$\n",
        "   R(x) = |r(x)|.\n",
        "   $$\n",
        "\n",
        "2. **Adaptive Selection:**  \n",
        "   A fraction of the batch (defined by `hard_frac`) is formed using high-error points. There are two modes:\n",
        "   - **Hard Sampling:** Directly select the top $K = \\texttt{hard_frac} \\times \\texttt{batch_size}$ points with the highest $R(x)$.\n",
        "   - **Soft Sampling:** Sample points with probability proportional to  \n",
        "     $$\n",
        "     p(x) \\propto R(x)^\\beta.\n",
        "     $$\n",
        "     The parameter $\\beta$ controls the selection sharpness:\n",
        "     - A small $\\beta$ makes the sampling nearly uniform.\n",
        "     - A large $\\beta$ heavily favors points with high residuals.\n",
        "\n",
        "3. **Batch Formation:**  \n",
        "   The final batch is a combination of these adaptively chosen points and randomly selected points from the remaining pool.\n",
        "\n",
        "This method helps concentrate training on regions where the model underperforms while still maintaining overall coverage."
      ],
      "metadata": {
        "id": "OH0uiQg_8lBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Uniform + Adaptive Sampling functions in the disk\n",
        "def sample_uniform_disk(N, R=R):\n",
        "    theta = 2*np.pi * torch.rand(N, dtype=torch.float64, device=device)\n",
        "    rho = R    * torch.sqrt(torch.rand(N, dtype=torch.float64, device=device))\n",
        "    return torch.stack([rho*torch.cos(theta), rho*torch.sin(theta)], dim=1)  # [N,2]\n",
        "\n",
        "def make_adaptive_batch(\n",
        "    model, pool_size, batch_size,\n",
        "    forcing, theta, sigma,\n",
        "    hard_frac=0.1,    # fraction of batch from highest residuals\n",
        "    use_soft=False,   # if True, sample soft rather than top‐K\n",
        "    beta=1.0          # exponent for soft sampling\n",
        "):\n",
        "    # candidate pool\n",
        "    Xp = sample_uniform_disk(pool_size)\n",
        "\n",
        "    # 2) Compute residuals _with_ gradient‐tracking so second‐derivatives work\n",
        "    r_all = pde_residual(model, Xp, theta, sigma, forcing)  # [pool_size]\n",
        "    # 3) Detach and take absolute\n",
        "    Rvals = r_all.detach().abs()                             # [pool_size]\n",
        "\n",
        "    # number of hard points\n",
        "    K     = int(batch_size * hard_frac)\n",
        "    if use_soft or beta < 10.0 :\n",
        "        # 2a) soft sampling: probabilities ∝ (residual^beta)\n",
        "        weights = Rvals.pow(beta)\n",
        "        weights = weights / (weights.sum() + 1e-12)\n",
        "        hard_idx = torch.multinomial(weights,\n",
        "                                     num_samples=K,\n",
        "                                     replacement=False)\n",
        "    else:\n",
        "        # 2b) hard sampling: pure top‐K\n",
        "        hard_idx = torch.topk(Rvals, K).indices # [K]\n",
        "\n",
        "    all_idx  = torch.arange(pool_size, device=device)\n",
        "    mask     = torch.ones(pool_size, dtype=torch.bool, device=device)\n",
        "    mask[hard_idx] = False\n",
        "    rest_idx = all_idx[mask]\n",
        "    n_rest   = batch_size - K\n",
        "    rnd      = rest_idx[torch.randperm(rest_idx.numel(), device=device)[:n_rest]]\n",
        "\n",
        "    batch_idx = torch.cat([hard_idx, rnd], dim=0)                # [batch_size]\n",
        "    return Xp[batch_idx]                                      # [batch_size,2]"
      ],
      "metadata": {
        "id": "IJI5xaOUqom1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Training loop"
      ],
      "metadata": {
        "id": "gkRR91T6_atw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 6.1) Training Parameters"
      ],
      "metadata": {
        "id": "Qo8UoTLI_lue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "pool_size        = 4096\n",
        "batch_size       = 512\n",
        "n_epochs         = 20_000\n",
        "learning_rate    = 5e-2\n",
        "beta = 1 # 0 -> no adaptive sampling, infty -> top K sampling\n",
        "\n",
        "\n",
        "# model instantiation\n",
        "model = BoundaryPINN().to(device)\n",
        "model.apply(init_weights)\n",
        "\n",
        "opt   = torch.optim.Adam(list(model.parameters()), lr=learning_rate)\n",
        "\n",
        "# scheduler: every `step_size` epochs multiply lr by gamma\n",
        "step_size = 500        # decay lr every step_size epochs\n",
        "n_steps   = n_epochs // step_size\n",
        "damping   = 1e-2\n",
        "gamma     = math.exp(math.log(damping) / n_steps)        # mutiply lr by gamma at each step\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt,\n",
        "                                            step_size=step_size,\n",
        "                                            gamma=gamma)"
      ],
      "metadata": {
        "id": "Oq-NigAc8Ag2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2) Generating the \"data-fidelity\" samples"
      ],
      "metadata": {
        "id": "7iyHryGJ_pU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample x_data\n",
        "x_data = sample_disk(batch_size = batch_size//2,\n",
        "                     R = R,\n",
        "                     radius_frac = 0.8)\n",
        "\n",
        "# precompute tau_data once (theta, sigma are fixed PDE params)\n",
        "tau_data = mc_exit_time(\n",
        "    x0       = x_data,\n",
        "    theta    = theta,\n",
        "    sigma    = sigma,\n",
        "    R        = R,\n",
        "    n_paths  = 256,\n",
        "    dt       = 1e-3,\n",
        "    max_steps= 10_000\n",
        ")"
      ],
      "metadata": {
        "id": "kepv7k3TzfBU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3) Parametrizing the homotopy function and schedule"
      ],
      "metadata": {
        "id": "upAlBbgt_zz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parametrizing the homotopy\n",
        "sigma_true = sigma       # true diffusion coefficient\n",
        "theta_true = theta       # true drift coefficient\n",
        "r_true     = theta_true / sigma_true # true ratio\n",
        "\n",
        "# \"easy\" and true coefficient ratio\n",
        "r0 = 0.25 if r_true > 0.25 else r_true\n",
        "r1 = r_true\n",
        "\n",
        "# \"easy\" and true forcing term\n",
        "g_hom = RandomFourierHomotopy(M=50)\n",
        "f_0 = lambda x : -1.0 - g_hom(x)\n",
        "f_1 = lambda x : x.new_full((x.shape[0],), -1.0)\n",
        "\n",
        "#helper functions\n",
        "nu_step = 0.1\n",
        "def make_nu(epoch, n_hom, step = 0.1):\n",
        "    \"\"\"Returns nu in steps of `step` from 0 up to 1 after n_hom epochs.\"\"\"\n",
        "    if epoch >= n_hom:\n",
        "        return 1.0\n",
        "    continuous_nu = float(epoch) / n_hom\n",
        "    discrete_nu = math.floor(continuous_nu / step) * step\n",
        "    return discrete_nu\n",
        "\n",
        "def interp(a0, a1, nu):\n",
        "    return a0 * (1.0 - nu) + a1 * nu"
      ],
      "metadata": {
        "id": "KrqgYNkqxnko"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot homotopy forcing g_hom(x)\n",
        "n_pts = 200\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(-R,R,n_pts),\n",
        "    np.linspace(-R,R,n_pts)\n",
        ")\n",
        "mask = xx**2 + yy**2 <= R**2\n",
        "grid_pts = np.vstack([xx[mask], yy[mask]]).T\n",
        "\n",
        "with torch.no_grad():\n",
        "    g_vals = g_hom(torch.from_numpy(grid_pts).to(device)).cpu().numpy()\n",
        "\n",
        "Zg = np.zeros_like(xx)\n",
        "Zg[mask] = g_vals\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "cg = plt.contourf(xx, yy, Zg, levels=50, cmap='coolwarm')\n",
        "plt.colorbar(cg, shrink=0.8)\n",
        "plt.title('Homotopy forcing $g_{\\\\rm hom}(x)$')\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "M3o_xL7B0mPq",
        "outputId": "a8592bd2-4a80-4a5f-f756-dd051a3fdfd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHqCAYAAACna18/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAex9JREFUeJztnXuUFNW977/zYHoezIDIewRBNGKC+EAgAz4wQYW4JiFZQa8aASUazUAgaIJ4jAMxMnA0Ro9yEV9wzAHx6jmgiUSvEkf0AFFAbnwcVFRkAvIwCgPzZGbq/jFW011dtWs/q6q7f5+1eq2Znqraux/Tn/799t6/nWNZlgWCIAiCILSSG3YHCIIgCCITIcESBEEQhAFIsARBEARhABIsQRAEQRiABEsQBEEQBiDBEgRBEIQBSLAEQRAEYQASLEEQBEEYgARLEARBEAYgwRIEQRCEAUiwBEEQBGEAEixBcPLWW29hzJgxKCkpQU5ODrZv3x5Y2ytWrEBOTg527doVWJvpwL/+679i6NCh6OjoEDrv4YcfxsCBA9HS0mKoZwRBgk1r7A/dLVu2uP593LhxGDZsWMC9EmPjxo2YP38+Dh06FHZXmBw7dgyTJ0/Gl19+iT/84Q/44x//iJNPPjnsbmU19fX1WLx4MebOnYvcXLGPsmnTpqG1tRXLli0z1DuCIMESIbNx40YsWLAg8oL9+OOP8dlnn+HWW2/FjTfeiJ/85Cc44YQTAmv/2muvRVNTE0k9gSeeeAJtbW246qqrhM8tLCzE1KlTcd9994E2FCNMQYIlCA4OHDgAAOjevbu2azY0NHAfm5eXh8LCQuTk5GhrP91Zvnw5vv/976OwsFDq/CuuuAKfffYZXn31Vc09I4hOSLBZxttvv42JEyeirKwMXbt2xXe/+11s3rw56Zj58+cjJycHH374IX7yk5+gW7du6NWrF37zm9/AsizU1dXhBz/4AcrKytC3b1/8/ve/l27nV7/6FQBg8ODByMnJSRpnFOnrjh07cMUVV6CsrAwnnngiZs2ahebm5vhxr776KnJycrBmzZqUvq5atQo5OTnYtGmT63M2bdo0XHTRRQCAyZMnIycnB+PGjZN6Tt9//31cffXVOOGEE3D++efH/75nzx5Mnz4d/fv3RywWw+DBg3HzzTejtbUVgPsYrH3NnTt3Ytq0aejevTu6deuG6667Do2NjUnt19bW4rzzzkNhYSGGDBmCZcuWxc/n5d///d8xfPhwFBUVYcSIEdi0aROuuOIKnHXWWdzX0MWnn36Kv//97xg/fnzS/Xv27EFhYSGuv/76pPtfeeUVdOnSBb/85S/j940YMQI9evTAc889F0ifiewjP+wOEOocPnwYX3zxRcr9x44dS/r9vffewwUXXICysjL8+te/RpcuXbBs2TKMGzcOr732GkaPHp10/JVXXokzzjgDixYtwgsvvIDf/e536NGjB5YtW4bvfOc7WLx4MVauXIlbb70VI0eOxIUXXijUzo9+9CN8+OGHeOqpp/CHP/wBPXv2BAD06tVLuK9XXHEFBg0ahJqaGmzevBn/9m//hq+++gpPPvkkgM7x6AEDBmDlypX44Q9/mHTuypUrMWTIEFRUVLg+vz/72c9QXl6OhQsX4he/+AVGjhyJPn36SD2nkydPxmmnnYaFCxfGU5N79+7FqFGjcOjQIdx4440YOnQo9uzZg2effRaNjY0oKCjweOWPP/bBgwejpqYG27Ztw2OPPYbevXtj8eLFADq/AEyYMAH9+vXDggUL0N7ejt/+9rfo1asX87qJ1NTU4Pbbb8cPf/hDzJw5E9u3b8f3v/99dOvWDd/+9re5r6OLjRs3AgDOPffcpPvLy8vx05/+FI888giqq6tx8sknY8eOHZg8eTImTpyY8mXw3HPPxX//938H1m8iy7CItGX58uUWAObtW9/6Vvz4SZMmWQUFBdbHH38cv2/v3r1WaWmpdeGFF8bvq66utgBYN954Y/y+trY266STTrJycnKsRYsWxe//6quvrKKiImvq1KnC7ViWZd1zzz0WAOvTTz9Nul+0r9///veTzv/5z39uAbD+3//7f/H75s2bZ8ViMevQoUPx+w4cOGDl5+db1dXVKc9vIq+++qoFwHrmmWeU+nnVVVelXHvKlClWbm6u9dZbb6X8raOjw7Ks46914vNkX/P6669POueHP/yhdeKJJ8Z/r6ystIqLi609e/bE7/voo4+s/Px8i+cjYOvWrVZeXp41b968pPunT59uAbBqamp8r6GbO+64wwJgHTlyJOVv//jHP6xYLGbdfPPN1hdffGENGTLEOvvss62jR4+mHHvjjTdaRUVFQXSZyEIoRZwBLFmyBC+//HLKbfjw4fFj2tvb8X//7//FpEmTcMopp8Tv79evH66++mq88cYbqK+vT7ruT3/60/jPeXl5OO+882BZFqZPnx6/v3v37jj99NPxySefSLfjROYaVVVVSb/PnDkTALBu3br4fVOmTEFLSwueffbZ+H1PP/002tra8JOf/ITZJ139vOmmm5J+7+jowNq1a1FZWYnzzjsvpQ2eFK7zmhdccAH++c9/or6+Hu3t7XjllVcwadIk9O/fP37MqaeeiokTJ3I9zoULF8ajX2c7AHDmmWfG+/qPf/yD65qq/POf/0R+fj66du2a8rfy8nLccMMNeOKJJ3D55ZejqakJf/7zn1FSUpJy7AknnICmpqaUlDpB6IAEmwGMGjUK48ePT7klznI9ePAgGhsbcfrpp6ecf8YZZ6CjowN1dXVJ9w8cODDp927duqGwsDCeyk28/6uvvpJux4nMNU477bSk34cMGYLc3NykMcuhQ4di5MiRWLlyZfy+lStX4tvf/jZOPfVUZp909XPw4MEp16ivr1daTuV8nezX/auvvsKBAwfQ1NTk+vh4HnNLSwv+8pe/4Morr0SXLl2S/nb06FEAxwUbJW699Va0tLTg73//O55//nmUl5e7Hmd9naanyWOECUiwhCd5eXlc9wGI3FIHrw/MKVOm4LXXXsM//vEPfPzxx9i8ebNU9CpLUVGR9muafE0+/vhjNDY2uk5k+uSTT1BWVpYi+CA48cQT0dbWhiNHjrj+/e677wYAtLW1oUePHp7X+eqrr1BcXGzkdSEIEmyW0KtXLxQXF+ODDz5I+duOHTuQm5uLAQMGBN6Omwhl+vrRRx8l/b5z5050dHRg0KBBSff/r//1v5CXl4ennnoKK1euRJcuXXDllVeKPESlfrpdo6ysDO+++65UH/zo3bs3CgsLsXPnzpS/ud3npKmpCQBSCjm0tLTgqaeeSom8//SnP2Hw4MHo2bMnampqkv5mTwjr3r07RowYkTS5KCcnB0uWLMGgQYPQvXt3LFu2DBs3bsQ3v/lNnHDCCbjrrruSrjV06FAAnbOJndxzzz147LHH8NBDDyE/Pz8uWzc+/fRTnHHGGb7PA0HIQILNEvLy8nDppZfiueeeS0qb7t+/H6tWrcL555+PsrKywNuxx8USC03I9HXJkiVJvz/44IMAkDLO2LNnT0ycOBH/8R//gZUrV2LChAkpKW9Tj9WN3NxcTJo0CX/6059cK3KpRqF5eXkYP3481q5di71798bv37lzJ/7yl7/4nm8XtnjjjTeS7l+0aBE+//zzFMH+9a9/xTvvvIPa2losWLAAH3/8MQCgtbUVlZWVmDx5Mg4ePIhf//rXqKysjA8tAMDrr7+O999/H2vWrMHs2bPx+9//Hm+88QY2bdqEhQsXxsf5AcRnfDufs7Vr1+K2227DXXfdhaqqKtx444148sknXUUMANu2bcOYMWN8nweCkCLUKVaEEvbMUrfZp5ZlWRdddFHSLOJ3333XKikpscrLy627777bWrx4sXXKKadYsVjM2rx5c/w4e3bqwYMHk643depUq6SkRFs7lmVZb775pgXA+t73vmc9+eST1lNPPWUdPXpUuK9nnnmmVVlZaS1ZssT6yU9+YgGwrr76atfn5dlnn43Psn766acZz/BxvGYRqz6nltU567Vv375WcXGxNXv2bGvZsmXW/PnzrW9961vWV199ZVkWexax85rOY7ds2WIVFBRYgwYNshYvXmwtXLjQ6t+/v3X22WdzzSKeMGGClZuba82YMcN65JFHrCuuuMIaMmSIBcB68MEH48cBsLZs2RL/feTIkdaaNWssy7KsDRs2WCeffHLSdb/97W9bq1atip+7devW+N969+5t/ed//mf891GjRsWvZTNs2LCkWdlbtmyxiouLrWuvvTZ+3549e6xYLGZNnz495XFt2bLFAmC98sorvs8BQchAgk1jRAVrWZa1bds267LLLrO6du1qFRcXWxdffLG1cePGpGNUBcvbjs1dd91llZeXW7m5uUliEOnr+++/b/34xz+2SktLrRNOOMGaMWOG1dTU5NpeS0uLdcIJJ1jdunXzPMaJl2BF++kmWMuyrM8++8yaMmWK1atXLysWi1mnnHKKVVVVZbW0tFiWpSZYy7Ks9evXW+ecc45VUFBgDRkyxHrsscesW265xSosLPR97Pv377cmTZpklZWVWf369bNmzZplrVmzxgKQ9CUCgFVXVxf//aKLLrL++Mc/WpZlWatXr7bOP//8pOteeeWV1r333ut67sknn2y9/vrrrteyue+++6yuXbtajY2NVl1dndWvXz9r7NixVnNzc9JxN998s9WlSxfrk08+Sbp/7ty51sCBA+NLoQhCNyRYIq3xE5cbx44ds3r16pWyfjTb+MEPfmCdeuqpUudWVVVZPXv2tI4dOxa/jyVYtwi2oqIiKYIVFeyhQ4esHj16WI899phw/5ubm62+ffta999/v/C5BMELjcESWcfatWtx8OBBTJkyJeyuBIY9Wcnmo48+wrp165JKPrrR0tKSMg68YcMGLFu2DDfddBPy8/mKwdkVrR566CG0tbXhmWeewf/8z/9gwoQJ/A/CQbdu3fDrX/8a99xzj/B2dcuXL0eXLl1S1hAThE6oVCKRNfztb3/D3//+d9x1110455xz4vWFs4FTTjkF06ZNwymnnILPPvsMS5cuRUFBAX79618zz3vppZfw29/+Fj/+8Y/RvXt3bNu2DcuXL8c555yD22+/nbv9goICPP/887j55pvxL//yLxgyZAief/555R2J5s6di7lz5wqfd9NNN5FcCeOQYImsYenSpfiP//gPnH322VixYkXY3QmUCRMm4KmnnsK+ffsQi8VQUVGBhQsXphTocNKjRw8UFBRg0aJFaGxsxKBBgzB37lzMmzcvZe2oM9Ktra1N+n348OGedX+d5zo3lndeiyDSgRzL+c4mCIIgCEIZGoMlCIIgCAOQYAmCIAjCAJEeg+3o6MDevXtRWlpKxbgJgiACxLIsHDlyBP37908plUnwEWnB7t27V0t9XIIgCEKOuro6nHTSSWF3Iy2JtGBLS0sBdL7AOurkEgRBEHzU19djwIAB8c9hQpxIC9ZOC5eVlZFgCYIgQoCG5+ShxDpBEARBGIAESxAEQRAGIMESBEEQhAFIsARBEARhABIsQRAEQRiABEsQBEEQBiDBEgRBEIQBSLAEQRAEYQASLEEQBEEYgARLEARBEAYgwRIEQRCEAUiwBEEQBGEAEixBEARBGIAESxAEQRAGIMESBEEQhAFIsARBEARhABIsQRAEQRiABEsQBEEQBiDBEgRBEIQBSLAEQRAEYQASLEEQBEEYgARLEARBEAYgwRIEQRCEAUiwBEEQBGEAEixBEARBGIAESxAEQRAGIMESBEEQhAFIsARBEARhABIsQRAEQRiABEsQBEEQBiDBEgRBEIQBSLAEQRAEYQASLEEQBEEYgARLEARBEAYwKtiamhqMHDkSpaWl6N27NyZNmoQPPvjAZJMEQRAEEQmMCva1115DVVUVNm/ejJdffhnHjh3DpZdeioaGBpPNEgRBEESc+fPnIycnJ+k2dOhQrnNXr16NnJwcTJo0SbjdfOEzBHjxxReTfl+xYgV69+6NrVu34sILLzTZNEEQBEHE+da3voVXXnkl/nt+vr/+du3ahVtvvRUXXHCBVJtGBevk8OHDAIAePXq4/r2lpQUtLS3x3+vr6wPpF0EQBJHZ5Ofno2/fvtzHt7e345prrsGCBQvw+uuv49ChQ+JtCp8hSUdHB2bPno2xY8di2LBhrsfU1NRgwYIFXNe76EcbdXaPIAgiq3ntv8aE3QWjfPTRR+jfvz8KCwtRUVGBmpoaDBw40PP43/72t+jduzemT5+O119/XarNwARbVVWFd999F2+88YbnMfPmzcOcOXPiv9fX12PAgAFBdI8gCIIIiObmZrS2tipdw7Is5OTkJN0Xi8UQi8VSjh09ejRWrFiB008/HZ9//jkWLFiACy64AO+++y5KS0tTjn/jjTfw+OOPY/v27Up9DESwM2bMwJ///Gds2LABJ510kudxXk8OQRAEkRk0Nzejf3EpvrLalK7TtWtXHD16NOm+6upqzJ8/P+XYiRMnxn8ePnw4Ro8ejZNPPhn/5//8H0yfPj3p2CNHjuDaa6/Fo48+ip49eyr10ahgLcvCzJkzsWbNGtTW1mLw4MEmmyMIgiAiTmtrK76y2vDH7qehOEduIUuj1YFrD32Euro6lJWVxe/nDdC6d++Ob3zjG9i5c2fK3z7++GPs2rULlZWV8fs6OjoAdI7jfvDBBxgyZAhXO0YFW1VVhVWrVuG5555DaWkp9u3bBwDo1q0bioqKTDZNEARBRJjinFyU5OQpXaOsrCxJsLwcPXoUH3/8Ma699tqUvw0dOhTvvPNO0n133HEHjhw5ggceeEBo2NKoYJcuXQoAGDduXNL9y5cvx7Rp00w2TRAEQRAAgFtvvRWVlZU4+eSTsXfvXlRXVyMvLw9XXXUVAGDKlCkoLy9HTU0NCgsLUybidu/eHQA8J+h6YTxFTBAEQRBh8o9//ANXXXUV/vnPf6JXr144//zzsXnzZvTq1QsAsHv3buTm6q+7FOg6WIIgCIIImtWrVzP/Xltby/z7ihUrpNolwRLE1xSWFiud33ykUVNPCILIBEiwREajKk3TbZGUCSJzIcESGUGQItWJX79JwASRvpBgibQjXWUqA+uxknyJdKakfwwleZLLdNrbga/09scEJFgi8mSTUEXwel5IvAQRDUiwRCQhqcrj9tyRdAkieEiwRGQgqZqDpEsQwUOCJULFtFSLSoKTdlNDegmLpEsQZiHBEoFjQqpBilSlD1GXsPO1IeEShDwkWCIwdIk1CjKVxa/vURMwCZcg5CHBEsZRFWs6C1UUr8caFfGScAmCHxIsYQSSql6iKl4SLkF4Q4IltKIiVpKqOFETb+LrT7IlWBSeUIiifDkFtbe1ae6NGUiwhDZk5GpCqkVdC7Vfk5emo82htZ1IFMRLsiWyHRIsoUyYYg1Tpm749SdsAbs970FIl2RLZCMkWEKaMMQaNaGKwup/WPINWrokWyJbIMESwgQp1nQXqghejzUM8QYlXZItkcmQYAkhROVKYlUnKuI1LV2SLZFpkGAJLoIQq26pFpcWab2eH41HmgJtLwridb7OuoRrv99ItEQ6Q4IlfDEtV1WxBi1SL/z6EZSAwxSvbuGSaIl0hgRLeBJlsUZFqiKw+hyEfMMQry7hUvqYSEdIsIQrJuUqI9Z0FKoIXo8vLPGakq4O4VJUS6QLJFgiBRG5mo5aTYm1qKRA+tymhlaNPWETlniDinYT3z+isiXRpjdF3QpR1EWyktMxquREpBlRilpVxaoiUF3XNiniKIlXl3RlZUuiJaIKCZYAEB25yorVpFBl8euTCQGHIV4T0pWRbWFpMUmWiBQkWMKYXE2KNYpCFcXrMWSCeHVKV0S2FM0SUYIEm+WYGm/llWs2itWPTBWv8z0hI1z7PUiiJdKB3LA7QIRDYWlxqHItLi3ilmtRSUH8JktxcUHgN90kPg/Om27s18ftpouiroVJN6FzS4rjNxai73Mi81m0aBFycnIwe/Zs5nH3338/Tj/9dBQVFWHAgAH45S9/ieZmsS+FFMFmIWGnhEXEKoMJucng14/GRn0RadhRr46IN/H9IxLd8kS1ND5LAMBbb72FZcuWYfjw4czjVq1ahdtuuw1PPPEExowZgw8//BDTpk1DTk4O7rvvPu72SLBZRjrIVUasUZGqCF59Tkfx6k41y6ST/URLaePs5ujRo7jmmmvw6KOP4ne/+x3z2I0bN2Ls2LG4+uqrAQCDBg3CVVddhb/97W9CbVKKOIsIU6686UURuRpNxxbnu96CIIi0c1DpZl0pZpFUsl/qmFLGmUN9fX3SraWlxfPYqqoqXH755Rg/frzvdceMGYOtW7fizTffBAB88sknWLduHb73ve8J9Y8i2CwhbLn6t8f3wa4qGVVJypzf1KhvUXwmRL3O94NolGu/5/yiWlZES9Fs+MTKClFY0EXq3GOtxwAAAwYMSLq/uroa8+fPTzl+9erV2LZtG9566y2u61999dX44osvcP7558OyLLS1teGmm27C7bffLtRPEmwWkAlylRFrUBGnH3790CHgdBavrHB5x2z9REuSTV/q6upQVlYW/z0Wi7keM2vWLLz88ssoLOQbyqqtrcXChQvxv//3/8bo0aOxc+dOzJo1C3fddRd+85vfcPcvGp9AhDHSXa6iYo2KVEVg9VlVvqznT5d8dYtXRrg8UW1RSTFFsxlGWVlZkmDd2Lp1Kw4cOIBzzz03fl97ezs2bNiAhx56CC0tLcjLy0s65ze/+Q2uvfZa/PSnPwUAnHnmmWhoaMCNN96If/mXf0FuLt/oavp9GhHcRFmuOqNWHVItLs7zP4iTxsZ2bdfyemzpEPW6vcYy0k18L/nJ1k+0FM1mH9/97nfxzjvvJN133XXXYejQoZg7d26KXAGgsbExRaL2cZZlcbdNgs1Q0lmuJsWqU6QqbahKOF2jXlXp8srWL33sJVqSbOZRWlqKYcOGJd1XUlKCE088MX7/lClTUF5ejpqaGgBAZWUl7rvvPpxzzjnxFPFvfvMbVFZWugrZCxJsBpLpchURaxBClcGvXyoCDiPqBeTlKytdEdmyIlo3yQKUMs4mdu/enRSx3nHHHcjJycEdd9yBPXv2oFevXqisrMTdd98tdF0SbIYR5hIE03LlFWtUpSoC6zHIytdk1AvoTTknvldEZOslWlbqmKLZ7KO2tpb5e35+Pqqrq1FdXa3UDgk2g5CRq67oVUWuOsQqK9Xiohyp81RobOIfw3HD67GaiHoBMylnEek63zss4fpFtX6iJckSOiHBZgjZKldRsYYhVNE+yArYRNQLmJGvinR5o1tWVOslWpIsoRMSbAYQplz925GTqy6xRkGoorD6nC7ylRGv8/3AI1we2fqJ1k2yndc7LlWSrH5iZSWIxeQKTbS2HNPcGzOQYNOcsOXKil7DlKusWIsKzQq5qVkxPZwm8tUhXlHh2u83UdHyRrM0+YkQhQSbxpiUKw9By9VPrKJSNS1T2TZlJZwO8nV7fXmlm/i+YcnWL6oVES2ljAkVSLBpimm5qoy7Bi1XXrGGIVQZ/PopI2Cv50hlwpWuyVYy0uWNbllRbXFpEVfamFLGhCwk2DQkynJlnichV9WoVVaqxTG1VK4fjS3ysmc9JlH5mphwpUO8zvcDr3BFRcuKZnlSxiRZggUJNs0wvc7V5KQmz3Mk5KpTrKZlKtumjIS9HncU0s4q4uUVrl8aWUS0PCljkizBggSbRsjKNcqTmnTLlUesYQhVBlY/ReWrM+q10ZV2dr7WosL1k62oaP2iWZIswQsJNk0wLVcewparilhlpVpU0CF1Hi9NrXy7cjgJSr6A3rQzj3zdXn+WdP1k6yda3miWJEuIQoJNA4KQa9DjrkHJVUSspmUq26aohHXKFzA/5isqXR7ZioiWN5olyRKikGAjThTk6t+Wu0RNy1VVrGEIVQa/fooIOCj5iohXVLo8KWVWVCsiWjfJAsfHZUmyBAsSbISJilxlU8OuxxuWq59YZaRaEtO3v6sfDS3iNZVZj0mXfAExAauK1/m68wjXK7L1impZonVKFvBOGZNk5SgoLUJBTHxSJAAUFOjZs9g0JNgIojJTOCpy5d3TtfNY83LlFWuQMpVpX1TAuuQL6Il+ZcWb+F7wkq1fGllEtLzRLEmWYEGCjRhBydUkIqlhEbmaEKsuoRbm+9dGbW6Tq7uaiE4BByFfWfGyhMsT3bKiWpZoeaJZkizBCwk2QgQpV1PRq+i4q+s1NMhVp1h55GnqOqJSZj2uMOQrK14Z4bJEC6TK1k20XtGsrGSJ7IYEGxEyQa6exwuMu5qUK69UdQlVB359ERFwlOTr9tqxpMsjXL80sldUW1Sc7xvNykqWotjshgQbAdJJrszzFMddVeUqK1ZZoRZpFnGTRApZl4BNy5dHvM7XlFe4LNnyipYnmnWOy5JkCT9IsCETNbn6t6meGlaRq86olVesukWq2o6IiFmPMUj5yoiXV7gs2bKi2uLiPOVo1jnDmCRLJEKCDZEoyjWI1DDXuYpyVRFrUEKVhdW/dJOv87XjFa6fbHmjWpFoljdlTJIlbEiwIZFucmWeZyA1nHKMhpQwSyiiUi3MaxE6Xpbm9pjQ8X6Pg1fApuTrJ11e4frJlieq5REtSZZQgQQbAkHWFdYl1zBTw7xyNSXWoGQq27aIhHVEv17PJ494RaXLI1xe2bqJ1i9t7Ixm3cZlRSVLdJLftQRdCuUKTeR3UV/yFgQk2IDJJLl6Hq953DXlGA1y9ROrilRjOXLntlhi0aqNX195BawqX1nxikg38bUXla2baHVEs6KSpSg2eyDBBkTQBSSCkKtIapgHnnFXXrnKiJVXqrIC1XldERmzHpeqfE2JN/E1VZWtimhlJesHSTY7IMEGQFTlqoLu1LBpuaqI1ZRQVfDrE6+AVeWrU7xewnW+xm7CZcmWJVq/tLGsZGk8lgBIsMYJeh9XEblGKTWccgzHbjiqcmXJRVSqMavJ/yAFWnLEJqCx+q8qX1PilREuS7Y8ovWKZlkpY5IswYvcbs8EF5kqV5XUsK5JTTxyLco/5vpBX5jX4iqPWE5L/MYiZjWl3Ezj1qZsHxIfp/PGg/38ud38sF+TxJtnO/nHkm5ulMTa47eUtgo6XLMexTErNTvifA8W5aS8VxO/LDq/TCb+TyT+7yT+nyX+f0albng2smjRIuTk5GD27Nmexzz66KO44IILcMIJJ+CEE07A+PHj8eabbwq3RRGsIbJNriKF/JPOk5jUxCvXlGM8BMAjVBVibfwRSku+/AevXz95omDVyNftOfaLeJ2vlVeUm/gau0W39vvCGdWyIlqZaDYxkgWSZxiLRLLxx0VRbGC89dZbWLZsGYYPH848rra2FldddRXGjBmDwsJCLF68GJdeeinee+89lJeXc7dHgjWAjFyDECsQrlxlUsMm5cqSCa9UReRp4noiQmY9JhX5+olXVLqJr5+MbEVE65U25pUskJwyFpEspYqD5ejRo7jmmmvw6KOP4ne/+x3z2JUrVyb9/thjj+E///M/sX79ekyZMoW7TUoRayZT5ep5Dme1JpnUcBhy9Uu3xtoak25h4+yPbP9U0s4y6Wbe1DJPOtkrhSySOnZLGSe+P50pY+cXyMT/A5508fG/U6o4KKqqqnD55Zdj/Pjxwuc2Njbi2LFj6NGjh9B5FMFqRFSuKv9cOlPCXNfQsIF6Ijzjrn74yVVUrF6IirTgWIPQ8SK0dikROp7Vd57o1+t5kY14vaJd52vlFeGyolv7/SAS0apEs261jOPH+SzhofWxeqivr0/6PRaLIRZLfe+sXr0a27Ztw1tvvSXVzty5c9G/f39hOZNgNRGUXHVHrfHrhpwaTrm2T/SqS66qYjUpU9n2eCWsIl9Z8TpfAxXh2q+5imi90sYyknXbKMAJjcceJ7+kCPlFcsVV8vM6X8MBAwYk3V9dXY358+cn3VdXV4dZs2bh5ZdfRmGh+BLGRYsWYfXq1aitrRU+nwSrAZIrow8GUsOm5coSj6pQ81v5zm8rEItUE2H1UVW+MuJlSVdGuE7ZekW1oqLVLVnZ8ViCn7q6OpSVlcV/d4tet27digMHDuDcc8+N39fe3o4NGzbgoYceQktLC/Ly3LNu9957LxYtWoRXXnnFd2KUGyRYRUTkGpRYAbNy9T5ePTUchFxFxSoiVV6B6r4Or5BV5ev2HOmUbuJr5Sdb3qiWJVpWNOtMGZuSbLx9ShULU1ZWliRYN7773e/inXfeSbrvuuuuw9ChQzF37lxPuf7rv/4r7r77brz00ks477zzpPpHglXAtFzDEivAlqvJ1DALU3KVFasumerAry88AvZ6vH7i1SFdN+H6yZYnqvUTrWg0q1Oy8fayPFVsmtLSUgwbNizpvpKSEpx44onx+6dMmYLy8nLU1NQAABYvXow777wTq1atwqBBg7Bv3z4AQNeuXdG1a1futo3OIt6wYQMqKyvRv39/5OTkYO3atSabCxSSa+LxenbJ4Zk17IVTrm4zWXnlWnCswVM2+a0N8Rsv+c1Htd9ESey36GOwnw/njYXojGa/mct+s5O9ZiO7zT52m3XsfK+xZhm7FaWI/+xRjMLtf8qtCAXNKg6H3bt34/PPP4//vnTpUrS2tuLHP/4x+vXrF7/de++9Qtc1GsE2NDTgrLPOwvXXX48f/ehHJpuKJFETK6BfrtztGk4N++H84PYSqxc8MpIRnyx+bbUV8n3L9npcshEvK9p1PudeUW7iayUa2Xqlj4vyj7lOhnJGs0FEspQqDp/a2lrm77t27dLSjlHBTpw4ERMnTjTZRCjwRK+mNkV3ErZcTaSGVcdd/SJXEbmyxBqkUEVh9Y1HvrLiFZEuj3B5ZcsjWp60sTNl7DYuqyLZeF8oVZwVRGoMtqWlBS0txz8cnWucooBuuUZBrIBZuYpGryyCkqsOseY2BztG21HIN9FJRb5uz4uodHmEKypbUdGqRLMsyfrhNh5Ls4ozl0gJtqamBgsWLAi7G55EQa6iRSOClKvr+RpTw7rlKiJWHqkGLVSR9lXkq1u6ic+7qmxFRMsTzapKVnTSkw2lijOTSAl23rx5mDNnTvz3+vr6lIXEYeEn13QUK6B3zJVnj1cWfqnhpL8FJFc/sUpJtUlRxEXia2RV5KtDul7C5YluWbIVES1PNBuUZOPX40wVZyK5JcXILZLL4OXm8n3BD5tICdarzFXY6JJrEGIFzMvVVCF/FqxJTapyFY1auaWqKlKV6wpI2O3x6JaujHBZslUVLSuadRuX1SVZG79UcbwtimLTmkgJNh0xJdewxArokWuQqeFEdMhVWqymhCoDqy8c8tUhXV7h+slWl2hVolldkuVNFdOEp8zAqGCPHj2KnTt3xn//9NNPsX37dvTo0QMDBw402bQ2WNErj1yjJFYgHLmKIpsaNiVXplhFpdpoQMLFgiljrz77iFdUurzC9ZMtK6oVES1vNKtTsm6IpoppwlP6YlSwW7ZswcUXXxz/3R5fnTp1KlasWGGyaS0EKdewxQqYk6tKQQmR1HDS3wTlKhy18ojVhExl2uEVsNtjEpSuqnB5ZSsiWp5oVlayfviNx/KmiuN9oSg2rTAq2HHjxsGyxLchizp+cjUpVtE9W3nrCYvKlbt9Q6lh1rirDrlKiTUooYri1S8e8QpKV1a4orIVEa1XNKtDsrrHY51QFJve0BisB17Rqy65poNYO6/jLleZcVc/RFLDibC2nNMmV01i7TAs4VyRdLGseJ3PhQbh8spWRLR+0awzZewclzUlWRtWqpgmPGUGJFgXZOSabmIF5KNW2XFXE6lh1rircbn6yNK0TEXb5Jav8xqGhOsnW1XR6ohmdUrWhjeKZU14ItIDEqwDU3LVXXkp5fqaxNp5LXW5BpUaToRVUN5PrrrEGoZUefHqm6943c5jncMpXD/ZyopWNpo1JVkbv1nFNm4Tno7/jaLYdIIEy4GKXNNJrJ3XC1euTnhTwzyFJGyk5apJrB0NhtPEJWKzit36LixdXuH6yJYlWiBVtm6iFYlmZSUrAm+qONui2NyiEuQWSxaaABWaSDtEtqAD9MnVZBoYMCNWgE+uosimhhNhpYZ1y9VPrKZlKtomr3ydj0tIuAqylY1q81sbpKJZWcmaThVTFJsZkGB98IpeWXLlEavpaBXgL3VoUq66olddqeFEuOQqIdYwpMqLW994pCskXN7ollO2XqJViWbDkKyN7ISnTIxiMx0S7Ne4Ra8m5BqFaPX4tdlplqDlmhi96pg1zLvWNQ6HXHWJte2o2cgjvyt/NkZGutLC9ZOtgGhVollRySYiKtn4eS6pYtFlO/FrURSbFpBgoUeuOsUqKlUgGLEC8nL1Q0dBCaVxVwW58ojVtFB52+MVr/MxiQiXS7aGResVzcpK1rlONhHnBgFOeFPFFMVmHiRYAWTkqqs+sOu1RXe74SgYYUquQUxsSkRo3FVSrn5iDVqqPLj1iUe6IsLlkq1fVCspWr9o1k2ywPHJT7yS9Zr0pJoqjv+NotiMIOsFyxu9mpKryRRw5/X5ZtuJihXQJ1dWalhmYpPQuKsBuYqK9dgRvWO2XUrFZhE7+ysqXG2ylRAtbzQrMi4rI1nZVLENRbGZSdYL1okOueoWq6hUO6+vLlYgWLk6MZEaTkKzXHnEqlumIm3wildUuNpkKyFa3miWd5axjVsNYxseybohOuGJJ4qN94mi2EiS1YJ1Rq+8clWJWnWVMHS/tlgRcmb7jMpMsnJNOUdyGzotqWEJucqKNQip8uDWDx7pighXVLY6RcsjWcB7XJY1Jsua9OSGShTrhlcUSzWKo01WC9YPEbnqEKup9G/8eI5N0f1KHqrIVdc2dIlIp4Z90CFXWbG2CkYiBYLrtxNx9lFUuKqyVRItRzQrOi7LK1nRVLGNySiWiB5ZK1ie6NWJjFxV9l91v554BRMesQLiUSsgL1dd29B5oZIa5pGrDrGKilT2OiICFhWuqGy1ipYzmg1TsjY6otj4MR5RbNqliYuLgWLxbTo7yfU/JAJkrWD9cEavonLVKVYTkWq8HxIRa/xcTXI1seY1EZHUsIpcecSqS6oiuLXJK93Ex6RDtn5Rra9oBaJZUckm4la/WAaVKDb+N47qTkQ0SY+vAZrxi155d8aRkWtRcT536UL7xkNxUU78xkNRYU4k5ap7YhMzNRyQXFuPNMZvUSGxT7z9OnakIX7zo+1oo+/YdEdDg2fqvaOxwX3dcWODe3Utl/KWztc+v/loSmYj8YuZ8z2V+H5LmgOQ8B5NfP8mzYZ3ydAk/s/Y/1uuS9++/p/n+ZywP6vszzDRcq+EWbI+guWRq1v06iZXP7H6oXOSkmsfOLaUA8TFCoiPubohsol6IqyJTUkw9nTlKdbvJgw/sYrSclhtQlSsm9gSHRtnX/0iXN7IViSq9YpouaNZl5Sx2+QnFrwzi0XWx/pNeLIRiWLd9oslokfWCVb0G55TrqJRq8rWcCnHhiRVgF2ZiVeuoaaGnQgW6TclV1Wh8l5PVLyJ/dctW5ZohdLGrLFZhmT9lvCwxmNF4J3wJLoulkgfsjJFbOMXvfLuhuMmV79UME/6NzHtK5r65UkBA53/5LJyLYm1a5NroBObBFPDInLlSbm2HG6I34IisU3RtkVSyTwpZFb62C9t7ApHytgtXZz0u+OLWuKXOJVUsRusL6tcM/2//pJvfz5RmtifpUuXYvjw4SgrK0NZWRkqKirwl7/8hXnOoUOHUFVVhX79+iEWi+Eb3/gG1q1bJ9RuVkWwrDcej1yd0ato1KpaqtC1Lc4INakNzi3lRKNWQI9cjU9sSoB3OU4iLLmyCFKoPDj7wxPl8ka29nPkF9GKpo2Z0azmSDYRr0pPfvWK/aJYG7coNv43WrKjzEknnYRFixbhtNNOg2VZ+Pd//3f84Ac/wNtvv41vfetbKce3trbikksuQe/evfHss8+ivLwcn332Gbp37y7UblYJNhGeZTnJx/vL1S9i9fybxlm/nm1okCogJlZAXa6mJzb54Yy0ZOQqK9bmw+JjbIXdZJc9JPdTRLYqolVJG5uWLGs81g+/DdrtsVjWjGKeJTvx66X7kh3DVFZWJv1+9913Y+nSpdi8ebOrYJ944gl8+eWX2LhxI7p06XwdBw0aJNxuVqeIbfyiVxW5slLBvKlfkZRv/Npfp355UsBA5z+8X8SqW65+yO7zmoRC9MpbU9hLriKp2ObDTSk3GdyuI3MtkVQyT/rYL3XslzZ2vd9rlrETwXRxIiqp4vh9Cf8HrOpmXEM6X3/2ONPE2Up9fX3SraXF/zOmvb0dq1evRkNDAyoqKlyPef7551FRUYGqqir06dMHw4YNw8KFC9HezveFxyZrItjE9DAretUlV5WIVTRK5Y1Ok9rg3E7Or9whT0oYcP/gkU0NO9ERvcqOu7Lk6oesRGVwtiUS6dqPxS+q1RXRukWzrJSxjkg2EVaqOBFWvWLAP4q1cYti43/L5MlOhSVAkeQXhI7O2HDAgAFJd1dXV2P+/Pmup7zzzjuoqKhAc3MzunbtijVr1uCb3/ym67GffPIJ/vrXv+Kaa67BunXrsHPnTvz85z/HsWPHUF1dzd3NrBGsF6w1r7rlKrNjjet1JIQK8EsVkBMroE+uQUevfuiUa5Bi5ekDr2x5U8iqomWljd1SxtySZcCbKvaaVSwyFmvDqu7EWrLjJGMqO0lQV1eHsrKy+O+xmHe96NNPPx3bt2/H4cOH8eyzz2Lq1Kl47bXXXCXb0dGB3r1745FHHkFeXh5GjBiBPXv24J577iHBOpGNXpP+xiFXU2I1GaEm4idVgL221ZRcw45edck1CmJ1Q0W2OkQrE81KSVZwPDYRL8nKRLG81Z1SruWY7ESVnRCfFcxDQUEBTj31VADAiBEj8NZbb+GBBx7AsmXLUo7t168funTpgry846/TGWecgX379qG1tRUFBXybtmSFYL1IjF5517vG/84hVxWxikpVRqgAn1QBcbEC6mlhIFWuQRWVYBGUXJsOye/5WdSdrxqZE1HZ6hBtlCSbCG+q2EZXFGsjM9mJ4Kejo8NzzHbs2LFYtWoVOjo6kJvb+fp8+OGH6NevH7dcAZrk5IpfalhFrqzJSjKTkvwmJyViT1RKvLEozD8Wv7n2If+YklzdkE0NBxm9uqFLrk2HmuM3FRKvI3stkQlSPBOiWBOhWJOgRCY/cU18Ykx6Up3w5Ibb/4jqZKf4sbQmlot58+Zhw4YN2LVrF9555x3MmzcPtbW1uOaaawAAU6ZMwbx58+LH33zzzfjyyy8xa9YsfPjhh3jhhRewcOFCVFVVCbWb8RGsV3qYFb0mokuuMjvVJJ1vKOXrhKe8IWshvddMYTe56koNpxBw9KoqV1WZ8uBsQyTCtR8Db0RrIppVjmQFSEwVBxnFikx2ojWxYhw4cABTpkzB559/jm7dumH48OF46aWXcMkllwAAdu/eHY9Ugc7JUy+99BJ++ctfYvjw4SgvL8esWbMwd+5coXYzXrCiJEavonIVEatKaUI3ZGQKiNUL9qtQY1KuUY5evfCTaxBi5WmbV7a8ouVNGwcqWU2pYtNjsU5EJjsR3jz++OPMv9fW1qbcV1FRgc2bNyu1mzUpYp7olTXuqkuurBQwb8pXNNWbSGLalzdaZaWCgU6xeqWEZeTqRzpEr1GWqxPRNDJv6lg1ZeyG6FrZJHxSxYkw32M+8AyFeMHaZccLShNHl4wWrMobKzF6FZWr1zirn1hZ6JApb7TKI1XAW6yA94cMj1yDiF6dyESvmSDXRETHbHlE6zc2yypSISpZJ6JfqFjvJa9t7fy+HPoVnrDhyVg5t7Hz23OaCJ+sSxHzRK+sNy6PXFPOYYjVC1GRquAn0qS2fKox8YoVkJOrbPTqhCviSYB3dxyWcGTF2vSl+Azkoh5qFX7svvKkj5sPN3GljWVSxiLpYh2p4kRYy3bc8KpRbCOaJpZZE5tOdBQWo6NQLgjqaJcrGRs0WSFY0brDSecmRK+65KoqVhWhisg03h5HiUPmbjiScvWDGb06EIlmVKJXXchIlXW+rHCbDjVzSxZgj8+GJdkUGEUoZMZi/eCd7GTDsyaWSA8yNkXslx7miV6Zxft95Oo21uqVCvZL/6qmeXlTvkltfp3+5YlYTclVKHp1olgWMZEgo9emL5uU5cq6rsy1RdPGLGTHZUXSxc7X1/fLleJYrMiSHRYiExudaWIah40mGStYN1hlEf1IjF555JrSNkOsbshORBIVKZAsUx6pAnxiNSnXlOjV4OQmJ6LRq4hcg0BFtDwELVkeUt4DjPeESGaEhdv/h+iaWBv7M4dny0siOmS8YP3SwzzRK+tN7SdXt6iVR6ye7WmKSkVkChwXqqxYAXm5CqMgVNkPcS+p8EjJVNRqol3eaFZVsl64vT48UawvnFGs6clONjKziYnokZGCFUkPi5IYvfLI1YmMWEVlqiJSG16hxo/3EauKXFWiVyem0sOyhCFWtz7IiNYPFcmKPu88M4uDimKDShPb8KaJieDJSMG64Zce5oleWbWF/eTqFbV6iVV0qYwukfIKFTguVdYHitc3e94JTSrrEYFg0sOy0WsU5JqIqGjDkixvliHoKNYNnWliG+dyHV5oHDZ4Mlqwbt/ceAtL+F47IXrlkasTP7F6IStTFZHGr5EgVL9v6V5RK+D9ocSTGvaNXjULNRtJB8m6EXYUK5Mm5sH+rPHbR5qIHlmxTMcP0ehVRa4i+6jGzxEUqS5EU11+HzDM2sIyqWFFdJdGFCFq0auTpi+buJf28Czl8Vsr67eExwlrB55EuJbtJMJYFyuCX+lEG1quk9lknGDd0iBu6WG/6JVHrinXlJCryG40TnTIVGW8COAvcygatXKlhn2iV2e0Yqq4hBsmqzU1/MP/dS85yXvjaV7sLwE8otUhWS9E1sd61SvWgdcmAH5rYnmLTsT/xtjCzg97j1jnJuxEOGScYFn4TW4SHdNIjF5F5SorVhmpqko05XoCtYNFo1bAXa66o1ddSO3zKhm98ojV7VhV2fJGs7xFKbwQjWJ5cUaxvtWdEmAVnnAjcQMAUXiK/9uI7q5TVFKMpoZGFJYWo9nwxD1e2mIlaBN4bpPObUuPyD5jBcs7c86tLKJoaliHXFliFZl0pBPRIvw2PBOYlOUqMHNYF6arN7EQkavXuTqiWj/8JKs7ijWCwTSxaFUnm0wvm5ipZKxgbXjTw6LRqxe65Mq7NEYFWYG6wT0rmDGRSWnGsOb0cJRQkavzOrKSFRmT9YMlWR1jsTxpYtU9Y4OCxmHTm4yaRSw6Dd1vNwrR6FVUrm4zgXkLOfDI1Z7J63VToeBYQ9LNj/zWBim5mopew5zgJIIuueq4Hm9q29T4s8qYuO8XLM7ZxKaX68T/JrEelogeGSVYFrzFJdyqNpmSqxPWTjQ86011CtTGKVJeodr4iRXQIFdamiOEbmnLwBq7Fk3F81Z3EkLhS5zK/57Ielgb0brERHBkZIqY9UbiTQ+rrDkTlavIFm9Jf1f4RxbduUYE3lKHrJSwyqQm3cUldCIywcmkCGXTxUFNeMoUeMdhRbDHYe2JTqJEaaJTppORgrVhVW/ym9zkeg5H9KpDrjKVkdwwKdFERGsH+421esqVoletqIzJhoXKZCff2cQhIjLRiUgfMlqwNiq1h/2KbbNSOqJyFSmS7yQKEanvdTgmMQnJlROZCU6maxCnM7omPOmc7KQFzuU6OtfD8kATndKXjBGsbJ1N3vQwa1lOvA8JQtUhV5XKSH7okiZXW5yzg4XTwi7Ra5TTw0Bn0YaoV3HSRZBp4qCLTujCVMEJIhpkjGBtRMdfbfwmN7nhlRo2KVfRCUZhILrcxlesIax5LSgtzoooNh3TxIGhsB5WpeBEttBWUBKP/sXP1dwZQ2ScYHlgLc+RjV69EJWrrFijGJH6wRWxeslVIVJVnmEaECUnxSIx45fQD2uik0hFJxtnRSevkolRrOiUyWSsYP22pwPUikvwRK865CpTapAHXZKUgTsVLBi5hpEeLuxWJFUukYgGQUx04i38L4LqTGIiGDJWsDY8E5x408Mqi791ylXHMpigER5fZclVQKQ6KzjFupVoKZcoMg5rOopNx/SwzpnEUYJmEmceGS9YG569X/3Swzai0auoXGXFGhWhKhXmD2G81QRF3QuN7qhDGIIxkzgRr5nEBJFIRkxRE5lB7Fce0QuR6JVZuF9CrqxqSPnNR+M3GXKbG7TfpOGRa8RnCZsgHaPMbEWmZCIPbl/0CX6WLl2K4cOHo6ysDGVlZaioqMBf/vIX5jnPPPMMhg4disLCQpx55plYt26dcLsZIVgbkVJgrPFXv9nDNqyZwzaJ/1CycnWDV6rGZKiTpgZluYa5PMdrLSdriYroOlITkk1XcQe2q44DU/8vVJPYPCeddBIWLVqErVu3YsuWLfjOd76DH/zgB3jvvfdcj9+4cSOuuuoqTJ8+HW+//TYmTZqESZMm4d133xVqN6MEa8MzwcmGVb3JLz3sBis1nIisXHnEGjmBumFLlTclHJHIVWfxgzAlq3It3n5TqUQiKlRWVuJ73/seTjvtNHzjG9/A3Xffja5du2Lz5s2uxz/wwAOYMGECfvWrX+GMM87AXXfdhXPPPRcPPfSQULsZKVgbkQpOrNrDft8iWd9AbRKjVxW5ehFZqSaKVFSqNgHI1VmkANATKemWTMlJMSU5qp5P8KNzO0gZvIr+Zzvt7e1YvXo1GhoaUFFR4XrMpk2bMH78+KT7LrvsMmzatEmorayY5MQzwSl+rER62A1WajgRHrlqK4qfjhOIOOQqmh7O71qsfS2s7HId2cpOiZLkmWWsS6q69oQFvFPrhJ61sJ7HZdBa2Pr6+qTfY7EYYjH39/o777yDiooKNDc3o2vXrlizZg2++c1vuh67b98+9OnTJ+m+Pn36YN++fUL9ywrB2shOcLJxSw+z1r264fetlleuSkUa0oWIpIWdiC7X8ZtRrFo+MYoRqWrkbqoOcVSX6KiQrmthj3UpZtZuZp/bOXw3YMCApPurq6sxf/5813NOP/10bN++HYcPH8azzz6LqVOn4rXXXvOUrA6ySrA2PAUmdM3aE4leeeQaxbKC2hFZ52pYwiIlE1WKTqRDjWKd0atu3FL8ROZTV1eHsrKy+O9e0SsAFBQU4NRTTwUAjBgxAm+99RYeeOABLFu2LOXYvn37Yv/+/Un37d+/H3379hXqX0aPwfrhtz0d4D7+6pYe5pnclBi9aper7NimzM0Epq/PgciHtFeEJTOjOH5MhAUm0jeexyqbHg5rBrEJeDJeLFT2rM4U7GU39o0lWCcdHR1oaXF/DSoqKrB+/fqk+15++WXPMVsv0j6Cld1FJxHZNyrP5CYelOQaxizciKZuTaGr8D9P8YkoRrJBi19XephnJ52UMokR2R+W0Mu8efMwceJEDBw4EEeOHMGqVatQW1uLl156CQAwZcoUlJeXo6amBgAwa9YsXHTRRfj973+Pyy+/HKtXr8aWLVvwyCOPCLWb9oK1EVkD63kNxgQnv+U5Nl6Tm1jRqx+ucvUTaxZIMOyt6bzGYlmpYl7JAoiEaEXlajJ6JQhZDhw4gClTpuDzzz9Ht27dMHz4cLz00ku45JJLAAC7d+9Gbu7xhO6YMWOwatUq3HHHHbj99ttx2mmnYe3atRg2bJhQuxkjWBt7KrrKJuus8Ve/9LAoftGrsFyzQKw68JpJ3KW0BMeOpD6HolGsqmSB8KPZMOTKil690sNBjb/aG66HDdUjFufxxx9n/r22tjblvsmTJ2Py5MlK7WacYJ2ILNHRiUz0qiRXCbGKRoCmdx0RIezo1YY1o1iXZIFgo1mZlHDUikq4pYczcQYxEW0yXrA2Mkt0WAUm3MZfReuMCm83pyBXHUJiXSNI+ZqWq2gUa1qyQDCilR1r5ZWrieiVIKJM1gjWRmYPWN7xVxV8o1dJuQYV6Xm1o1u8Oh+PTMEJE5IFICxaQI9sVScwBSFXFirpYd/3ZpH33+2ddAiCRdYJ1oZniQ4PfuOvXulhVvTKXZ0posXvE3H2Q0W4Mo8pt6REak9YryiWhaxkAbnt7dzkyJKu7tnAuuTqh+jYq3R6WPK96bVVXUs+O+pubo9egZAgackrRoHPc+R9bnpsgpC1grURWaLjVx7RhlVcwg3fXXHcolcP2URFrF7IRLomHxMripWZ8KQqWYA/mnW9RgBLakTGW3nkmkmpYdnKRERmkvWCteGtQWwartSwolxlIrpETEwWCfOLQZQkC+gRrQlEJzKZlKtI9OqGaCYlKjOIifQiqys5ucFTIlFmgpNXelh4o3RJuXY0NMRvqiReS8f1TGNq9ihLACxx8KZMi7oXRmZ2btBy1YlUepgx/koQvFAEaxDl7ao4qzSx5BqEAJ1tpONyCJkoFlCLZAFw1S4OK6KVkTvvlwc/uZqMXgkiKAKJYJcsWYJBgwahsLAQo0ePxptvvhlEs0r47QFrAt/JTS4iDVuuXu1GLbLlkT7rA5o1W1U2kgU6hSQa0ZqMalXaiKJc3V531ZntKjOIWyz1iU1UZCJ9MC7Yp59+GnPmzEF1dTW2bduGs846C5dddhkOHDhgumnjuM0gFp3g5Ikzek0TuTr7EIV+2IQpWR7RipAoQhXp6rgG75cEnudBRq5ecGdSfNLDrPFXrxnEqojuBUtEE+Mp4vvuuw833HADrrvuOgDAww8/jBdeeAFPPPEEbrvtNtPNRw6l8VdORKTGuw5UJf1m9ycKqWOeZTsq6WIAUiljQCxt7EbQ47UiXwp4xltl5Sry3jRZECVxBnHiEp2WHPbz1NTWxVifiHAxKtjW1lZs3boV8+bNi9+Xm5uL8ePHY9OmTSnHt7S0JG0f5NytPgx0FJngKe7Pvfb1a7yiVx65ihZXcDtHRrhREa0OyQKQHpcFwCVaQF62JhGNtlWiVkBOrtypYUHhUoEJQgSjgv3iiy/Q3t6OPn36JN3fp08f7NixI+X4mpoaLFiwwGSX0gOO9LAbftKQESvPtURl29HQkPaSBdSjWYAtWkA9qtWJbrECwcmVG4H0MKFGa06hb3TvfW6b5t6YIVLLdObNm4fDhw/Hb3V1dWF3iQu3JTrKM4gZuEWvQcrV7dqi14/C2KzqmCzgPy7oJxCecUng+DinyKQoHci0yfuYgpSrjujVicr4K28Vp6ZW74/oxiaa7BR1jEawPXv2RF5eHvbv3590//79+9G3b9+U42OxmNCO9AQfJuXqbEckmk2nSBbwfh55UsaAdzQL8Ee0Nk7h6YpwVeTNu66VpzqTrjFXQECuPtErKz3sNf6aiN8M4mYai804jAq2oKAAI0aMwPr16zFp0iQAQEdHB9avX48ZM2aYbFo7vGUSeeGe4OSIVkWj16Dk6myP90MwKpK1+8JCJWUM8O0pKypamzA3MRcpGKEStQLs91XY7yM3ZFOgRGZgfBbxnDlzMHXqVJx33nkYNWoU7r//fjQ0NMRnFRPiE5x4CVquzrbTSbJAdKJZIFlaorINCp1iBczI1VT0qmt5jo4ZxI2N5nf7IuQwLtgrr7wSBw8exJ133ol9+/bh7LPPxosvvpgy8SkbEN7/Nc0RTRlHAZ3RLKAuWkA+qjWBaHlD3mL9UZKrKLoL/LutgW1siUatdEKMQEolzpgxI+1SwqHBWR7RxksEItEr77ZsMntv8ko2KlGsDY9o/aJZgF+0gFhUCwQnXJmawWGKFVCb1KQSvXqtf00cfzW1TV1TY3rMrM0mqBZxFiO636l9vMom16Zx+2BV2aknKNECYlEt4C4+VemqFuDXJVZAs1y9iFj06geVSUwvSLBpBK8oeKJXUbk6zxWRbBBRLOtD1fk32Y3bgWBFC/DL1iaoHWqciOzbqhK1ApJy5UwN64peRXGbQcxaosOisbFVuh+EXkiwnDS3ddE+kzgsVOTqvEYUolnR8neJx4vKNkjRAmqyNY3oZuiqUSsQrFz9YEWvPOlhKpGY+ZBgiUAwNeFJtbasrGyDFi0QDdmKShUIUayAklxNzRxmwVvkn6fIRFNDtCPZFiuGLpK7C7VY0X5sNiTYLENH9Oq8XlhRrO7C7TKy1S1aQFy2NiakKyNUG973RdhydcNPrs7oVSU97AfNIE5fSLA+NLTkaSn4b4IolBsEwpGsyV1RnNfnka0u0QLisrVRkaEuRN4HKmIFBFPCgKdcRSo28SCaHlap4MSzBrbxSPh1rLMVEqwGWqyYaz1iJ20FJVm3FjaRdFwXC4jJVkS0gDnZBo1OsQKao1aAW65uhBG9uk1wohnE6QcJ1oOm1lwUFXSE3Y20Icgo1nT0ytM2r2gBPVEtEC3ZyrzWqmIFzMtVdNzVKVev6JUHlU3WedbANh1tlr4+IUekdtOJArrGO0yOydhEqTBDUIQp10Ryi0viN99jS0p8X6v8rsXxGw9dSktSbiaRbYv3cfk9R77PtQG5uiG77lU2Pez2eaS6i05TQ7RmowdBTU0NRo4cidLSUvTu3RuTJk3CBx98wH3+6tWrkZOTE6+pz0vaR7DNRxpRWFqMpoZGFJWIS62xyUJxUQ6ami0UFYrJtbk9hsI8/9SwG22FXfkL/mcJRr8w8IpZZo2soagWEKvI5Sc+v6hXp6R5vyjwvOZSYgWU5SqaGo5CYX9aA+vOa6+9hqqqKowcORJtbW24/fbbcemll+L9999Hic97cNeuXbj11ltxwQUXCLeb9oJ10nS0GUVdC9F4pAnFpUVoamhFUUkBGhtbUVxcgKbGNhQV56OxsR3FxfIpGZ10FJYcL/hfVOJZLjG3uESpKlG6Ixy9ykS7bufwzijWPFYLyMvWDdNRrsj4urJYAeGoFZCXqx9OuYqWRkxMD/OOv7ImOPEs0WmO2Lpqk7z44otJv69YsQK9e/fG1q1bceGFF3qe197ejmuuuQYLFizA66+/jkOHDgm1m3GCDYKmti4oypCiExmJ7jRy4vU0y5Y3qgVSBRbmbkk2wnuzmhQrIDyZiVeuIhObWGOvumYPE53U19cn/c67p/jhw4cBAD169GAe99vf/ha9e/fG9OnT8frrrwv3jwSrmZacIsSs5GnxrV1KUHAseyNPHXBHr6bHaJ3X51nCozmFbOMmN9PSlZ0FrkWsQCTlykoNqxT25x1/ZU1wivISneaOAuRLPj/NHZ1DcwMGDEi6v7q6GvPnz2ee29HRgdmzZ2Ps2LEYNmyY53FvvPEGHn/8cWzfvl2qjwAJVohMKpcYBkY3yw5r8pNAdCuTQgbE1juznmNe+epaSiXympqIWoFgI1dALnr1Sw8T3tTV1aGsrCz+O0/0WlVVhXfffRdvvPGG5zFHjhzBtddei0cffRQ9e/aU7h8JlgOeYhPG1sIWl0hNvPGiS2mJkSUeJsf3lD58gyRisnUS1BrkwMQKBCpXN0xFr4nwjr+yJjhl6hKdsrKyJMH6MWPGDPz5z3/Ghg0bcNJJJ3ke9/HHH2PXrl2orKyM39fR0blsMz8/Hx988AGGDBni2x4JloHqWtiW/GLE2ryjBs+ZxAITnXJLSlI+dP02A88oZOQqs0WZ4D69QcgWiEY1L9Hsg3IqGNAmVoBfrn6pYdWx18Tolcoj6sWyLMycORNr1qxBbW0tBg8ezDx+6NCheOedd5Luu+OOO3DkyBE88MADKalpL0iwCdhLdRpbclAc41trprJUJ5GkmcSGMRXFsjCyt2eA+366ns8rXUOyBdyfO9PSNbGlYBIZIFfe6FWkuATv+CtrBnE2roEFOtPCq1atwnPPPYfS0lLs27cPANCtWzcUFXW+llOmTEF5eTlqampQWFiYMj7bvXt3AGCO2zrJSMGKLtWx18IKtcGYSRyFiU5BRrGm0sNaikqoilXk2jzCNSjb+Hk+AuQRsM41yWGKFdAvVz+cclWZOUzlEfWwdOlSAMC4ceOS7l++fDmmTZsGANi9ezdyc/WOgWeEYFWLTQi1pWGik+5xWLc0sR+6olhVuUp/kCt8GBsjsU2DsgXkNo2PXyuACmBCX44UX0vRqBVQk6tsatiJ1+Qmv/Qw7/grawZxNq2BBTpTxH7U1tYy/75ixQrhdjNCsEEgO9FJZBxWd8EJvyhWVbK6tiNzQyk1HIZc/frgJ1zBtbY6hasDI0VAJMUKiEWtgD65slLDSrvmKJRHzNQJTukACdYHnolOusZhVZCJYgF5yeqQq1QkpVmuPLupuCE8Xi4S3SoWtgDMC1c6fc97XgbIVTV69UsPi46/EsFDgnUgM9HJDe3jsI40sa4oFjguSx7RBrFjjvA+n4CQWGWl6ncNbukali3gL0CuCVQ6lz+FKFZAv1xF0VW1iWf/Vy+iNsGpua0L8iSfl3SpgpW1gjU90cmPxHFYmTSxG15RLO+EJ93ylIleTclVh1RF2+ASrqxsAaX10YHsSqRxlrff66cjagX45Rpk9OqXHhYdfyWCI+PKhtjf0uxxB/uNZqdOVHabsP8xWN+e3CY8aNu6zvGBFZWt29wwWrUpkYjI1atd+8ZFUcnxGw/FJcm3KCDaH5/H6/f8tRV2jbxcvao2qcCz/6sX2TbBKUwyJoK1ZxKbQHYcVkuaOOAoVgfS9WpFo1fFqMcP5we3yvaCwtGt6IxkQGknIGkMFvrQnQ4GwpWrE56Zw4nRq1962G38lSY4hUvGCFYnIuOwxtPETjjGYsOULM/G2q73a5SrqFh5NtrmOU5EwIl9FJItIFZViiVAXvnqio41iBXQN9YKeGeXZOTqB2/0KrL2lfZ/jTYkWEBqHJa1HlZmuQ4TwSgWYEsWMLPrSjrJlVeqIshGvEKyBeSiWzeCSCtrnHwWRNQKyMtVd/Tqea5Petht/DVqE5yyhYwbg2XhHIeVGcdgfQt1+6dz+2dN/IdP/GBI/ABhfthoGIvVWfg9v2txWsjVHq8zIVe/9njbVBq3jcL6X0C4PyrjrEDwcnXDT668O+Z4TW6SSQ8T4ZOREaxd0clZMlEGO03MGoflTRNrjWIVUsU2qtEsr6SFJzVplmtQQvVDNMIVjmwBtZrJskiKnedLhG6xAmLLcNzkKjruyvpSrlLU3y897Db+ShOcgiWjBKtjopOdJrbHYZntCaaJE0mc7CQ1FuuCjGSBZFHyyFYk+pUu5O9EcDNtG1G5sj60/RAqf4nkvonIFhAsdOElQFHxaoiQdaXwTUetgJxcnTjlqhq9yqSHifDIKMHK4FwPywOrbCLvbGIpfKJYwFuyAF+Rd52pYym5ut0vIVfuiUsKQuW5Fq90RWQLSEa3TgJMKYcpViA4uYoUQNC1JZ1fepjGX8Mj6wTr3FmHB9k0sd9kJ6koVlKygHw5RVH8UsJRkKtOsYq0wyNcFdkCCsLVjMhsbtXXTJdcvcZbZeRqMnqVSQ9HDarklMboGIeVTRPrjmJ9U8WCkgXM7RmqdW9XQblGSaw87ZuQLRCecGXWHUdFrECwchWpOcyLX3qYxl+DJ+MEqzIOK7Jcxy1NbCqKTYFz2Q6rXrFO0fJMYgpbrjJiZX14O5GpMS0a3crIFvB+zlTFq1LIQ8eXoaBTwoB+uToRjV5p9nC0yTjBiuDcgJ15LCNNzLtHrGgUq5oqBvw3BUiUo4hsRWYG61qKo2vfTzdEZCpyvoh4RaJbHVWmwighGZZYgWDkKorpDdVp/DVcskqwdprYHoflgZUm5p3sJBvFOuGSLOCaLgb8d1DRvRG31J6umuTKI1ZVqfLgbINXuEGkkoNCZCZ3usvVRPTKQ2J6OB3GX7OFjC404Sz8z4P9xmbtYMGcrODzjTbxHz3xA4Gn+ATgIho3IXnIK6jNAXKLS4zLVabIu01rl5JA5MpqW6QPbQUl8RvX8RIFLnQj2r7f4/N7vlgpYa/JTGHLlXfHHB3pYRp/DYeMjGBFxmFl0sSubfpMdvJbF8vCOR7rG8kCzJQxYGZDbl+BC245pztqVZEqKzqSLh6C5D7xRLeikS3g/nzpjnJlRa6aadAVtQLhydWJyp6vSW1Qejh0MlKwLETSxKyiE/ZYLO9kp0QSx2J5U8XMSU+AkGSBZBmqyJY7Kg4xJSwiVpmtBXXJNwjZxs8V3LhAdySsI4WfLnL1QzV6pfRwdMkawdrLdZjHcBSd0BXFek14kh6PBbwlCzB3TvGSZErBCpkUs8RG6brkyitWbfv1clybV7hBytb1eoZSyzomncmIFQhGrm6EEb0mQunh8MhYwdppYns9LAueohMqUazbuthEWDWKWUt3bBH5posBLtE6URqz9TtXcLzVDZWo1aRURdrlEW7YslVFZImUiagV4J/MBKjJVTQ1bCp6TYf0cGNLHtBFbgP6Rk0b15smoyc5eWG/KVmTBFiTnVgzARP/Ed3+URP/0XkmPAHsSU+Ax8QnrzJ4xSVmtynzu75H37x2VJGJWv2in7Dk6obdH94+iU7QSpwgFWSRDdE2eR6XbEo4XeQqUnOYSA8yNoJ1QyRN7Po3zihWNlXsNR4L+Beh8EwZA+yI1kZ2HJZX1hI74bjJVXdVH8/jGdEQL6KVuxL76BfZika1Nir1kkWvywPPlwW/107HeCtgVq5+sFLDVFgifclowfKkiXlqE7tVdnIbi1VNFQNikgXAnl1swxKtjamoVpNYAbmxVl6x6hAqzzV5pRuEbG3CKB+pY3xc13groFeurteXTA2z4EkP0/hruGRlihhg1+203+Bu3yrdJii4/YP5VXjxShU7YaWLAfd1sp4VeoLclJvRFquPuuTKk3a110iakKvONmVSyGGt8/WDt29+jznKclVJDadcy6eoPxFtsk6wrGnsrDcz71is6z9hwj9r4j85z3gsIC5ZgFO0OmWbeE3JqNUrJewmV9YHNa9Yw0ZUtrLjtVGQrUg/ZFPCQPrLlRW9ik5uouj1OBs2bEBlZSX69++PnJwcrF271veclStX4qyzzkJxcTH69euH66+/Hv/85z+F2s14wdpvMtasOp7JTknHS0SxQUhWWLRAqhh5pCt4jt0HXRWZZKNWGbHak2REb6LIypYXmQpSqoi2p/L6sZ73qMjVD6dcKXrVR0NDA8466ywsWbKE6/j//u//xpQpUzB9+nS89957eOaZZ/Dmm2/ihhtuEGo3o8dgvWBtYceq7CQzFps44cmrAAXPpCeAPSYbv8+jIIXrkh4vNEW2fsXkdYqVBbe0JMQoci3eSl6J/fUbsxUZq01Etkay6HV54PmiIBO1AvxrXAG9cnVDJTXsFb0SfEycOBETJ07kPn7Tpk0YNGgQfvGLXwAABg8ejJ/97GdYvHixULsZH8EmEmQU67cA3etbNSAeyfJGswA7mtQBz/WDSgfzRIQqUacoMm2ZTCEn4oxwZW+imJJrc3ssVLmaSg2n/I3Sw0aoqKhAXV0d1q1bB8uysH//fjz77LP43ve+J3SdrIhgWbWJdUexftvZec0qdtYqdkayAJJmFwPgimYB77qzbhIU2SNURNKyW8rJitWPIITK2z5PZCsS1QKp75mooSpWQM94KyBfoQmQk6vvNVlzQSh6TaK+vj7p91gshlhM/X977NixWLlyJa688ko0Nzejra0NlZWV3Clmm6yKYBNxm+zEG8Xa/zBJu2H4THgSHY8FUj9gZKJZQGxnk8QI1O/Gg98Yq2jBCFaE5hftqUardlTkdZNFtF9BRbUm4O1LFOUqsxzHDdPRa7rQdCwXTa2St2Odr8WAAQPQrVu3+K2mpkZL395//33MmjULd955J7Zu3YoXX3wRu3btwk033SR0nayIYBNxWxPLG8W61ShmFZ8A+MZjeSNZwH1cFkiNZgH3AgKm9w1V3VBbdksyFqJClZWl13l+a58TEYlsZaNaIPjIVkTwYcrVC9lJTaKpYR3Razalh+vq6lBWVhb/XUf0CgA1NTUYO3YsfvWrXwEAhg8fjpKSElxwwQX43e9+h379+nFdJ2sE65Ymdqvs5LbLjmqqWEayADw3BnBL/zknQAH+NWm9ZMgjXpli8CaqMMlOfklEJfqUuT6vcJ3vA+axXz8PJgpZyKK7epboZCZAXK5hTWrq/Lv3xKaUPtGuOQCAsrKyJMHqorGxEfn5yZ/5eXmd7w3L4k/5Z41gExGNYpPvY0exuiQLpM4uBiAczdqwotqUYzXupKKyR6tJsZqWKm/bPLI1KVrA/XmWka5KGjrd5Soz7ipSb5hZGIcmN/ly9OhR7Ny5M/77p59+iu3bt6NHjx4YOHAg5s2bhz179uDJJ58EAFRWVuKGG27A0qVLcdlll+Hzzz/H7NmzMWrUKPTv35+73awSrMko1kuynn2RkCzAH83asKJaQP9uK1HcjiyRMMXqhohsZdLHovWQ4+cHNGarOiEtXeQqmhqm6FUvW7ZswcUXXxz/fc6cOQCAqVOnYsWKFfj888+xe/fu+N+nTZuGI0eO4KGHHsItt9yC7t274zvf+Y7wMp2sEqwfMlGsl2RtvKJYQE2yQGo0C6RGHqyoFuATYrz+sWLN2iC3IktEVqpeH9I8uK139sPup86oVnScNkhMydXz+ADk6oaqXHmjV8KbcePGMVO7K1asSLlv5syZmDlzplK7WSvYxDSxTBTL2pQd4EsVA2zJAvAclwVSo1nAX7SAeFGBKO6UAugVq4pMea/HK10TogXUo1pd6Cj8wXpteSs0AfrlKjruKgoreqX0cPTIOsGy1sQC/lGsbKpYRrKAXDQLsNdBuolPRyUfkUIDURCrbqmKtMcjW5n0sYk1tboQ2uBAo1y9MC1XNyh6zS6yTrCJiESxsqliWckCEI5mAW/RAuyJK6br05pc+2jDI9agpeqFrGx1ihYIRra6xArIyVWlkAQvOsZdU853yJWi1/QjKwUrE8Um4pUq1ilZgC+aBdxFC7BlC5hdC6lrH9YoSdXtg7pQYqzVifMLFbMPhkQLpL4W0hOkJHcqCluuJic18SCymXomRK9NLTlAvtjG9EnnpgFZKdhEZKNYnZIF4LqEB3CXLABf0QL+0QlLgrzylZltqqOUoSmxihQf8DteVL6iotU9RptybpD75AYkV89rGJzUBKinhil6TU+yVrAiUaxfqpgFj2SB1HWyADxTxoCYaAG1qj860FUf2E+solIVFarKtXmFyytaU5OhgkT1NQ9zOQ6gZ9zV93yHXDMhes0WslawifhFsZ7ncUSxgJxkAfdoFuAXLeAv2/hxGsffdI65AfqjVZNS5W2XR7aZLtpMlKtIneH4MQITm5xQ9BptslqwOqJYHZIFwEwZA2CmjQHvD1ne4gRRSgcCeqUallBZuL2uXmSaaHWUsBTNVIQxqcn1PMXUMEWv6UVWCzYRryg2CMkC8tEs4B7RAmzZ2pj+gBUptB81qYp8KCe+ViKIRLUmRQsEI1vTcg1iUpMbMuOuqlD0Gn2yXrCJUaxbjWIWQUgWYEezgPcHL886StYHHteaSsV9VXWvWZURq47oxu0aotLljWpFRCuzk48J0er+ouV6XkCTmnTVGaboNfPJesF6wRPFppwjKVkAniljwD2aBfhFC8jt6GJiU3IT1ZVEpao7XcjbDq9wRUSrM5q10RXVyrx/ZCexRX3cVaWghBsUvaYHJFh4R7GiqWInvJIFxKNZwDu9yFPEwO2DTORD2A+ZKMTURKWghOqH22vIgke0JtLGifBkOHR9EQtCriroGnflgaLXzIAEK4DoeGzn35IlCyBpnSwA4WgWSP2Q9otqbVgfxEHvNGNy5m9UpOpGYt94ZOscf3eDJ5oFxNPGLHRmOHQvv4rKuKtrHxRTw5kSvTa1WEAe/96qKeemASTYr+GJYp3ISBaQi2YBMdEC7pGPShF6FYIo+qBDqm4fwH4kvi6i8Ea1UYhmTaA6sS3q464i29ARmQcJlgOvVLET3ZIFwC1agC1bwPvDOSr1eYMUqoxIRa4lKl0R0eqMZoHwRGtKrrzjrryYTA1na/SaLZBgE+CdUcya9OSULADPLe78UsYAv2gB/9SjbGUhEwQ921enUEXbE5Etj2h1RrNAOKINUq5eBL0kR6UcIpGekGAZsFLFvJIFUmcXA/CNZgF+0QLisgX01tEVvT4PskINWqZ+yMjWOXPcDZ3RLBCMaIMe5weiuSSHB4pe0x8SrANWdSfe8ViALdnOv7OjWSA1bQy4ixbwjmoBueUiYVQ/yhShsmC9Tk7CiGYBM6IVFWvQqWHZJTlumEgNE+mJMcHefffdeOGFF7B9+3YUFBTg0KFDpprSDitVzBqPlZEsIB7NAv6iteERro1sNSIRwpqIxMItmuHB+dyLICraoKNZgK9Qicg1eAkjNcx1nqHUMA8UvaYnxgTb2tqKyZMno6KiAo8//ripZgKBdzy281gxyXYewxfN2riljgH3D3we4dpEcWmLLpnKfqiKXlNUuryi5Y1mdVWBSrm2hyht8epK/eqaMQykT2qYJjZlLsYEu2DBAgDAihUrTDVhFGeqmHc8tvNYf8kC4IpmgWTRAv5RLeD9QS8i3CDRGZWakKlM2yKyFRGtasoYEI9mPdvTOKYqO5s9jIISsktyaGJTdhGpMdiWlha0tBxPRdXX14fYG7HxWB7JAhCOZgFx0QKpkuEVrhNdAjYxThqmSHmQka2zgpcbOlPGQDDroP3wk6toath0QYnUY8THXd2g6DWziJRga2pq4pFvFGGNxwL+kgXko1nAX7SAu2wBfuE6icoEoqjL1A+vMXM3eKJZXSljQF80KwNP1JqtqeFMp6nJgpUjN4+hmeN1igJCn5633XYbcnJymLcdO3ZId2bevHk4fPhw/FZXVyd9LV04v0E6/wmc/yQpKaCG1tRJDm4TIRrbXCZMtLt+e25ssuK3lOs0W0k3LxpbclxvYeLVJ539cj4/MjcVRB4Pz5cbv/Roc1sXLkE1tXUJvOCIqlyjWmtYV2qYotf0RyiCveWWWzBt2jTmMaeccop0Z2KxGGKx4NfJ+cEajwX8I9nOc/xTxoB32rjz2NQPFK+oNn49hxC8Itz49dI8UlQVoGwbfs+rE96Iljea1ZEyBoJLG5uSaxT3eKXUcPYiJNhevXqhV69epvqS1shIFnDfjcctbdx57PF/eK/0cfzvnMIFxOUQNkFIVBSeNL0bIqINSrKAOdGajJJ1r3lNOY9Sw4QgxsZgd+/ejS+//BK7d+9Ge3s7tm/fDgA49dRT0bVrV1PNGsMvigX4JQuAO5oFUkXbeY53VAskf2B4yTbeDkNYQcs3ivIURUa2zg0eXK/LIVlAz7hsvE1NohUVq67UsM41r6nHUGqYYGNsBsudd96Jc845B9XV1Th69CjOOeccnHPOOdiyZYupJo3jNx4LuI/JuqWIXP8ZG1u5x2ePn9PuOVYbPyZhzNZr7NYLHWOWQY1vRhGRx8UzPtvUmusbqekal01q9+sxWhFRypxj988LE6lh5/8DpYYzjw0bNqCyshL9+/dHTk4O1q5dyzz+v/7rv3DJJZegV69eKCsrQ0VFBV566SXhdo0JdsWKFbAsK+U2btw4U02GAo9kAfd/NrcJUIC/aFVkGz9WQbpRx+2xqdx0ICpa3+spShaQL4eZKE7WTQZdcuWFUsPZQUNDA8466ywsWbKE6/gNGzbgkksuwbp167B161ZcfPHFqKysxNtvvy3UbqSW6aQDbmtjedLFgHvKuPP81LFZwDt1DCT/07NSyDZeqeSkc3w+bPxSzaYIW/5e7cs8H6y1y0ltcozNBj0uaxqd9a+DXPNKqeHoM3HiREycOJH7+Pvvvz/p94ULF+K5557Dn/70J5xzzjnc1yHBSqAqWQBcY7PxcxiiBdhjtcevkfrBwSPdpGtkUJSrA5FxbiduGzm4tuEzNqtLskC0ty8MIjXsen1KDUcaZzEiUytROjo6cOTIEfTo0UPoPBKsJCqSBdjRLKAmWhuWcDuvpy5dohMZ2YpEs6YlC4QTzfJErUGlhnnKIab0gVLD0jQ1taMDchuMtDR1njdgwICk+6urqzF//nzVrqVw77334ujRo7jiiiuEziPBKiAiWQDc0WzndfxFC3jLFhAXbue12W94ErA/fmuTnfBEs0FKFggmmlWRqxdRK4dIqWGz1NXVoaysLP67ieh11apVWLBgAZ577jn07t1b6FwSrAG8dt8RjWY7r+UtWoBftoCccFPbM7+lXRTQ8UVCRLQ80awOyQL8+wGblKyqXKM4sYlSw8FTVlaWJFjdrF69Gj/96U/xzDPPYPz48cLnk2AV8doQQEaygHs023k9tmgBMdkC7h8iMtLNRHSmz0VFa1KyQLjRLO9EJhm5hj2xKaVtSg2nNU899RSuv/56rF69GpdffrnUNejTVAMykgVSU8YAv2gBftkCfMIF/L+5Z7OAZWZmJ53PKVoeyQLsHZJ0SRZIlqKsbEVmCJuUa1ATmyg1HC2OHj2KnTt3xn//9NNPsX37dvTo0QMDBw7EvHnzsGfPHjz55JMAOtPCU6dOxQMPPIDRo0dj3759AICioiJ069aNu91obJWSAXj9s7C+tbL+Cb0KVCRfu9VzLW3K9b5eW+u1xpaXxLW4frdMh3fNccp5PB/yHOtmWetldWwU4IZdpMKvWAXvcTr6xFutydTEJh65Umo4XLZs2RIvdgQAc+bMwTnnnIM777wTAPD5559j9+7d8eMfeeQRtLW1oaqqCv369YvfZs2aJdRu9oYjBhCNZAF2NAv4R7TH2+CLbOPXdZEsb5TLS9iSDSraZtWI9jxHYzTrt9evjslPXuhcu+onV5Fx16BSwzLjrkTwjBs3Dpbl/Z5YsWJF0u+1tbVa2iXBaoYlWQBM0XpJFkj+R9Yt23gbHpGtbvEGhYjgdcnYr0Z0yvFNllHJAnonP5lCVq5hp4ZTrsEx7krRa/ZAgjWAl2QBtWjWhjeq7Wwv+UNCRLjx9nw+aNJVwInonvAlItooSBZQj2Zl0SlX1+NCTA07IblmFyRYQ8hKFhAXLcAn28621YWb0g/Ob/rpJmKdy5r8RMuTMg5KskBw0azOtDAQ7dQwyTWZpsY2dFhyw0gtTekxx4MEaxA/yQLeKWOAX7SAnGw7+5EqRx3SdUNlclUU5OxX/5lFY2O7lmg2CMkC5qNZnslMLLkGmRqmJTmELCRYw7AkC/hHs4CYaAF52R7vk/sHiinx8iAqZ9NC5qn/7EQkmo2KZAG90SzvLGFTcpVJDadcwyc1TOOuhA0JNgB4JAuwo1kg+R9ZRraAnHDj7TO+yYcpXzdYQtYpX1nRpotkgWQpyshWdOmNqFx5MZEapnFXggUJNiD8JAvwixYQj2ptdAo3qT8+abQoCdjEEiVR0fJEs0FIFmAv43HiJstE6cqsY3XrkxtecjW1iTqNuxKqkGADhEeyAF/aOH6sRFSbiCnhOom6gGUrXzmREW2YkgXEolk3VKWa2A8vVOTqel4AS3JIrgQJNmDsfzqd0Wz8HEXZAu7f0k1JNxGeiSRBSli0rrMTEdHySBbwnmEcBcmq4DdTWFWuQSzJoUlNhBsk2JAQiWYBMdECemRr45UaC0K8iYQVBavItqmxTYtkAXY0q0uygFjKWJWg5eraBo27EoYgwYYIr2QBedECemWbSFTEaxPEkiO/Te/d4I1moyBZIBjR8qxvFZGr6/k07kqEDAk2ZHhTxjYqogVSv33rFK5NlMRrSrqyouWRbOd15cZlVXfiSbqWAdHyFo4QlSuNuxJRhAQbEUSiWSD5H1tWtkAwwrWJinh1VrMSFa2uaNZPsoDa5u1J10uQooxsRaoxMXcIEpBrGOOuJFcxmppa0W7JFZ9pbZYvWhMkJNgIISpZG9WoNulaAQrXhpWGC3qClaxsZURrUrKAvpRx0jUFSxeKEKRcVcddSa4EDyTYiCGaMk5EV1SbdE2XCR1BSNcm6FnNqrIVEW1UJAvwpYxNYkqurudplitBeEGCjSiy0ayNzqg25dpZIl37g1dWtLySBdgpY9OSBeSiWR34VWZSlavqpCaaMUyoQIKNMCrRrI2JqNa1nYhJV6dwZUWrM5oNSrJAMNEsT8nDsOXq2idKDRMCkGDTAB2iBVI/HEwKFwhXuiaEqyLadJEskCw/nbLlrSPMWoZjSq6u/aBxV0IREmwaoZo2dhJUdJvUZkjSVd1hKBEZ0fJGs0FIFmDPME66nqJsRYvziy7DkZGr63VoUhNhABJsmqErmnUSdHSb1HbAM5d1yVZWtEFIFlDbvN31ugo72fghGrUC8nKlGcNEUJBg0xRTorUJI7qNtx1glKtDtqKi1SVZQH03HoA/mjWBX1UmkiuRzpBg0xzTogXCjW7jfQiwApWKaEUkC7BTxkHMMAbCEa1OsQIk13SkqeEY2ttlC00c09wbM5BgM4QgRGsTNeHqlq1KVBtWNKsqWSAY0fLUEVaJWjuPI7kS0YAEm2EkfhAEIVsgfOGajG5lo1oR0UZlXDbeVoIEdciWuzg/o54wyZVIR0iwGUyQUW0iURKuLtmqiDYqkgX4o9l4my5y9JIur0jd+uT5N86UcOex/ktxSK5EkJBgs4CwRGsTlRnKOmTbeKQp8pIF/Cc/AXzRrGsfJEXq1Q/Pv5NciTTHXOVuInI0H2mM38KkqaEx6RZYu0ebuUrf+dF4pImr6k9S2w2tXMUNGhtbfddt8uwMw1WTt8ni2uZNN37tNja2e6aEZQv3k1wJAFiyZAkGDRqEwsJCjB49Gm+++Sbz+EOHDqGqqgr9+vVDLBbDN77xDaxbt467PYpgs5Qwxmq9CHpJkK6oViZtrCua5Z1hDLCjWSA5kpSNanngkblK1ArwlT8kuWYnTz/9NObMmYOHH34Yo0ePxv3334/LLrsMH3zwAXr37p1yfGtrKy655BL07t0bzz77LMrLy/HZZ5+he/fu3G2SYInQU8iJhFXOMUjRBpky7ryO/9hs/FiNshWJjkXE2nk8TWYixLjvvvtwww034LrrrgMAPPzww3jhhRfwxBNP4Lbbbks5/oknnsCXX36JjRs3okuXLgCAQYMGCbVJKWIiTlRSyIkElUrWkT4WSRuLpIx9r8WZMuZJGyed83UqV/bG1QajX7xydXsuSa5EIq2trdi6dSvGjx8fvy83Nxfjx4/Hpk2bXM95/vnnUVFRgaqqKvTp0wfDhg3DwoUL0d7O/39EESzhSpRSyDZBpJJVI1oT0ayuohSd1+JLG5uGJXuVqBUguWYT9fX1Sb/HYjHEYrGU47744gu0t7ejT58+Sff36dMHO3bscL32J598gr/+9a+45pprsG7dOuzcuRM///nPcezYMVRXV3P1jwRL+JKNstUh2qimjDuvFbxo/SJoViRO462ZR9PRJrQdk1PQsZbO13rAgAFJ91dXV2P+/PmqXQMAdHR0oHfv3njkkUeQl5eHESNGYM+ePbjnnntIsIQZsk22KqIViWZ5C1PwShbwj2Y7r3dceiZky5OWVhUr4B+1dp5Hcs006urqUFZWFv/dLXoFgJ49eyIvLw/79+9Pun///v3o27ev6zn9+vVDly5dkJd3/P/ijDPOwL59+9Da2oqCAv8vxTQGS0gT5TFb7ddVGKMVHZv1vR7HUh7Ae1mL93Xbk26iOM/niVhZ6WCdKeHE90TU3rOEPGVlZUk3L8EWFBRgxIgRWL9+ffy+jo4OrF+/HhUVFa7njB07Fjt37kRHR0f8vg8//BD9+vXjkitAESyhiahFtqaiWtmINqxoFhCLaJOvLy5ZHkQjVoBPrAClhAlv5syZg6lTp+K8887DqFGjcP/996OhoSE+q3jKlCkoLy9HTU0NAODmm2/GQw89hFmzZmHmzJn46KOPsHDhQvziF7/gbpMES2gnqrLVLVrZtHHQE6Di15MUrQ78ImlWRE4pYUIHV155JQ4ePIg777wT+/btw9lnn40XX3wxPvFp9+7dyM09ntQdMGAAXnrpJfzyl7/E8OHDUV5ejlmzZmHu3LncbZJgCaNESba6RRtUNMs7AQoQEy1gVrZ8y4fUxApQ1ErwM2PGDMyYMcP1b7W1tSn3VVRUYPPmzdLtkWCJwIiKbHWnj1VEqzNlDIiJFkiVoKxwRcZ6ATNi7TyX5EpEBxIsEQpRk60u0UZhbBYQF228DUFRiiIqVkAuagVIrkT4kGCJ0ImCbHWJ1nQ0C/CnjQF50erEd/MCBbF2nk9RKxFNSLBEpAhbtmGK1lQ0CyRLzrRseZYQAfrFCpBc04mmhha0Heside6x1hbNvTEDCZaILGHKVqdoTUezAL9ogVQBqgiXV6Y2rHW+XuuFKWol0hUSLJEWhLXjjw7Rmo5mATnRxtsSlKQMJFYiGyHBEmlFWFFtU0Nj5NPGQLLIZGSrC66KVApiBUiuRPQhwRJpS9BRbdhpY0B8c3ebIGSrIlWAxEpkHiRYIu0JOqoNK20MyIkWcJefrHR5ROqExEpkIyRYIqMIMqpNR9EmtS0hShH8Njnw2jyB5EpkCiRYIiPJNtECarLVhaxUARIrkXmQYImMJsj0cZiiBVLlFoRwebfiE4lWARIrkRmQYImsIaioVqdoATnZAu7yk5WuyJ62NqLRKkBizSaaGxrRdkxuS/K21vR4n5BgiawjnUQLqEW1TmREKYLfpvQkViKbIMESWUtQ6WPdogX0yFYHfkIFvKUKkFiJzIYESxAIJqrVuU2eU2xBCZdHqPFjKVolshwSLEEkkG5Rbfx6HuKTEa+IRFPOpWiVIOKQYAnCg3SLal2vryBLruszhGpDYiWyFRIsQfgQdFQLmJGtLkiqBMEHCZYgBAh6BrJNWMLlkakNSZUgkiHBEoQEYdU/dqJtDFdApImQVAnCGxIsQSgShY3hg4SkShB8kGAJQiNO+QQtXBOQUAkTNB9tQn4XyUpOx8wWTNEFCZYgDJKOwiWhEoQeSLAEESBREi6JlCDMQoIliBDxk5yKgEmgBBEuJFiCiDAkSYJIX+RGmAmCIAgizViyZAkGDRqEwsJCjB49Gm+++Sbz+GeeeQZDhw5FYWEhzjzzTKxbt06oPWOC3bVrF6ZPn47BgwejqKgIQ4YMQXV1NVpbW001SRAEQRCuPP3005gzZw6qq6uxbds2nHXWWbjssstw4MAB1+M3btyIq666CtOnT8fbb7+NSZMmYdKkSXj33Xe52zQm2B07dqCjowPLli3De++9hz/84Q94+OGHcfvtt5tqkiAIgiBcue+++3DDDTfguuuuwze/+U08/PDDKC4uxhNPPOF6/AMPPIAJEybgV7/6Fc444wzcddddOPfcc/HQQw9xt2lsDHbChAmYMGFC/PdTTjkFH3zwAZYuXYp7773XVLMEQRBEGtDe1qB8bn19fdL9sVgMsVgs5fjW1lZs3boV8+bNi9+Xm5uL8ePHY9OmTa5tbNq0CXPmzEm677LLLsPatWu5+xnoJKfDhw+jR48enn9vaWlBS0tL/Hfnk0cQBEGkNwUFBejbty/+9uIPla7TtWtXDBgwIOm+6upqzJ8/P+XYL774Au3t7ejTp0/S/X369MGOHTtcr79v3z7X4/ft28fdx8AEu3PnTjz44IPM6LWmpgYLFiwIqksEQRAEgNf+a0xgbRUWFuLTTz9Vno9jWRZycnKS7nOLXsNEWLC33XYbFi9ezDzmf/7nfzB06ND473v27MGECRMwefJk3HDDDZ7nzZs3Lykkr6+vT/mGYhPkG4IgCILQR2FhIQoLCwNrr2fPnsjLy8P+/fuT7t+/fz/69u3rek7fvn2FjndDWLC33HILpk2bxjzmlFNOif+8d+9eXHzxxRgzZgweeeQR5nle+XOCIAiCkKWgoAAjRozA+vXrMWnSJABAR0cH1q9fjxkzZrieU1FRgfXr12P27Nnx+15++WVUVFRwtyss2F69eqFXr15cx+7ZswcXX3wxRowYgeXLlyM3l5bdEgRBEMEzZ84cTJ06Feeddx5GjRqF+++/Hw0NDbjuuusAAFOmTEF5eTlqamoAALNmzcJFF12E3//+97j88suxevVqbNmyxTdQTMTYGOyePXswbtw4nHzyybj33ntx8ODB+N9EQmyCIAiCUOXKK6/EwYMHceedd2Lfvn04++yz8eKLL8YnMu3evTspCBwzZgxWrVqFO+64A7fffjtOO+00rF27FsOGDeNuM8eyLEv7IwGwYsWK+DcDJ7xN1tfXo1u3bjh8+DDKysp0do8gCIJgQJ+/6hjL2U6bNg2WZbneCIIgCCLToUFRgiAIgjAACZYgCIIgDECCJQiCIAgDkGAJgiAIwgAkWIIgCIIwAAmWIAiCIAxAgiUIgiAIA5BgCYIgCMIAJFiCIAiCMAAJliAIgiAMQIIlCIIgCAOQYAmCIAjCACRYgiAIgjAACZYgCIIgDECCJQiCIAgDkGAJgiAIwgAkWIIgCIIwAAmWIAiCIAxAgiUIgiAIA5BgCYIgCMIAJFiCIAiCMAAJliAIgiAMQIIlCIIgCAOQYAmCIAjCACRYgiAIgjAACZYgCIIgDECCJQiCIAgDkGAJgiAIwgAkWIIgCIIwAAmWIAiCIAxAgiUIgiAIA5BgCYIgCMIAJFiCIAiCMEB+2B1gYVkWAKC+vj7knhAEQWQX9ueu/TlMiBNpwR45cgQAMGDAgJB7QhAEkZ0cOXIE3bp1C7sbaUmOFeGvJx0dHdi7dy9KS0uRk5MTv7++vh4DBgxAXV0dysrKQuxh5kDPqX7oOdUPPaf68XpOLcvCkSNH0L9/f+Tm0miiDJGOYHNzc3HSSSd5/r2srIz+yTRDz6l+6DnVDz2n+nF7TilyVYO+lhAEQRCEAUiwBEEQBGGAtBRsLBZDdXU1YrFY2F3JGOg51Q89p/qh51Q/9JyaI9KTnAiCIAgiXUnLCJYgCIIgog4JliAIgiAMQIIlCIIgCAOQYAmCIAjCAGkv2F27dmH69OkYPHgwioqKMGTIEFRXV6O1tTXsrqUtd999N8aMGYPi4mJ079497O6kLUuWLMGgQYNQWFiI0aNH48033wy7S2nLhg0bUFlZif79+yMnJwdr164Nu0tpT01NDUaOHInS0lL07t0bkyZNwgcffBB2tzKKtBfsjh070NHRgWXLluG9997DH/7wBzz88MO4/fbbw+5a2tLa2orJkyfj5ptvDrsracvTTz+NOXPmoLq6Gtu2bcNZZ52Fyy67DAcOHAi7a2lJQ0MDzjrrLCxZsiTsrmQMr732GqqqqrB582a8/PLLOHbsGC699FI0NDSE3bWMISOX6dxzzz1YunQpPvnkk7C7ktasWLECs2fPxqFDh8LuStoxevRojBw5Eg899BCAzrraAwYMwMyZM3HbbbeF3Lv0JicnB2vWrMGkSZPC7kpGcfDgQfTu3RuvvfYaLrzwwrC7kxGkfQTrxuHDh9GjR4+wu0FkKa2trdi6dSvGjx8fvy83Nxfjx4/Hpk2bQuwZQXhz+PBhAKDPTo1knGB37tyJBx98ED/72c/C7gqRpXzxxRdob29Hnz59ku7v06cP9u3bF1KvCMKbjo4OzJ49G2PHjsWwYcPC7k7GEFnB3nbbbcjJyWHeduzYkXTOnj17MGHCBEyePBk33HBDSD2PJjLPJ0EQ2UFVVRXeffddrF69OuyuZBSR3a7ulltuwbRp05jHnHLKKfGf9+7di4svvhhjxozBI488Yrh36Yfo80nI07NnT+Tl5WH//v1J9+/fvx99+/YNqVcE4c6MGTPw5z//GRs2bGBuD0qIE1nB9urVC7169eI6ds+ePbj44osxYsQILF++nDYHdkHk+STUKCgowIgRI7B+/fr4RJyOjg6sX78eM2bMCLdzBPE1lmVh5syZWLNmDWprazF48OCwu5RxRFawvOzZswfjxo3DySefjHvvvRcHDx6M/42iBTl2796NL7/8Ert370Z7ezu2b98OADj11FPRtWvXcDuXJsyZMwdTp07Feeedh1GjRuH+++9HQ0MDrrvuurC7lpYcPXoUO3fujP/+6aefYvv27ejRowcGDhwYYs/Sl6qqKqxatQrPPfccSktL4/MDunXrhqKiopB7lyFYac7y5cstAK43Qo6pU6e6Pp+vvvpq2F1LKx588EFr4MCBVkFBgTVq1Chr8+bNYXcpbXn11Vdd35NTp04Nu2tpi9fn5vLly8PuWsaQketgCYIgCCJsaLCSIAiCIAxAgiUIgiAIA5BgCYIgCMIAJFiCIAiCMAAJliAIgiAMQIIlCIIgCAOQYAmCIAjCACRYgiAIgjAACZYgCIIgDECCJQiCIAgDkGAJgiAIwgAkWIIgCIIwwP8H0a1N+shrq4sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pde_residual_homotopy(model, X, nu):\n",
        "    \"\"\"\n",
        "    Single‐nu homotopy:\n",
        "      - theta_nu = (interp(r0,r1,nu)) * sigma_true\n",
        "      - f_nu(x)  = interp( f_0(x), f_1(x), nu )\n",
        "    If nu=None, uses theta_true and f_1 exactly.\n",
        "    \"\"\"\n",
        "    # 1) drift/diff ratio\n",
        "    if nu is None:\n",
        "        theta_nu = theta_true\n",
        "    else:\n",
        "        r_nu     = interp(r0, r1, nu)\n",
        "        theta_nu = r_nu * sigma_true\n",
        "\n",
        "    # 2) forcing\n",
        "    if nu is None:\n",
        "        forcing_nu = f_1\n",
        "    else:\n",
        "        forcing_nu = lambda x : interp(f_0(x), f_1(x), nu)\n",
        "\n",
        "    return pde_residual(model, X, theta_nu, sigma_true, forcing=forcing_nu)"
      ],
      "metadata": {
        "id": "vIE2jqz5zK5H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4) Start the Training with Adam"
      ],
      "metadata": {
        "id": "RSYL1T67_73u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop w/ Homotopy & Loss Logging\n",
        "\n",
        "# prep for best‐model tracking\n",
        "best_loss       = float(\"inf\")\n",
        "best_model_path = \"best_adam.pth\"\n",
        "best_epoch = 0\n",
        "eval_Xb = sample_uniform_disk(pool_size, R=R) #to evaluate the model\n",
        "\n",
        "total_history = []\n",
        "pde_history   = []\n",
        "data_history  = []\n",
        "\n",
        "n_hom =  int(0.6 * n_epochs)   # epochs to ramp nu from 0 to 1\n",
        "\n",
        "print(\"\\n=== Training with single‐nu homotopy ramp ===\")\n",
        "model.train()\n",
        "for ep in range(1, n_epochs+1):\n",
        "    nu = make_nu(ep, n_hom, nu_step)   # in [0,1], then stays at 1\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # 2) build one adaptive interior batch using current nu\n",
        "    if nu is None:\n",
        "        forcing_nu = f_1\n",
        "        theta_nu = theta_true\n",
        "    else:\n",
        "        forcing_nu = lambda x : interp(f_0(x), f_1(x), nu)\n",
        "        r_nu     = interp(r0, r1, nu)\n",
        "        theta_nu = r_nu * sigma_true\n",
        "\n",
        "    Xb = make_adaptive_batch(\n",
        "        model, pool_size, batch_size,\n",
        "        forcing_nu, theta_nu, sigma_true, beta=beta\n",
        "    )  # → [batch_size,2]\n",
        "\n",
        "    # 3) PDE residual + loss\n",
        "    r        = pde_residual_homotopy(model, Xb, nu)  # uses theta_nu, f_nu under the hood\n",
        "    loss_pde = loss_fn(r)\n",
        "\n",
        "    # 4) data‐loss (fixed x_data, tau_data)\n",
        "    tau_pred  = model(x_data).squeeze(-1)\n",
        "    loss_data = (tau_pred - tau_data).pow(2).mean()\n",
        "\n",
        "    # 5) total + backward + step\n",
        "    loss_total = torch.exp(-model.log_sigma_pde) * loss_pde \\\n",
        "               + torch.exp(-model.log_sigma_data) * loss_data \\\n",
        "               + model.log_sigma_pde + model.log_sigma_data\n",
        "\n",
        "    # 6) backward + step\n",
        "    loss_total.backward()\n",
        "    opt.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    #eval\n",
        "    r_eval        = pde_residual_homotopy(model, eval_Xb , None)  #evaluate the model on the true PDE\n",
        "    loss_eval     = torch.exp(-model.log_sigma_pde) * loss_fn(r_eval).item() \\\n",
        "                  + torch.exp(-model.log_sigma_data) * loss_data\\\n",
        "                  + model.log_sigma_pde + model.log_sigma_data\n",
        "\n",
        "    if loss_eval < best_loss:\n",
        "        best_loss = loss_eval\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        best_epoch = ep\n",
        "\n",
        "\n",
        "    # 7) logging & histories\n",
        "    total_history.append(loss_total.item())\n",
        "    pde_history.append(loss_pde.item())\n",
        "    data_history.append(loss_data.item())\n",
        "\n",
        "    if ep % 100 == 0:\n",
        "        print(\n",
        "            f\"[ep {ep:4d}/{n_epochs}] \"\n",
        "            f\"nu={nu:.3f}  \"\n",
        "            f\"loss_pde={loss_pde:.2e}  \"\n",
        "            f\"loss_data={loss_data:.2e}\"\n",
        "        )\n",
        "    if ep % 500 == 0:\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"  → epoch {ep:4d},  lr={lr:.2e}\")"
      ],
      "metadata": {
        "id": "wMX05ifLq36Z",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89a131b-4bae-42e2-86e0-b6ecb24ef49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training with single‐nu homotopy ramp ===\n",
            "[ep  100/20000] nu=0.000  loss_pde=9.97e+00  loss_data=3.45e+00\n",
            "[ep  200/20000] nu=0.000  loss_pde=5.73e+00  loss_data=1.20e+00\n",
            "[ep  300/20000] nu=0.000  loss_pde=3.16e+00  loss_data=7.38e-01\n",
            "[ep  400/20000] nu=0.000  loss_pde=1.73e+00  loss_data=8.42e-01\n",
            "[ep  500/20000] nu=0.000  loss_pde=1.24e+00  loss_data=9.57e-01\n",
            "  → epoch  500,  lr=4.46e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.5) L-BFGS Fine-Tuning"
      ],
      "metadata": {
        "id": "MYTAjR_mAHHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LBFGS fine-tuning\n",
        "\n",
        "# Reload best Adam snapshot\n",
        "print(f\"\\nLoading best Adam model (loss={best_loss:.2e}, epoch={best_epoch}) …\")\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# define L-BFGS parameters\n",
        "lbfgs = torch.optim.LBFGS(\n",
        "    model.parameters(),\n",
        "    lr=1.0,\n",
        "    max_iter=500,\n",
        "    history_size=500,\n",
        "    tolerance_grad=0,\n",
        "    tolerance_change=0,\n",
        "    line_search_fn=\"strong_wolfe\"\n",
        ")\n",
        "\n",
        "# freeze one big PDE batch for the closure\n",
        "Xb_ft = make_adaptive_batch(\n",
        "    model, pool_size, pool_size,\n",
        "    f_1, theta, sigma, beta=beta\n",
        ").detach()\n",
        "\n",
        "lbfgs_total = []\n",
        "lbfgs_pde   = []\n",
        "lbfgs_data  = []\n",
        "\n",
        "\n",
        "\n",
        "#closure function\n",
        "def closure():\n",
        "    closure.calls += 1\n",
        "    lbfgs.zero_grad()\n",
        "    # PDE term\n",
        "    r_ft    = pde_residual_homotopy(model, Xb_ft, nu=None)\n",
        "    pde_l   = loss_fn(r_ft)\n",
        "    # data term\n",
        "    tau_p   = model(x_data).squeeze(-1)\n",
        "    data_l  = (tau_p - tau_data).pow(2).mean()\n",
        "    total_l = torch.exp(-model.log_sigma_pde) * pde_l \\\n",
        "            + torch.exp(-model.log_sigma_data) * data_l \\\n",
        "            + model.log_sigma_pde + model.log_sigma_data\n",
        "\n",
        "    # record\n",
        "    lbfgs_total.append(total_l.item())\n",
        "    lbfgs_pde.append(  pde_l.item()   )\n",
        "    lbfgs_data.append( data_l.item()   )\n",
        "\n",
        "    total_l.backward()\n",
        "    return total_l\n",
        "\n",
        "closure.calls = 0"
      ],
      "metadata": {
        "id": "6Xu_iuYS2b2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# report losses before/after lbfgs\n",
        "# make sure model is in eval mode so e.g. Dropout/BatchNorm won’t move\n",
        "model.eval()\n",
        "\n",
        "# --- PDE loss (needs grad to compute ∇u inside pde_residual) ---\n",
        "r_before = pde_residual_homotopy(model, Xb_ft, nu=None)\n",
        "before_pde = loss_fn(r_before).item()\n",
        "\n",
        "# --- data loss (pure forward, safe under no_grad) ---\n",
        "with torch.no_grad():\n",
        "    pred = model(x_data).squeeze(-1)\n",
        "    before_data = (pred - tau_data).pow(2).mean().item()\n",
        "\n",
        "print(f\"Before L-BFGS → PDE {before_pde:.2e}, DATA {before_data:.2e}\")\n",
        "\n",
        "# … run your L-BFGS …\n",
        "print(\"→ Running L-BFGS …\")\n",
        "loss_after = lbfgs.step(closure)\n",
        "print(f\"L-BFGS did {closure.calls} closure calls, final total loss = {loss_after:.2e}\")\n",
        "\n",
        "# after L-BFGS, same pattern:\n",
        "model.eval()\n",
        "r_after = pde_residual_homotopy(model, Xb_ft, nu=None)\n",
        "after_pde = loss_fn(r_after).item()\n",
        "with torch.no_grad():\n",
        "    pred = model(x_data).squeeze(-1)\n",
        "    after_data = (pred - tau_data).pow(2).mean().item()\n",
        "print(f\" After L-BFGS → PDE {after_pde:.2e}, DATA {after_data:.2e}\")"
      ],
      "metadata": {
        "id": "Tq8eGZNl31KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Plotting the results"
      ],
      "metadata": {
        "id": "CpHta0VwANgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1) Training curves"
      ],
      "metadata": {
        "id": "ShkQeYZSAQVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting three separate loss evolutions\n",
        "total_history = total_history + lbfgs_total\n",
        "pde_history   = pde_history + lbfgs_pde\n",
        "data_history  = data_history + lbfgs_data\n",
        "\n",
        "# a) Total Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n_hom), total_history[:n_hom], \\\n",
        "             color = 'blue', label = \"ADAM with homotopy\")\n",
        "plt.semilogy(np.arange(n_hom, n_epochs), total_history[n_hom: n_epochs], \\\n",
        "             color = 'orange', label = \"Adam on true PDE\")\n",
        "plt.semilogy(np.arange(n_epochs, len(total_history)), total_history[n_epochs:], \\\n",
        "             color = 'green', label = \"L-BFGS on true PDE\")\n",
        "plt.title(\"Total Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step (Adam epochs or L-BFGS iter)\")\n",
        "plt.ylabel(\"loss_total\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "# b) PDE Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n_hom), pde_history[:n_hom], \\\n",
        "             color = 'blue', label = \"ADAM with homotopy\")\n",
        "plt.semilogy(np.arange(n_hom, n_epochs), pde_history[n_hom: n_epochs], \\\n",
        "             color = 'orange', label = \"Adam on true PDE\")\n",
        "plt.semilogy(np.arange(n_epochs, len(pde_history)), pde_history[n_epochs:], \\\n",
        "             color = 'green', label = \"L-BFGS on true PDE\")\n",
        "plt.title(\"PDE Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss_pde\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "# c) Data Loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.semilogy(np.arange(n_hom), data_history[:n_hom], \\\n",
        "             color = 'blue', label = \"ADAM with homotopy\")\n",
        "plt.semilogy(np.arange(n_hom, n_epochs), data_history[n_hom: n_epochs], \\\n",
        "             color = 'orange', label = \"Adam on true PDE\")\n",
        "plt.semilogy(np.arange(n_epochs, len(pde_history)), data_history[n_epochs:], \\\n",
        "             color = 'green', label = \"L-BFGS on true PDE\")\n",
        "plt.title(\"Data Loss vs Epoch / L-BFGS step\")\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss_data\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QC2cFlG3q6mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2) Learned Solution vs True Solution"
      ],
      "metadata": {
        "id": "dqHCGWxwAW-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Visualize PINN vs True tau\n",
        "\n",
        "n_pts = 200\n",
        "xx, yy = np.meshgrid(\n",
        "    np.linspace(-R,R,n_pts),\n",
        "    np.linspace(-R,R,n_pts)\n",
        ")\n",
        "mask = xx**2 + yy**2 <= R**2\n",
        "pts = np.vstack([xx[mask], yy[mask]]).T\n",
        "\n",
        "with torch.no_grad():\n",
        "    inp = torch.from_numpy(pts).to(device)\n",
        "    pred = model(inp).cpu().numpy().squeeze(-1)\n",
        "\n",
        "Zp = np.zeros_like(xx); Zt = np.zeros_like(xx)\n",
        "Zp[mask], Zt[mask] = pred, true_tau_vec(xx[mask], yy[mask])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
        "cf1 = ax1.contourf(xx, yy, Zp, levels=50, cmap='viridis')\n",
        "ax1.set_title('PINN tau')\n",
        "fig.colorbar(cf1, ax=ax1, shrink=0.8)\n",
        "\n",
        "cf2 = ax2.contourf(xx, yy, Zt, levels=50, cmap='viridis')\n",
        "ax2.set_title('True tau')\n",
        "fig.colorbar(cf2, ax=ax2, shrink=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mICNQZu_q96H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3) Relative error"
      ],
      "metadata": {
        "id": "37SwVkTGAcBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average relative L2 error\n",
        "#    ‖tau_pinn − tau_true‖₂ / ‖tau_true‖₂\n",
        "pred_vals = pred\n",
        "true_vals = true_tau_vec(pts[:,0], pts[:,1])\n",
        "tau_l2_norm =  np.linalg.norm(true_vals)\n",
        "glob_rel_L2 = np.linalg.norm(pred_vals - true_vals) / tau_l2_norm\n",
        "print(f\"Global relative L2 error: {glob_rel_L2:.3e}\")\n",
        "\n",
        "# pointwise relative L2 error\n",
        "Z_err = np.abs(Zp - Zt)                     # raw error\n",
        "#Z_err_norm = Z_err / tau_l2_norm\n",
        "#err_flat = Z_err[mask]              # flatten to disk\n",
        "#L2_norm = np.sqrt(np.mean(err_flat**2))\n",
        "#Z_err_norm = np.zeros_like(Z_err)\n",
        "#Z_err_norm[mask] = Z_err[mask] / L2_norm\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "cf = plt.contourf(xx, yy, Z_err, levels=50, cmap='RdBu_r')\n",
        "plt.colorbar(cf, label=r'$(|\\tau_{PINN}-\\tau|/\\|\\tau\\|_{L^2}$')\n",
        "plt.title('Normalized L²‐Error Field')\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GZSdlI0pyicy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}